[
  {
    "objectID": "recscal_dcca.html",
    "href": "recscal_dcca.html",
    "title": "Reciprocal scaling with dcCA",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# dc-CA\nsource(here(\"functions/dpcaiv2-ade4.R\"))\n\n# Reciprocal scaling\nsource(here(\"functions/reciprocal.R\"))\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(CAnetwork)"
  },
  {
    "objectID": "recscal_dcca.html#introduction",
    "href": "recscal_dcca.html#introduction",
    "title": "Reciprocal scaling with dcCA",
    "section": "Introduction",
    "text": "Introduction\nThis is an extension of reciprocal scaling defined for correspondence analysis by Thioulouse and Chessel (1992) to double-constrained correspondence analysis.\nHere, we have 3 matrices:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables \\(E\\) (\\(r \\times l\\))\nA matrix of predictor variables \\(T\\) (\\(c \\times k\\))\n\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- ncol(E))\n\n[1] 6\n\n(k &lt;- ncol(T_))\n\n[1] 7\n\n\n\n\nCode\n# Define bound for comparison to zero\nzero &lt;- 10e-10"
  },
  {
    "objectID": "recscal_dcca.html#computation",
    "href": "recscal_dcca.html#computation",
    "title": "Reciprocal scaling with dcCA",
    "section": "Computation",
    "text": "Computation\n\nFrom dcCA scores\nWe compute the \\(H_k(i, j)\\) from the LC scores computed with dcCA (noted \\(LC\\) for rows LS scores and \\(CC\\) for columns LC scores). This formula is a direct extension of formula (11) in Thioulouse and Chessel (1992) but we replace the ordination scores obtained with CA with the ordination scores obtained with dcCA.\n\\[\nH_k(i, j) = \\frac{LC_k(i) + CC_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\n\nYdf &lt;- as.data.frame(Y)\nca &lt;- dudi.coa(Ydf, \n               scannf = FALSE,\n               nf = min(r - 1, c - 1))\n\nneig &lt;- min(c(k, l))\ndcca &lt;- dpcaiv2(dudi = ca, \n                dfR = E,\n                dfQ = T_,\n                scannf = FALSE, \n                nf = neig)\n\nL_dcca &lt;- dcca$li\nC_dcca &lt;- dcca$co\n\nlambda_dcca &lt;- dcca$eig\nmu_dcca &lt;- 1 + sqrt(lambda_dcca)\n\nWe also compute reciprocal scaling for comparison:\n\nrec_dcca &lt;- reciprocal.dpcaiv(dcca)\n\n\n# Transform matrix to count table\nYfreq &lt;- as.data.frame(as.table(Y))\ncolnames(Yfreq) &lt;- c(\"row\", \"col\", \"Freq\")\n\n# Remove the cells with no observation\nYfreq0 &lt;- Yfreq[-which(Yfreq$Freq == 0),]\nYfreq0$colind &lt;- match(Yfreq0$col, colnames(Y)) # match index and species names\n\n\n# Initialize results matrix\nH &lt;- matrix(nrow = nrow(Yfreq0), \n            ncol = length(lambda_dcca))\n\nfor (kl in 1:length(lambda_dcca)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H[ind, kl] &lt;- (L_dcca[i, kl] + C_dcca[j, kl])/sqrt(2*lambda_dcca[kl]*mu_dcca[kl])\n    ind &lt;- ind + 1\n  }\n}\n\n\n\nFrom canonical correlation analysis\nTo perform the canonical correlation analysis, we compute the inflated tables \\(R\\) (\\(\\omega \\times l\\)) and \\(C\\) (\\(\\omega \\times k\\)) from \\(E\\) (\\(r \\times l\\)) and \\(T\\) (\\(r \\times k\\)). \\(R\\) and \\(C\\) are respectively equivalents to \\(E\\) and \\(T\\) where rows of are duplicated as many times as there are correspondences in \\(Y\\).\nWe take the frequency table defined before and use it to compute the inflated tables (with weights):\n\n# Create indicator tables\ntabR &lt;- acm.disjonctif(as.data.frame(Yfreq0$row))\ntabR &lt;- as.matrix(tabR) %*% as.matrix(E)\ntabC &lt;- acm.disjonctif(as.data.frame(Yfreq0$col))\ntabC &lt;- as.matrix(tabC) %*% as.matrix(T_)\n\n# Get weights\nwt &lt;- Yfreq0$Freq\n\nBelow are the first lines of tables \\(R\\) and \\(C\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n0\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n0\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n0\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n0\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n0\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n0\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n1\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n1\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n1\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n1\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n1\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n1\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n\n\n\n\n\n\nbiog\nforag\nmass\ndiet\nmove\nnest\neggs\n\n\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n1\n1\n2\n1\n2\n2\n\n\n1\n1\n1\n2\n1\n2\n2\n\n\n1\n1\n1\n2\n1\n2\n2\n\n\n1\n1\n1\n2\n1\n2\n2\n\n\n\n\n\nThen, we perform a canonical correlation on the scaled tables \\(R_{scaled}\\) and \\(C_{scaled}\\). We find the coefficients \\(\\rho\\) and \\(\\gamma\\) maximizing the correlation between the scores \\(S_R = R_{scaled} \\rho\\) and \\(S_C = C_{scaled} \\gamma\\).\n\n# Center tables\ntabR_scaled &lt;- scalewt(tabR, wt, \n                       scale = FALSE)\ntabC_scaled &lt;- scalewt(tabC, wt, \n                       scale = FALSE)\n\nres &lt;- cancor(diag(sqrt(wt)) %*% tabR_scaled, \n              diag(sqrt(wt)) %*% tabC_scaled, \n              xcenter = FALSE, ycenter = FALSE)\n# res gives the coefficients of the linear combinations that maximizes the correlation between the 2 dimensions\ndim(res$xcoef) # l columns -&gt; R_scaled is of full rank\n\n[1] 6 6\n\ndim(res$ycoef) # k columns -&gt; C_scaled is of full rank\n\n[1] 7 7\n\n# Compute these scores from this coef\nscoreR &lt;- tabR_scaled[, 1:l]  %*% res$xcoef\nscoreC &lt;- tabC_scaled[, 1:k]  %*% res$ycoef\n\nWe have \\(H = (S_R + S_C)_{scaled}\\).\n\n# Get H\nscoreRC &lt;- scoreR[, 1:l] + scoreC[, 1:l] # here we have l &lt; k so l axes\nscoreRC_scaled &lt;- scalewt(scoreRC, wt = wt)\n\n\n# Check result\nall(abs(scoreRC_scaled/H) - 1 &lt; 10e-10)\n\n[1] TRUE\n\n\n\n\nPlot\n\n\nCode\nmultiplot(indiv_row = H, \n          indiv_row_lab = paste0(\"site \", Yfreq0$row, \"/\", Yfreq0$col),\n          row_color = \"black\", eig = lambda_dcca)"
  },
  {
    "objectID": "recscal_dcca.html#conditional-means-and-variances-from-rc-scores",
    "href": "recscal_dcca.html#conditional-means-and-variances-from-rc-scores",
    "title": "Reciprocal scaling with dcCA",
    "section": "Conditional means and variances from RC scores",
    "text": "Conditional means and variances from RC scores\n\n\n\n\n\n\nTL;DR\n\n\n\nOnce we have the correspondences scores, we can group them by row (site) or column (species) to compute conditional summary statistics:\n\nconditional mean for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional variance for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional covariance for site \\(i\\) or species \\(j\\) (between axes \\(k\\) and \\(l\\))\n\nThese conditional statistics can be computed using \\(H_k(i,j)\\) (weighted means/variances/covariances) or using the dcCA scores. We only present the dcCA scores formulas below.\nFormulas using dcCA scores\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[m_k(i) =  \\frac{1}{\\sqrt{2 \\mu_k}} \\times (LC1_k(i) + L_k(i))\\]\n\\[m_k(j) = \\frac{1}{\\sqrt{2 \\mu_k}} \\times (CC1_k(j) + C_k(j))\\]\n\n\nVariance for axis \\(k\\)\n\\[s^2_k(i) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} CC_k^2(j) \\right) - \\lambda_k L_k^2(i) \\right)\\]\n\\[s^2_k(j) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} LC_k^2(i) \\right) - \\lambda_k C_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\n\nLet’s compare the means obtained from canonical correlations scores and the dcCA scores.\n\nn &lt;- sum(Y)\n\n\nFor rows = sites\nBelow is a graphical illustration of scoreRC grouped by rows:\n\ns.class(scoreRC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        plabels.col = params$colsite, \n        main = \"With RC score (points = correspondences)\")\n\n\n\n\n\nFormula with RC scores (definition)\n\nmrowsRC &lt;- meanfacwt(scoreRC_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\nmrowsRC/(as.matrix(dcca$l1 + dcca$lsR) %*% diag(1/sqrt(2*mu_dcca)))\n\n   X1 X2 X3 X4 X5 X6\n1  -1  1 -1 -1 -1 -1\n2  -1  1 -1 -1 -1 -1\n3  -1  1 -1 -1 -1 -1\n4  -1  1 -1 -1 -1 -1\n5  -1  1 -1 -1 -1 -1\n6  -1  1 -1 -1 -1 -1\n7  -1  1 -1 -1 -1 -1\n8  -1  1 -1 -1 -1 -1\n9  -1  1 -1 -1 -1 -1\n10 -1  1 -1 -1 -1 -1\n11 -1  1 -1 -1 -1 -1\n12 -1  1 -1 -1 -1 -1\n13 -1  1 -1 -1 -1 -1\n14 -1  1 -1 -1 -1 -1\n15 -1  1 -1 -1 -1 -1\n16 -1  1 -1 -1 -1 -1\n17 -1  1 -1 -1 -1 -1\n18 -1  1 -1 -1 -1 -1\n19 -1  1 -1 -1 -1 -1\n20 -1  1 -1 -1 -1 -1\n21 -1  1 -1 -1 -1 -1\n22 -1  1 -1 -1 -1 -1\n23 -1  1 -1 -1 -1 -1\n24 -1  1 -1 -1 -1 -1\n25 -1  1 -1 -1 -1 -1\n26 -1  1 -1 -1 -1 -1\n\n\n\nvarrowsRC &lt;- varfacwt(scoreRC_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n\n\nVariance formula with dcCA scores\n\n# Get marginal counts\nyi_ &lt;- rowSums(Y)\ny_j &lt;- colSums(Y)\n\nvarrows_dcca &lt;- matrix(nrow = r, \n                       ncol = l)\n\nfor (i in 1:r) {\n  # Get CCA scores for site i\n  Li &lt;- dcca$lsR[i, ]\n  \n  # Compute the part with the sum on Cj\n  # we add all coordinates Cj^2 weighted by the number of observations on site i\n  sumCj &lt;- t(Y[i, ]) %*% as.matrix(dcca$co)^2\n\n  # Fill i-th row with site i variance along each axis\n  varrows_dcca[i, ] &lt;- (1/(2*lambda_dcca*mu_dcca)) * (((1/yi_[i])*sumCj) - lambda_dcca*as.numeric(Li)^2)\n}\n\n\nvarrowsRC/varrows_dcca\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\n\n\n\nFor columns = species\nBelow is an illustration of the RC scores grouped by species.\n\ns.class(scoreRC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        plabels.col = params$colspp, \n        main = \"With RC score (points = correspondences)\")\n\n\n\n\n\nFormula with RC scores (definition)\n\nmcolsRC &lt;- meanfacwt(scoreRC_scaled, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsRC/(as.matrix(dcca$lsQ + dcca$c1) %*% diag(1/sqrt(2*mu_dcca)))\n\n   X1 X2 X3 X4 X5 X6\n1  -1  1 -1 -1 -1 -1\n2  -1  1 -1 -1 -1 -1\n3  -1  1 -1 -1 -1 -1\n4  -1  1 -1 -1 -1 -1\n5  -1  1 -1 -1 -1 -1\n6  -1  1 -1 -1 -1 -1\n7  -1  1 -1 -1 -1 -1\n8  -1  1 -1 -1 -1 -1\n9  -1  1 -1 -1 -1 -1\n10 -1  1 -1 -1 -1 -1\n11 -1  1 -1 -1 -1 -1\n12 -1  1 -1 -1 -1 -1\n13 -1  1 -1 -1 -1 -1\n14 -1  1 -1 -1 -1 -1\n15 -1  1 -1 -1 -1 -1\n16 -1  1 -1 -1 -1 -1\n17 -1  1 -1 -1 -1 -1\n18 -1  1 -1 -1 -1 -1\n19 -1  1 -1 -1 -1 -1\n20 -1  1 -1 -1 -1 -1\n21 -1  1 -1 -1 -1 -1\n\n\n\nvarcolsRC &lt;- varfacwt(scoreRC_scaled, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\n\n\nVariance formula with dcCA scores\n\nvarcols_dcca &lt;- matrix(nrow = c, \n                       ncol = l)\n\nfor (j in 1:c) {\n  # Get CCA scores for species j\n  Cj &lt;- dcca$lsQ[j, ]\n  \n  # Compute the part with the sum on Li\n  # we add all coordinates Li^2 weighted by the number of observations on species j\n  sumLi &lt;- t(Y[, j]) %*% as.matrix(dcca$li)^2\n\n  # Fill i-th row with site i variance along each axis\n  varcols_dcca[j, ] &lt;- (1/(2*lambda_dcca*mu_dcca)) * (((1/y_j[j])*sumLi) - lambda_dcca*as.numeric(Cj)^2)\n}\n\n\nvarcolsRC/varcols_dcca\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   0  0  0  0  0  0\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  0  0  0  0  0  0\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1"
  },
  {
    "objectID": "recscal_dcca.html#conditional-means-and-variances-from-r-scores-and-c-scores",
    "href": "recscal_dcca.html#conditional-means-and-variances-from-r-scores-and-c-scores",
    "title": "Reciprocal scaling with dcCA",
    "section": "Conditional means and variances from R scores and C scores",
    "text": "Conditional means and variances from R scores and C scores\n\n\n\n\n\n\nTL;DR\n\n\n\nFor the scores computed with R scores and C scores, we have 3 types of formulas:\n\ndefinition (weighted mean/variance/covariance)\nformulas using the dcCA scores\nrelation with the RC scores\n\nHere, we don’t show the definition.\nFormulas using dcCA scores\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{1}{\\sqrt{n}} LC1_k(i)\\] (\\(LC1 =\\) normed LC score ($l1))\n\\[mR_k(j) =  \\frac{1}{\\sqrt{n}} C_k(j)\\] (\\(C =\\) species WA score ($lsQ))\n\n\nVariance for axis \\(k\\)\nNone\n\\[sR_k^2(j) = \\frac{1}{n\\lambda_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} LC_k^2(i) \\right) - \\lambda_k C_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[\\frac{1}{\\sqrt{n}} L_k(i)\\] (\\(L_k(i) =\\) sites WA score ($lsR))\n\\[\\frac{1}{\\sqrt{n}} CC1_k(j)\\] (\\(CC1_k(j) =\\) normed LC species score ($c1))\n\n\nVariance for axis \\(k\\)\n\\[sC_k^2(i) = \\frac{1}{n\\lambda_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} CC_k^2(j) \\right) - \\lambda_k L_k^2(i) \\right)\\]\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\nRelation between RC scores and R score / C score\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(i) - \\frac{1}{\\sqrt{n}} L_k(i)\\]\n\\[mR_k(j) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(j) - \\frac{1}{\\sqrt{n}} CC1_k(j)\\]\n\n\nVariance for axis \\(k\\)\nNone\n\\(sR^2_k(j) = \\frac{2\\mu_k}{n} s^2_k(j)\\)\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mC_k(i) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(i) - \\frac{1}{\\sqrt{n}} LC1_k(i)\\]\n\\[mC_k(j) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(j) - \\frac{1}{\\sqrt{n}} C_k(j)\\]\n\n\nVariance for axis \\(k\\)\n\\(sC^2_k(i) = \\frac{2\\mu_k}{n} s^2_k(i)\\)\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\n\n\nFor rows = sites\n\nscoreC\nBelow is a graphical illustration of scoreC grouped by rows:\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colspp,\n        plabels.col = params$colsite, \n        main = \"With C score (points = species scores)\")\n\n\n\n\n\nmrowsC &lt;- meanfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nmrowsC/(dcca$lsR*1/sqrt(n))\n\n   Axis1 Axis2 Axis3 Axis4 Axis5 Axis6\n1     -1     1    -1    -1    -1    -1\n2     -1     1    -1    -1    -1    -1\n3     -1     1    -1    -1    -1    -1\n4     -1     1    -1    -1    -1    -1\n5     -1     1    -1    -1    -1    -1\n6     -1     1    -1    -1    -1    -1\n7     -1     1    -1    -1    -1    -1\n8     -1     1    -1    -1    -1    -1\n9     -1     1    -1    -1    -1    -1\n10    -1     1    -1    -1    -1    -1\n11    -1     1    -1    -1    -1    -1\n12    -1     1    -1    -1    -1    -1\n13    -1     1    -1    -1    -1    -1\n14    -1     1    -1    -1    -1    -1\n15    -1     1    -1    -1    -1    -1\n16    -1     1    -1    -1    -1    -1\n17    -1     1    -1    -1    -1    -1\n18    -1     1    -1    -1    -1    -1\n19    -1     1    -1    -1    -1    -1\n20    -1     1    -1    -1    -1    -1\n21    -1     1    -1    -1    -1    -1\n22    -1     1    -1    -1    -1    -1\n23    -1     1    -1    -1    -1    -1\n24    -1     1    -1    -1    -1    -1\n25    -1     1    -1    -1    -1    -1\n26    -1     1    -1    -1    -1    -1\n\n\nNow let’s compute the variance of scoreC per row:\n\nvarrowsC &lt;- varfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nCompare it to the variance of the RC score:\n\nvarrowsC[, 1:ncol(varrowsRC)]/(varrowsRC %*% diag(2*mu_dcca/n))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\n\n\nscoreR\nNow, we compute the mean per row (site) from the row (sites) scores.\nBelow is a graphical illustration of scoreR grouped by rows:\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite, \n        main = \"With R score (points = sites scores)\")\n\n\n\n\n\nmrowsR &lt;- meanfacwt(scoreR, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nmrowsR/(dcca$l1*1/sqrt(n))\n\n    RS1 RS2 RS3 RS4 RS5 RS6\nX1   -1   1  -1  -1  -1  -1\nX2   -1   1  -1  -1  -1  -1\nX3   -1   1  -1  -1  -1  -1\nX4   -1   1  -1  -1  -1  -1\nX5   -1   1  -1  -1  -1  -1\nX6   -1   1  -1  -1  -1  -1\nX7   -1   1  -1  -1  -1  -1\nX8   -1   1  -1  -1  -1  -1\nX9   -1   1  -1  -1  -1  -1\nX10  -1   1  -1  -1  -1  -1\nX11  -1   1  -1  -1  -1  -1\nX12  -1   1  -1  -1  -1  -1\nX13  -1   1  -1  -1  -1  -1\nX14  -1   1  -1  -1  -1  -1\nX15  -1   1  -1  -1  -1  -1\nX16  -1   1  -1  -1  -1  -1\nX17  -1   1  -1  -1  -1  -1\nX18  -1   1  -1  -1  -1  -1\nX19  -1   1  -1  -1  -1  -1\nX20  -1   1  -1  -1  -1  -1\nX21  -1   1  -1  -1  -1  -1\nX22  -1   1  -1  -1  -1  -1\nX23  -1   1  -1  -1  -1  -1\nX24  -1   1  -1  -1  -1  -1\nX25  -1   1  -1  -1  -1  -1\nX26  -1   1  -1  -1  -1  -1\n\n\nThe variance is null.\n\n\n\nFor columns = species\n\nscoreC\nWe group the scoreC per species. Below is an illustration:\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp, \n        main = \"With C score (points = species scores)\")\n\n\n\n\n\nmcolsC &lt;- meanfacwt(scoreC, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsC/(dcca$c1*1/sqrt(n))\n\n     CS1 CS2 CS3 CS4 CS5 CS6\nsp1   -1   1  -1  -1  -1  -1\nsp2   -1   1  -1  -1  -1  -1\nsp3   -1   1  -1  -1  -1  -1\nsp4   -1   1  -1  -1  -1  -1\nsp5   -1   1  -1  -1  -1  -1\nsp6   -1   1  -1  -1  -1  -1\nsp7   -1   1  -1  -1  -1  -1\nsp8   -1   1  -1  -1  -1  -1\nsp9   -1   1  -1  -1  -1  -1\nsp10  -1   1  -1  -1  -1  -1\nsp11  -1   1  -1  -1  -1  -1\nsp12  -1   1  -1  -1  -1  -1\nsp13  -1   1  -1  -1  -1  -1\nsp14  -1   1  -1  -1  -1  -1\nsp15  -1   1  -1  -1  -1  -1\nsp16  -1   1  -1  -1  -1  -1\nsp17  -1   1  -1  -1  -1  -1\nsp18  -1   1  -1  -1  -1  -1\nsp19  -1   1  -1  -1  -1  -1\nsp21  -1   1  -1  -1  -1  -1\nsp22  -1   1  -1  -1  -1  -1\n\n\nThe variance is null.\n\n\nscoreR\nBelow are the scoreR grouped by column:\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colsite,\n        plabels.col = params$colspp, \n        main = \"With R score (points = sites scores)\")\n\n\n\n\n\nmcolsR &lt;- meanfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsR/(dcca$lsQ*1/sqrt(n))\n\n     Comp1 Comp2 Comp3 Comp4 Comp5 Comp6\nsp1     -1     1    -1    -1    -1    -1\nsp2     -1     1    -1    -1    -1    -1\nsp3     -1     1    -1    -1    -1    -1\nsp4     -1     1    -1    -1    -1    -1\nsp5     -1     1    -1    -1    -1    -1\nsp6     -1     1    -1    -1    -1    -1\nsp7     -1     1    -1    -1    -1    -1\nsp8     -1     1    -1    -1    -1    -1\nsp9     -1     1    -1    -1    -1    -1\nsp10    -1     1    -1    -1    -1    -1\nsp11    -1     1    -1    -1    -1    -1\nsp12    -1     1    -1    -1    -1    -1\nsp13    -1     1    -1    -1    -1    -1\nsp14    -1     1    -1    -1    -1    -1\nsp15    -1     1    -1    -1    -1    -1\nsp16    -1     1    -1    -1    -1    -1\nsp17    -1     1    -1    -1    -1    -1\nsp18    -1     1    -1    -1    -1    -1\nsp19    -1     1    -1    -1    -1    -1\nsp21    -1     1    -1    -1    -1    -1\nsp22    -1     1    -1    -1    -1    -1\n\n\nNow let’s compute the variance of scoreC per row:\n\nvarcolsR &lt;- varfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nCompare it to the variance of the RC score:\n\nvarcolsR/(varcolsRC %*% diag(2*mu_dcca/n))\n\n    X1  X2  X3  X4  X5  X6\n1    1   1   1   1   1   1\n2    1   1   1   1   1   1\n3    1   1   1   1   1   1\n4    1   1   1   1   1   1\n5    1   1   1   1   1   1\n6    1   1   1   1   1   1\n7  NaN NaN NaN NaN NaN NaN\n8    1   1   1   1   1   1\n9    1   1   1   1   1   1\n10   1   1   1   1   1   1\n11   1   1   1   1   1   1\n12   1   1   1   1   1   1\n13 NaN NaN NaN NaN NaN NaN\n14   1   1   1   1   1   1\n15   1   1   1   1   1   1\n16   1   1   1   1   1   1\n17   1   1   1   1   1   1\n18   1   1   1   1   1   1\n19   1   1   1   1   1   1\n20   1   1   1   1   1   1\n21   1   1   1   1   1   1"
  },
  {
    "objectID": "recscal_dcca.html#means-by-rc-scores-as-a-mean-of-lc-and-wa-scores",
    "href": "recscal_dcca.html#means-by-rc-scores-as-a-mean-of-lc-and-wa-scores",
    "title": "Reciprocal scaling with dcCA",
    "section": "Means by RC scores as a mean of LC and WA scores",
    "text": "Means by RC scores as a mean of LC and WA scores\nThe means of the RC scores by row (site) \\(m_k(i)\\) multiplied by a scaling factor \\(\\sqrt{2\\mu_k}\\) are equal to $lsR+$l1.\n\n\nCode\n# Invert first column\nmrowsRC_inv &lt;- mrowsRC\nmrowsRC_inv[, 1] &lt;- -mrowsRC_inv[, 1]\n\n\n\n(mrowsRC_inv[, 1:2] %*% diag(sqrt(2*mu_dcca[1:2])))/(dcca$l1[, 1:2]+dcca$lsR[, 1:2])\n\n    RS1 RS2\nX1    1   1\nX2    1   1\nX3    1   1\nX4    1   1\nX5    1   1\nX6    1   1\nX7    1   1\nX8    1   1\nX9    1   1\nX10   1   1\nX11   1   1\nX12   1   1\nX13   1   1\nX14   1   1\nX15   1   1\nX16   1   1\nX17   1   1\nX18   1   1\nX19   1   1\nX20   1   1\nX21   1   1\nX22   1   1\nX23   1   1\nX24   1   1\nX25   1   1\nX26   1   1\n\n\nHowever, perhaps it is more intuitive to see the \\(m_k(i)\\) as the mean between $lsR and $l1: for that, we divide \\(m_k(i) \\times \\sqrt{2\\mu_k}\\) by 2.\nThe graph below shows \\(\\frac{m_k(i) \\times \\sqrt{2\\mu_k}}{2}\\) along with the sites LS and WA scores. They are superimposed to the mean between $lsR and $l1 on the graph below:\n\n\nCode\n# Create a long df with $lsR and $l1 for the plot\nbindlsR &lt;- dcca$lsR\ncolnames(bindlsR) &lt;- colnames(dcca$l1)\nlscores &lt;- rbind(dcca$l1, bindlsR)\n\n\n\n\nCode\ns.class(lscores,\n        fac = as.factor(rep(rownames(Y), 2)),\n        ppoints.col = params$colsite,\n        wt = rep(dcca$lw, 2),\n        plabels.col = params$colsite)\ns.label((mrowsRC_inv %*% diag(sqrt(mu_dcca*2)/2)),\n        plabels.col = \"darkorchid3\",\n        add = TRUE)\n\n\n\n\n\n\nMeans of the not scaled scores\nThat was not too bad but it seems strange to compare LC1 and WA scores: LC and WA would be a better fit.\n\n\nCode\n# Create a long df with $lsR and $l1 for the plot\nbindlsR &lt;- dcca$lsR\ncolnames(bindlsR) &lt;- colnames(dcca$li)\nlscores &lt;- rbind(dcca$li, bindlsR)\n\n\n\n\nCode\ns.class(lscores,\n        fac = as.factor(rep(rownames(Y), 2)),\n        ppoints.col = params$colsite,\n        wt = rep(dcca$lw, 2),\n        plabels.col = params$colsite)\ns.label((mrowsRC_inv %*% diag(sqrt(mu_dcca*lambda_dcca*2)/2)),\n        plabels.col = \"darkorchid3\",\n        add = TRUE)\n\n\n\n\n\nBut then the mean of $lsR and $li is not superimposed to the means of the RC scores."
  },
  {
    "objectID": "recscal_dcca.html#non-reciprocal-score",
    "href": "recscal_dcca.html#non-reciprocal-score",
    "title": "Reciprocal scaling with dcCA",
    "section": "Non-reciprocal score",
    "text": "Non-reciprocal score\nWe can remain in the 2 biplots showing \\(V\\) with \\(U^\\star\\) (c1 and lsR) (scaling type 1 = rows niches) and \\(U\\) and \\(V^\\star\\) (lsQ and l1) (scaling type 2 = column niches).\n\n\\(H_1\\) (scaling type 1, rows niches)\nTo do that, we define the “CA-correspondences” \\(h1_k(i, j)\\) for scaling type 1:\n\\[h1_k(i, j) = \\frac{u^\\star_k(i) + v_k(j)}{2}\\]\n\n\nCode\n# Initialize results matrix\nH1 &lt;- matrix(nrow = nrow(Yfreq0), \n             ncol = length(lambda_dcca))\n\nfor (k in 1:length(lambda_dcca)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H1[ind, k] &lt;- (dcca$lsR[i, k] + dcca$c1[j, k])/2\n    ind &lt;- ind + 1\n  }\n}\n\n\n\n\nCode\ncorresp &lt;- paste(Yfreq0$row, Yfreq0$col, sep = \"-\")\nmultiplot(indiv_row = as.data.frame(H1), \n          indiv_row_lab = corresp,\n          row_color = \"black\")\n\n\n\n\n\n\n# Groupwise mean\nmrows_nr &lt;- meanfacwt(H1, fac = Yfreq0$row, wt = Yfreq0$Freq)\nall(abs(abs(mrows_nr/dcca$lsR) - 1) &lt; zero)\n\n[1] TRUE\n\nhead(mrows_nr/mrowsRC) # It is different from the reciprocal scaling means\n\n          X1        X2         X3          X4         X5          X6\n1  1.6533866 0.5279337  0.5851892  0.06781125 -0.1427069 -0.52991699\n2 -0.6823573 0.2621430 -0.5942531 -0.45270450 -0.5003293 -0.35482135\n3  0.4415413 0.5643021 -0.5909733  0.06788904  0.2459682  0.16148020\n4 -0.1482127 0.1372513 -0.3383964 -0.46228036  0.0820352 -0.32748383\n5 -0.1818639 0.5279171 -0.2356614 -0.11017165 -0.1671877  1.47696811\n6 -0.2874715 0.2745043 -0.0337867 -0.91463113  0.2885318 -0.05672653\n\n# Groupwise variance\nvarrows_nr &lt;- varfacwt(H1, fac = Yfreq0$row, wt = Yfreq0$Freq)\nres &lt;- varrows_nr %*% diag(2/mu_dcca) # factor 2/mu\nall(abs(res/varrowsRC - 1) &lt; zero)\n\n[1] TRUE\n\n# We could also multiply H1 before computing the variance\nH1_scaled &lt;- H1 %*% diag(sqrt(2/mu_dcca)) # Factor sqrt(2/mu)\nvarrows_nr_scaled &lt;- varfacwt(H1_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\nall(abs(varrows_nr_scaled/varrowsRC - 1) &lt; zero)\n\n[1] TRUE\n\n\n\n\nCode\ns.class(H1, \n        fac = Yfreq0$row, plabels.col = params$colsite, \n        main = \"Non-reciprocal scaling\")\n\n\n\n\n\nCode\ns.class(H,\n        fac = Yfreq0$row, plabels.col = params$colsite, \n        main = \"Reciprocal scaling\")\n\n\n\n\n\n\\(h1_k(i, j)\\) can also be defined from the canonical correlation scores:\n\\[h1_k(i, j) = \\frac{\\sqrt{n} (R \\bar{S_C} + S_C)}{2}\\] where \\(R \\bar{S_C}\\) corresponds to the duplicated version of \\(\\bar{S_C}\\), the mean of C-scores by rows.\n\nres &lt;- meanfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq) # get the mean of scoreC by row\ntabR &lt;- as.matrix(acm.disjonctif(as.data.frame(Yfreq0$row)))\nscoreRls &lt;- tabR %*% res # Duplicate means according to correspondences of R\n\n# Find back the formula from the scores \nH1_cancor &lt;- (sqrt(n)*(scoreRls[, 1:l] + scoreC[, 1:l]))/2\n# H1_cancor_scaled &lt;- scalewt(H1_cancor, wt = wt/sum(wt))\n\nall(abs(abs(H1_cancor/H1) - 1) &lt; zero)\n\n[1] TRUE\n\n\n\n\n\\(H_2\\) (scaling type 2, columns niches)\nWe define the “CA-correspondences” \\(h2_k(i, j)\\) for scaling type 2:\n\\[h2_k(i, j) = \\frac{u_k(i) + v^\\star_k(j)}{2}\\]\n\n\nCode\n# Initialize results matrix\nH2 &lt;- matrix(nrow = nrow(Yfreq0), \n             ncol = length(lambda_dcca))\n\nfor (k in 1:length(lambda_dcca)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H2[ind, k] &lt;- (dcca$l1[i, k] + dcca$lsQ[j, k])/2\n    ind &lt;- ind + 1\n  }\n}\n\n\n\n\nCode\ncorresp &lt;- paste(Yfreq0$row, Yfreq0$col, sep = \"-\")\nmultiplot(indiv_row = as.data.frame(H2), \n          indiv_row_lab = corresp,\n          row_color = \"black\")\n\n\n\n\n\n\n# Groupwise mean\nmcols_nr &lt;- meanfacwt(H2, fac = Yfreq0$col, wt = Yfreq0$Freq)\nall(abs(abs(mcols_nr/dcca$lsQ)-1) &lt; zero)\n\n[1] TRUE\n\nhead(mcols_nr/mcolsRC) # It is different from the reciprocal scaling means\n\n             X1        X2         X3           X4          X5          X6\nsp1 -0.34539825 0.4613888 -0.1291876  -0.59460911  0.05862701 -0.06963278\nsp2 -0.69971219 0.3321361 -0.7654332 -18.27788124 -0.85018616 -1.39038985\nsp3  0.08000112 0.7109524 -0.3302009  -0.40289677 -1.17113661 -0.25880816\nsp4 -0.54804851 0.4688067 -0.2190234  -0.75729851  0.70129907 -1.27143300\nsp5  0.52038835 0.3837661 -0.3593968   0.03308342 -0.76039465 -2.17864998\nsp6 -1.10639827 0.2343722 -5.0626170   0.15807737 -0.18222986  0.02268947\n\n# Groupwise variance\nsp1 &lt;- c(7, 13) # Species only present in one site\nvarcols_nr &lt;- varfacwt(H2, fac = Yfreq0$col, wt = Yfreq0$Freq)\nres &lt;- varcols_nr %*% diag(2/mu_dcca)\nall(abs(res[-sp1, ]/varcolsRC[-sp1, ] - 1) &lt; zero) # Factor 2/mu\n\n[1] TRUE\n\n\n\n\nCode\ns.class(H2, fac = Yfreq0$row, main = \"Non-reciprocal scaling\")\n\n\n\n\n\nCode\ns.class(H, fac = Yfreq0$row, main = \"Reciprocal scaling\")\n\n\n\n\n\n\\(h2_k(i, j)\\) can also be defined from the canonical correlation scores:\n\\[h2_k(i, j) = \\frac{\\sqrt{n} (S_R + C \\bar{S_R})}{2}\\]\nwhere \\(C \\bar{S_R}\\) corresponds to the duplicated version of \\(\\bar{S_R}\\), the mean of R-scores by columns.\n\n# ScoreR = l1\n# ScoreC = c1\n# mean of score C = ls\n\nres &lt;- meanfacwt(scoreR, fac = Yfreq0$col, wt = Yfreq0$Freq) # get the mean of scoreR by col\ntabC &lt;- as.matrix(acm.disjonctif(as.data.frame(Yfreq0$col)))\nscoreCls &lt;- tabC %*% res # Duplicate means according to correspondences of R\n\n# Find back the formula from the scores \nH2_cancor &lt;- (sqrt(n)*(scoreR[, 1:l] + scoreCls[, 1:l]))/2\n\nall(abs(abs(H2_cancor/H2) - 1) &lt; zero)\n\n[1] TRUE"
  },
  {
    "objectID": "recscal.html",
    "href": "recscal.html",
    "title": "Reciprocal scaling",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# dc-CA\nsource(here(\"functions/dpcaiv2-ade4.R\"))\n\n# Reciprocal scaling\nsource(here(\"functions/reciprocal.R\"))\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(ggplot2)\nlibrary(ggrepel)\n\nlibrary(CAnetwork)\nlibrary(patchwork)\nCode\n# Define bound for comparison to zero\nzero &lt;- 10e-10"
  },
  {
    "objectID": "recscal.html#introduction",
    "href": "recscal.html#introduction",
    "title": "Reciprocal scaling",
    "section": "Introduction",
    "text": "Introduction\nReciprocal scaling was introduced by Thioulouse and Chessel (1992). It is a technique allowing to compute the coordinates of each row/column cell in the multivariate space, and to plot them in a single space, which then allows to get the conditional mean and variance per row or column.\nThis technique was initially defined in the frame of correspondence analysis, but it is extended to canonical CA in reciprocal scaling (CCA) and double-constrained CA in in reciprocal scaling (dcCA).\nHere, we will analyze matrix \\(Y\\):\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21"
  },
  {
    "objectID": "recscal.html#computation",
    "href": "recscal.html#computation",
    "title": "Reciprocal scaling",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nReciprocal scaling gives a score per correspondence (row/column pair) on each ordination axis (instead of a score per row and per column in CA).\nThese scores can be presented in a matrix \\(H\\) (\\(n_\\bar{0} \\times K\\)). Here, \\(n_\\bar{0}\\) is the number of nonzero cells in \\(Y\\), also called correspondences (\\(n_\\bar{0} = \\sum_Y y_{ij} \\neq 0\\)) and \\(K\\) is the number of eigenvalues (axes) of the CA. Each row of \\(H\\) corresponds to a row/column pair.\nFrom CA scores\n\\(H\\) can be computed from the scores of the correspondence analysis of \\(Y\\). The score \\(h_k(i, j)\\) for row \\(i\\), column \\(j\\) and axis \\(k\\) is:\n\\[\nh_k(i, j) = \\frac{u^\\star_k(i) + v^\\star_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\nwhere \\(v^\\star_k(j)\\) and \\(u^\\star_k(i)\\) are the vectors of scores obtained by weighted averaging for CA for axis \\(k\\) (respectively equal to co and li).\nif \\(y_{ij} = 0\\), then the score \\(h_k(i, j)\\) is not defined.\nFrom canonical correlation analysis\nWe transform the table \\(Y\\) in two tables:\n\n\\(R\\) (\\(n_\\bar{0} \\times r\\))\n\\(C\\) (\\(n_\\bar{0} \\times c\\))\n\nEach row of \\(R\\) and \\(C\\) contains an indicator vector. The 1 is in the column corresponding to the row (for \\(R\\)) or column (for \\(C\\)) of the nonzero cell in \\(Y\\).\nAdditionally, we have a weights vector \\(w = y_{ij}\\) (the same for \\(R\\) and \\(C\\)).\nThen, we perform a (weighted) canonical correlation analysis of \\(R_{scaled}\\) and \\(C_{scaled}\\). \\(X_{scaled}\\) corresponds to \\(X\\) center and scaled (here, with the weights \\(w\\)).\nCanonical correlation analysis gives the vectors of canonical coefficients \\(\\rho\\) and \\(\\gamma\\) (resp. for \\(R_{scaled}\\) and \\(C_{scaled}\\)). The scores of the matrices are then \\(S_R = R_{scaled} \\rho\\) and \\(S_C = C_{scaled} \\gamma\\).\nFinally, \\(H\\) is computed as:\n\\[\nH = (S_R + S_C)_{scaled}\n\\]\n\n\n\nFrom CA\nWe perform the CA of table \\(Y\\) (\\(r \\times c\\)).\n\nkca &lt;- min(r - 1, c - 1) # non-null eigenvalues\n\nYdf &lt;- as.data.frame(Y)\nca &lt;- dudi.coa(Ydf, \n               scannf = FALSE,\n               nf = kca)\n\nUstar &lt;- ca$li\nVstar &lt;- ca$co\n\nlambda &lt;- ca$eig\n\nWe compute the reciprocal scaling score for comparison:\n\nrec_ca &lt;- reciprocal.coa(ca)\n\nWe can get the coordinates of row-column pairs (ie each cell in the original table \\(Y\\)) with:\n\\[\nh_k(i, j) = \\frac{u^\\star_k(i) + v^\\star_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\nwhere \\(u^\\star_k(i)\\) is the coordinate of row (site) \\(i\\) on axis \\(k\\) and \\(v^\\star_k(j)\\) is the same for column (species) \\(j\\) and \\(\\mu_k = 1 + \\sqrt{\\lambda_k}\\).\n\nmu &lt;- 1 + sqrt(lambda)\n\nLet’s compute \\(H\\) from the CA scores with our example dataset.\n\n# Transform matrix to count table\nYfreq &lt;- as.data.frame(as.table(Y))\ncolnames(Yfreq) &lt;- c(\"row\", \"col\", \"Freq\")\n\n# Remove the cells with no observation\nYfreq0 &lt;- Yfreq[-which(Yfreq$Freq == 0),]\nYfreq0$colind &lt;- match(Yfreq0$col, colnames(Y)) # match index and species names\n\n# Initialize results matrix\nH &lt;- matrix(nrow = nrow(Yfreq0), \n            ncol = length(lambda))\n\nfor (k in 1:length(lambda)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H[ind, k] &lt;- (Ustar[i, k] + Vstar[j, k])/sqrt(2*lambda[k]*mu[k])\n    ind &lt;- ind + 1\n  }\n}\n\nThe result is a matrix \\(H\\) with \\(n_\\bar{0} = \\sum_Y y_{ij} \\neq 0\\) rows (one row for each nonzero cell in \\(Y\\), called correspondences) and \\(K\\) columns (one column per principal axis of the CA):\n\n\nCode\nplotmat(r = sum(Y != 0), c = length(lambda),\n        Yname = \"italic(H)\",\n        rname = \"italic(n[bar(0)])\",\n        cname = \"italic(K)\",\n        plot.margin.x = 10)\n\n\n\n\n\nWe check that the loop did what we want:\n\n\nCode\n# Choose one element of H\ni &lt;- 1 # row\nj &lt;- 3 # column\njtxt &lt;- colnames(Y)[j]\nl &lt;- 2 # axis\n\nHtest &lt;- H[Yfreq0$row == i & Yfreq0$col == jtxt, k]\n\n# Compute one value with the formula\nHkij &lt;- (Ustar[i, k] + Vstar[j, k])/sqrt(2*lambda[k]*mu[k])\n\n# Compare\nHtest/Hkij\n\n\n[1] 1\n\n\nCompare the results computed above with the results from reciprocal.coa function in ade4:\n\nall(H/rec_ca[, 1:kca] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nFrom canonical correlation analysis\nCanonical correlation analysis is the extension of correlation to multidimensional analysis. This method allows to find the coefficients to maximize the correlation between the columns of two matrices.\nFirst, we compute the inflated tables \\(R\\) (\\(n_\\bar{0} \\times r\\)) and \\(C\\) (\\(n_\\bar{0} \\times c\\)) from \\(Y\\) (\\(r \\times c\\)).\nWe take the frequency table defined before and use it to compute the inflated tables (with weights):\n\n# Create indicator tables\ntabR &lt;- acm.disjonctif(as.data.frame(Yfreq0$row))\ncolnames(tabR) &lt;- rownames(Y)\ntabC &lt;- acm.disjonctif(as.data.frame(Yfreq0$col))\ncolnames(tabC) &lt;- colnames(Y)\n\n# Get weights\nwt &lt;- Yfreq0$Freq\n\nBelow are the first lines of tables \\(R\\) and \\(C\\) (respectively):\n\n\nCode\nknitr::kable(head(tabR, 30))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n\n\n\nCode\nknitr::kable(head(tabC, 30))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\nThen, we perform a canonical correlation on the scaled tables \\(R_{scaled}\\) and \\(C_{scaled}\\). We find the coefficients \\(\\rho\\) and \\(\\gamma\\) maximizing the correlation between the scores \\(S_R = R_{scaled} \\rho\\) and \\(S_C = C_{scaled} \\gamma\\).\n\n# Center tables\ntabR_scaled &lt;- scalewt(tabR, wt, \n                       scale = FALSE)\ntabC_scaled &lt;- scalewt(tabC, wt, \n                       scale = FALSE)\n\nres &lt;- cancor(diag(sqrt(wt)) %*% tabR_scaled, \n              diag(sqrt(wt)) %*% tabC_scaled, \n              xcenter = FALSE, ycenter = FALSE)\n# res gives the coefficients of the linear combinations that maximizes the correlation between the 2 dimensions\nncol(res$xcoef) # r-1 columns -&gt; R_scaled is not of full rank\n\n[1] 25\n\nncol(res$ycoef) # c-1 columns -&gt; C_scaled is not of full rank\n\n[1] 20\n\n# Compute these scores from this coef\nscoreR &lt;- tabR_scaled[, 1:(r-1)]  %*% res$xcoef\nscoreC &lt;- tabC_scaled[, 1:(c-1)]  %*% res$ycoef\n\nFinally, we compute \\(H = (S_R + S_C)_{scaled}\\).\n\n# Get H\nscoreRC &lt;- scoreR[, 1:(c-1)] + scoreC[, 1:(c-1)] # here c-1 &lt; r so c-1 axes\nscoreRC_scaled &lt;- scalewt(scoreRC, wt = wt) # normalisation à 1\n\nWe check the agreement of \\(H\\) defined with CA of with canonical correlation analysis:\n\n# Check agreement of RC score and H score defined above\nall(abs(scoreRC_scaled/H) - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nPlots\nThe scores \\(H\\) are displayed below on the first two axes:\n\n\nCode\nmultiplot(indiv_row = H, \n          indiv_row_lab = paste0(\"site \", Yfreq0$row, \"/\", Yfreq0$col),\n          row_color = \"black\", eig = lambda)\n\n\n\n\n\nWe can group those scores by sites:\n\n\nCode\n# Group by sites\ns.label(H,\n        labels = paste(Yfreq0$row, Yfreq0$col, sep = \"-\"),\n        plabels.optim = TRUE,\n        plabels.col = \"darkgrey\",\n        main = \"Sites\")\ns.class(H, \n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        plabels.col = params$colsite,\n        add = TRUE)\n\n\n\n\n\nOr by species:\n\n\nCode\n# Group by species\ns.label(H,\n        labels = paste(Yfreq0$row, Yfreq0$col, sep = \"-\"),\n        plabels.optim = TRUE,\n        plabels.col = \"darkgrey\",\n        main = \"Species\")\ns.class(H, \n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        labels = colnames(Y),\n        plabels.col = params$colspp,\n        add = TRUE)\n\n\n\n\n\nWe will demonstrate more in-depth below how these groups are linked to the CA scores (means and variances can be computed directly from the CA scores.)"
  },
  {
    "objectID": "recscal.html#conditional-means-and-variances-of-rc-scores",
    "href": "recscal.html#conditional-means-and-variances-of-rc-scores",
    "title": "Reciprocal scaling",
    "section": "Conditional means and variances of RC scores",
    "text": "Conditional means and variances of RC scores\n\n\n\n\n\n\nTL;DR\n\n\n\nOnce we have the correspondences scores, we can group them by row (site) or column (species) to compute conditional summary statistics:\n\nconditional mean for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional variance for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional covariance for site \\(i\\) or species \\(j\\) (between axes \\(k\\) and \\(l\\))\n\nThese conditional statistics can be computed using \\(h_k(i, j)\\) or using the CA scores:\nFormulas using \\(h_k(i, j)\\)\nThe means are simply the weighted means of the \\(h_k(i, j)\\) for a fixed \\(i\\) or \\(j\\) (corresponds to meanfacwt). Similarly, the variances are weighted variances (can be computed with varfacwt).\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[m_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} h_k(i, j)\\]\n\\[m_k(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} h_k(i, j)\\]\n\n\nVariance for axis \\(k\\)\n\\[s_k^2(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} \\left(h_k(i, j) - m_k(i)\\right)^2\\]\n\\[s_k^2(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} \\left(h_k(i, j) - m_k(j)\\right)^2\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\\[c_{kl}(i) = \\frac{1}{y_{i \\cdot}}\\sum_{j=1}^c y_{ij}h_k(i, j)h_l(i, j) - m_k(i)m_l(i)\\]\n\\[c_{kl}(j) = \\frac{1}{y_{\\cdot j}}\\sum_{i=1}^r y_{ij}h_k(i, j)h_l(i, j) - m_k(j)m_l(j)\\]\n\n\n\nFormulas using CA scores\nSummary statistics are also related to CA scores.\nMore precisely, the means by species or site is equivalent to the CA coordinates (co and li) but with a proportionality a factor \\(\\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}}\\).\nThe variances are equivalent to a “weighted variance” (the formula resembles the variance developed formula: \\(\\frac{\\sum x_i^2}{n} - \\bar{x}^2\\)).\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[m_k(i) = \\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}} u^\\star_k(i)\\]\n\\[m_k(j) = \\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}} v^\\star_k(j)\\]\n\n\nVariance for axis \\(k\\)\n\\[s^2_k(i) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} {v^\\star_k(j)}^2 \\right) - \\lambda_k {u^\\star_k(i)}^2 \\right)\\]\n\\[s^2_k(j) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} {u^\\star_k(i)}^2 \\right) - \\lambda_k {v^\\star_k(j)}^2 \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\\[c_{kl}(i) = \\frac{1}{2\\sqrt{\\lambda_k \\lambda_l} \\sqrt{\\mu_k \\mu_l}} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c y_{ij} v^\\star_k(j) v^\\star_l(j) - \\sqrt{\\lambda_k \\lambda_l} u^\\star_k(i)u^\\star_l(i) \\right)\\]\n\\[c_{kl}(j) = \\frac{1}{2\\sqrt{\\lambda_k \\lambda_l} \\sqrt{\\mu_k \\mu_l}} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} u^\\star_k(i) u^\\star_l(i) - \\sqrt{\\lambda_k \\lambda_l} v^\\star_k(j)v^\\star_l(j) \\right)\\]\n\n\n\nNote: formulas for the variances \\(s^2_k(i)\\) and \\(s^2_k(j)\\) are different from formula (15) in Thioulouse and Chessel (1992) (no square root at the denominator \\(2\\lambda_k\\mu_k\\)).\n\n\n\nUsing scores \\(h_k(i, j)\\)\n\nFor rows = sites\nWe compute the weighted mean of \\(h_k(i, j)\\) per row = site \\(i\\).\n\\[\nm_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} h_k(i, j)\n\\] We can compute means using a loop:\n\n\nCode\n# Get marginal counts\nyi_ &lt;- rowSums(Y)\ny_j &lt;- colSums(Y)\n\n\n\n\nCode\n# Initialize mean vector\nmrows &lt;- matrix(nrow = r, \n                ncol = kca) \n\nfor (i in 1:r) {\n  # Get nonzero cells for site i\n  rows &lt;- which(Yfreq0$row == i)\n  \n  # Get scores for site i\n  Hi &lt;- H[rows, ]\n  \n  # Get counts for site i\n  yij &lt;- Yfreq0$Freq[rows]\n  \n  # Fill i-th row with site i mean score along each axis\n  # (colSums sums all species j in site i)\n  if (is.matrix(Hi)) { # There are several species in site i\n    mrows[i, ] &lt;- 1/yi_[i]*colSums(diag(yij) %*% Hi)\n  } else { # Only one species in that site\n    mrows[i, ] &lt;- 1/yi_[i]*colSums(yij %*% Hi)\n  }\n}\n\n\nWe can also compute the mean using meanfacwt:\n\nmrows2 &lt;- meanfacwt(H, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n# Check\nres &lt;- mrows2/mrows\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# Check agreement with ade4 method\nmrows_ade4 &lt;- meanfacwt(rec_ca[, 1:kca], \n                        fac = rec_ca$Row, \n                        wt = rec_ca$Weight)\n\nall(abs(mrows_ade4/mrows) - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe compute the (weighted) variance of \\(h_k(i, j)\\) per row = site \\(i\\).\n\\[\ns_k^2(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} \\left(h_k(i, j) - m_k(i)\\right)^2\n\\]\nNB: in the original article (Thioulouse and Chessel 1992) they use the compact variance formula, \\(s_k^2(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c \\left(y_{ij} h_k(i, j)^2\\right) - m_k(i)^2\\) but I prefer the other formula.\nWe can use a loop:\n\n\nCode\n# Initialize mean vector\nvarrows &lt;- matrix(nrow = r, \n                  ncol = kca) \n\nfor (i in 1:r) {\n  # Get nonzero cells for site i\n  rows &lt;- which(Yfreq0$row == i)\n  \n  # Get scores for site i\n  Hi &lt;- H[rows, ]\n  \n  # Get counts for site i\n  yij &lt;- Yfreq0$Freq[rows]\n  \n  # Fill i-th row with site i variance along each axis\n  varrows[i, ] &lt;- 1/yi_[i]*colSums(diag(yij) %*% sweep(Hi, 2, mrows[i, ], \"-\")^2)\n}\n\n\nWe can also use varfacwt:\n\nvarrows2 &lt;- varfacwt(H, \n                     fac = Yfreq0$row, \n                     wt = Yfreq0$Freq)\n\n# Check\nres &lt;- varrows2/varrows\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# Check agreement with ade4 method\nvarrows_ade4 &lt;- varfacwt(rec_ca[, 1:kca], \n                         fac = rec_ca$Row, \n                         wt = rec_ca$Weight)\n\nall(abs(varrows_ade4/varrows) - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# We can also plot graphs and get back the variance graphical parameter\nvarrows_plot &lt;- s.class(rec_ca[,  1:2], \n                        fac = rec_ca$Row,\n                        wt = rec_ca$Weight, \n                        plot = FALSE)\nvarrows_ax1 &lt;- sapply(varrows_plot@stats$covvar, function(x) x[1,1])\n\nall(varrows_ax1/varrows[, 1] - 1 &lt; zero)\n\n[1] TRUE\n\n\nFinally, we can compute the covariance between scores on the several axes per row = site \\(i\\). The covariance between two axes \\(l\\) and \\(m\\) of the multivariate space for site = row \\(i\\) is defined as:\n\\[\nc_{kl}(i) = \\frac{1}{y_{i \\cdot}}\\sum_{j=1}^c y_{ij}h_k(i, j)h_l(i, j) - m_k(i)m_l(i)\n\\]\n\nk &lt;- 1\nl &lt;- 2\n\nBelow, we compute the covariance between axes \\(k =\\) 1 and \\(l =\\) 2.\n\n# Test to compute covariance for site 3 only\ni &lt;- 3\nrows &lt;- which(Yfreq0$row == i)\n\ncovrow1 &lt;- (1/yi_[i])*sum(Yfreq0$Freq[rows] * H[rows, k] * H[rows, l]) - mrows[i, k]*mrows[i, l]\n\n\n# Compute covariances for all sites\n\n# Create a df containing intermediate computation and row = site identifier\ndf &lt;- data.frame(var = Yfreq0$Freq*H[, k]*H[, l], \n                 by = Yfreq0$row)\n# Get the sum over the different species for each site\nsum_per_site &lt;- aggregate(df$var, list(df$by), sum)$x\n\n# Then vector-compute covariances\ncovrows_kl &lt;- (1/yi_)*sum_per_site - mrows[, k]*mrows[, l]\n\nWe check that the loop does what we want:\n\n\nCode\ncovrows_kl[i]/covrow1\n\n\n3 \n1 \n\n\nWe could also obtain the same result with covfacwt.\n\ncovrows &lt;- covfacwt(H, fac = Yfreq0$row, wt = Yfreq0$Freq)\n# Output: a list of length fac (here, sites) with the variance covariance matrices for each site\n\ncovrows_kl2 &lt;- sapply(covrows, function(c) c[k, l])\n\nres &lt;- covrows_kl/covrows_kl2\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe can also retrieve results from ade4:\n\n# Get results with covfacwt\ncovrows_ade4 &lt;- covfacwt(rec_ca[, 1:kca], \n                         fac = rec_ca$Row, \n                         wt = rec_ca$Weight)\n\nres &lt;- lapply(seq_along(covrows_ade4), \n              function(i) covrows_ade4[[i]]/covrows[[i]])\nreslist &lt;- sapply(res, \n                  function(ri) all(ri - 1 &lt; zero))\nall(reslist)\n\n[1] TRUE\n\n\n\n# Get results from ade4 plot\ncovrows_plot &lt;- s.class(rec_ca[,  k:l], \n                        fac = rec_ca$Row,\n                        wt = rec_ca$Weight, \n                        plot = FALSE)\ncovrows_kl_plot &lt;- sapply(covrows_plot@stats$covvar, function(x) x[k, l])\n\n# Check\nall(covrows_kl_plot/covrows_kl2 - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nFor columns = species\nSymetrically, we can compute the means, variances and covariances per columns = species \\(j\\).\n\\[\nm_k(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} h_k(i, j)\n\\]\n\n\nCode\nmcols &lt;- meanfacwt(H, \n                   fac = Yfreq0$col, \n                   wt = Yfreq0$Freq)\nmcols_ade4  &lt;- meanfacwt(rec_ca[,1:kca], \n                         fac = Yfreq0$col, \n                         wt = Yfreq0$Freq)\nres &lt;- mcols/mcols_ade4\nall(res - 1 &lt; zero)\n\n\n[1] TRUE\n\n\n\\[\ns_k^2(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} \\left(h_k(i, j) - m_k(j)\\right)^2\n\\]\n\n\nCode\nvarcols &lt;- varfacwt(H, \n                   fac = Yfreq0$col, \n                   wt = Yfreq0$Freq)\nvarcols_ade4  &lt;- varfacwt(rec_ca[,1:kca], \n                          fac = Yfreq0$col, \n                          wt = Yfreq0$Freq)\n\n\nTo check results, we treat as a special case species 7 and 13 because they appear in one site only:\n\ncolSums(Y != 0) == 1\n\n  sp1   sp2   sp3   sp4   sp5   sp6   sp7   sp8   sp9  sp10  sp11  sp12  sp13 \nFALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE \n sp14  sp15  sp16  sp17  sp18  sp19  sp21  sp22 \nFALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE \n\nsp1 &lt;- c(7, 13)\n\nIndeed, for this species the variance is null:\n\nvarcols[sp1, ]\n\n     X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 X11 X12 X13 X14 X15 X16 X17 X18 X19 X20\nsp7   0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0\nsp13  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0\n\n\n\nres &lt;- varcols[-sp1, ]/varcols_ade4[-sp1, ]\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\\[c_{kl}(j) = \\frac{1}{y_{\\cdot j}}\\sum_{i=1}^r y_{ij}h_k(i, j)h_l(i, j) - m_k(j)m_l(j)\\]\n\n\nCode\ncovcols &lt;- covfacwt(H, \n                   fac = Yfreq0$col, \n                   wt = Yfreq0$Freq)\ncovcols_ade4  &lt;- covfacwt(rec_ca[,1:kca], \n                          fac = Yfreq0$col, \n                          wt = Yfreq0$Freq)\n\nres &lt;- lapply(seq_along(covcols_ade4), \n              function(i) covcols_ade4[[i]]/covcols[[i]])\nreslist &lt;- sapply(res, \n                  function(ri) all(ri - 1 &lt; zero))\nall(reslist[-sp1])\n\n\n[1] TRUE\n\n\n\n\n\nUsing CA scores\n\nFor rows = sites\nThe conditional means and variances of rows scores on axis \\(k\\) for row \\(i\\) can also be computed as:\n\\[\nm_k(i) = \\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}} u^\\star_k(i)\n\\]\nwhere \\(u^\\star_k(i)\\) corresponds to the li for site \\(i\\) on axis \\(k\\).\n\nmrows_ca &lt;- sweep(ca$li, 2, sqrt(mu)/sqrt(2*lambda), \"*\")\n\n# Check with ade4 value\nall(mrows_ca/mrows_ade4 - 1 &lt; zero)\n\n[1] TRUE\n\n\nThe variance can be computed as:\n\\[\ns^2_k(i) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} {v^\\star_k(j)}^2 \\right) - \\lambda_k {u^\\star_k(i)}^2 \\right)\n\\]\nNote: this formula is different from formula (15) in Thioulouse and Chessel (1992) (no square root at the denominator \\(2\\lambda_k\\mu_k\\). Numerical computations suggest this is the correct formula.\n\nvarrows_ca &lt;- matrix(nrow = r, \n                     ncol = kca)\n\nfor (i in 1:r) {\n  # Get CA scores for site i\n  Li &lt;- Ustar[i, ]\n  \n  # Compute the part with the sum on Cj\n  # we add all coordinates Cj^2 weighted by the number of observations on site i\n  sumCj &lt;- t(Y[i, ]) %*% as.matrix(Vstar)^2\n\n  # Fill i-th row with site i variance along each axis\n  varrows_ca[i, ] &lt;- 1/(2*lambda*mu)*((1/yi_[i])*sumCj - lambda*as.numeric(Li)^2)\n}\n\n\n# Check with ade4 value\nall(varrows_ca/varrows_ade4 - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe can also compute the covariance using CA coordinates:\n\\[\nc_{kl}(i) = \\frac{1}{2\\sqrt{\\lambda_k \\lambda_l} \\sqrt{\\mu_k \\mu_l}} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c y_{ij} v^\\star_k(j) v^\\star_l(j) - \\sqrt{\\lambda_k \\lambda_l} u^\\star_k(i)u^\\star_l(i) \\right)\n\\]\nWe will use the same values as above for \\(k\\) and \\(l\\): \\(k =\\) 1 and \\(l =\\) 2.\n\n# Each site is multiplied by its score (Y*Vstar[, k] by column) and then summed per site\nsum_per_site &lt;- rowSums(Y %*% diag(Vstar[, k]) %*% diag(Vstar[, l]))\n\ncovrows_ca_kl &lt;- 1/(2*sqrt(lambda[k]*lambda[l])*sqrt(mu[k]*mu[l]))*(1/yi_*sum_per_site - sqrt(lambda[k]*lambda[l])*Ustar[, k]*Ustar[, l])\n\nCheck that the CA formulas give the same result as the weighted covariance of correspondences:\n\n# Check result\n\nall(covrows_ca_kl/covrows_kl2 - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nFor columns = species\nSimilarly, column statistics can be computed from CA with the following formulas:\n\\[\nm_k(j) = \\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}} v^\\star_k(j)\n\\]\n\nmcols_ca &lt;- sweep(ca$co, 2, sqrt(mu)/sqrt(2*lambda), \"*\")\n\n# Check\nall(mcols_ca/mcols_ade4 - 1 &lt; zero)\n\n[1] TRUE\n\n\n\\[\ns^2_k(j) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} {u^\\star_k(i)}^2 \\right) - \\lambda_k {v^\\star_k(j)}^2 \\right)\n\\]\n\nvarcols_ca &lt;- matrix(nrow = c, \n                     ncol = kca)\n\nfor (j in 1:c) {\n  # Get CA scores for species j\n  Cj &lt;- Vstar[j, ]\n  \n  # Compute the part with the sum on Li\n  sumLi &lt;- t(Y[, j]) %*% as.matrix(Ustar)^2\n\n  # Fill i-th row with site i variance along each axis\n  varcols_ca[j, ] &lt;- 1/(2*lambda*mu)*((1/y_j[j])*sumLi - lambda*as.numeric(Cj)^2)\n}\n\n\n# Check\nall(varcols_ca[-sp1, ]/varcols_ade4[-sp1, ] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\\[\nc_{kl}(j) = \\frac{1}{2\\sqrt{\\lambda_k \\lambda_l} \\sqrt{\\mu_k \\mu_l}} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} u^\\star_k(i) u^\\star_l(i) - \\sqrt{\\lambda_k \\lambda_l} v^\\star_k(j)v^\\star_l(j) \\right)\n\\]\nWe use the same values of \\(k =\\) 1 and \\(l =\\) 2 as above.\n\n# Each spp is multiplied by its score (Y*Ustar[, k] by row) and then summed per spp\nsum_per_spp &lt;- colSums(diag(Ustar[, k]) %*% diag(Ustar[, l]) %*% Y)\n\ncovcols_kl_ca &lt;- 1/(2*sqrt(lambda[k]*lambda[l])*sqrt(mu[k]*mu[l]))*(1/y_j*sum_per_spp - sqrt(lambda[k]*lambda[l])*Vstar[, k]*Vstar[, l])\n\n\n# Check\ncovcols_kl &lt;- sapply(covcols_ade4,\n                     function(x) x[k, l])\n\nall(covcols_kl[-sp1]/covcols_kl_ca[-sp1] - 1 &lt; zero)\n\n[1] TRUE"
  },
  {
    "objectID": "recscal.html#conditional-means-and-variances-of-r-scores-and-c-scores",
    "href": "recscal.html#conditional-means-and-variances-of-r-scores-and-c-scores",
    "title": "Reciprocal scaling",
    "section": "Conditional means and variances of R scores and C scores",
    "text": "Conditional means and variances of R scores and C scores\nNote: in this part, we change the notation (notation previously used in this part) and use \\(L_k(i)\\) for li and \\(L1_k(i)\\) for l1 (and the same with \\(C_k(j)\\) for co and \\(C1_k(j)\\) for c1).\n\n\n\n\n\n\nTL;DR\n\n\n\nWe can also compute compute means, variances and covariances with the R score or the C score.\nWe use the notation \\(m_k(i)\\)/\\(s^2_k(i)\\) for the mean/variances of sites (index \\(i\\)) computed with the RC scores and \\(mR_k(i)\\)/\\(sR^2_k(i)\\) for the mean/variances of sites computed with the R score. For the means computed for species, we use index \\(j\\) and for the means/variances computed with C scores, we use \\(mC\\)/\\(sC^2\\).\nDefinition\nThe definitions are simply the groupwise mean, variance and covariance.\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_j y_{ij} ~ \\text{scoreR}_k(i, j)\\]\n\\[mR_k(j) = \\frac{1}{y_{\\cdot j}} \\sum_i y_{ij} ~ \\text{scoreR}_k(i, j)\\]\n\n\nVariance for axis \\(k\\)\n\\[sR^2_k(i) = \\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ \\text{scoreR}(i, j)^2 - mR_k(i)^2\\]\n\\[sR^2_k(j) = \\frac{1}{y_{i \\cdot}} \\sum_j y_{ij} ~ \\text{scoreR}(i, j)^2 - mR_k(j)^2\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mC_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_j y_{ij} ~ \\text{scoreC}_k(i, j)\\]\n\\[mC_k(j) = \\frac{1}{y_{\\cdot j}} \\sum_i y_{ij} ~ \\text{scoreC}_k(i, j)\\]\n\n\nVariance for axis \\(k\\)\n\\[sC^2_k(i) = \\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ \\text{scoreC}(i, j)^2 - mC_k(i)^2\\]\n\\[sC^2_k(j) = \\frac{1}{y_{i \\cdot}} \\sum_j y_{ij} ~ \\text{scoreC}(i, j)^2 - mC_k(j)^2\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\nFormulas using CA score\nNow we can “prove” that the values defined above can be recomputed from the CA scores too.\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\(\\frac{1}{\\sqrt{n}} L1_k(i)\\)\n\\(\\frac{1}{\\sqrt{n}} C_k(j)\\)\n\n\nVariance for axis \\(k\\)\nNone\n\\[\\frac{1}{n \\lambda_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} L_k^2(i) \\right) - \\lambda_k C_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\nNone\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\(L_k(i) \\times \\frac{1}{\\sqrt{n}}\\)\n\\(C1_k(j) \\times \\frac{1}{\\sqrt{n}}\\)\n\n\nVariance for axis \\(k\\)\n\\[\\frac{1}{n \\lambda_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} C_k^2(j) \\right) - \\lambda_k L_k^2(i) \\right)\\]\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\nNone\n\n\n\nRelation between RC scores and R score / C score\nFinally, we can relate the quantity computed above (with the definition or with the CA scores) with the means/variances/covariances computed with the RC scores.\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{\\sqrt{2}}{\\sqrt{\\mu_k n}} m_k(i)\\]\n\\[mR_k(j) = \\frac{\\sqrt{2 \\lambda_k}}{\\sqrt{\\mu_k n}} m_k(j)\\]\n\n\nVariance for axis \\(k\\)\nNone\n\\[sR^2_k(j) = \\frac{2 \\mu_k}{n} s^2_k(j)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mC_k(i) =  \\frac{\\sqrt{2 \\lambda_k}}{\\sqrt{\\mu_k n}} m_k(i)\\]\n\\[mC_k(j) = \\frac{\\sqrt{2}}{\\sqrt{\\mu_k n}} m_k(j) \\]\n\n\nVariance for axis \\(k\\)\n\\[sC^2_k(i) = \\frac{2 \\mu_k}{n} s^2_k(i)\\]\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\n\nThis is not at all developed in the article of Thioulouse and Chessel (1992), but we could also use directly the R scores and the C scores to compute the groupwise (species- or sites-wise) mean and variances. In fact, the means and variances computed from the scoresR and scoresC should be related to the means and variances computed from \\(L_k(i)\\) = li and \\(C_k(j)\\) = co, since scoreR = l1 and scoreC = c1.\nWe bother computing these because with CCA and dc-CA, we can’t use directly RC scores.\n\nFor rows = sites (group per row)\n\nn &lt;- sum(Y)\n\n\nscoreC\n\nMean\nWe compute the mean score per site from the column scores.\n\nmrowsC &lt;- meanfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nWe have \\(mC_k(i) = \\frac{L_k(i)}{\\sqrt{n}}\\).\n\nres &lt;- mrowsC/(ca$li * 1/sqrt(n))\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe can prove that equality: we begin by writing the weighted mean formula of scoreC:\n\\[mC_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_i y_{ij} ~ \\text{scoreC}_k(i, j)\\] We replace scoreC with \\(\\frac{C1_k(j)}{\\sqrt{n}}\\) (this equality remains to be proven):\n\\[mC_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_i y_{ij} \\frac{C1_k(j)}{\\sqrt{n}}\\]\nThen we remove \\(\\frac{1}{n}\\) from the sum:\n\\[mC_k(i) = \\frac{1}{\\sqrt{n}}\\frac{1}{y_{i\\cdot}} \\sum_i y_{ij} C1_k(j)\\] By definition, the li are at the mean of the c1 so we can replace \\(\\frac{1}{y_{i\\cdot}} \\sum_i y_{ij} C1_k(j)\\) with \\(L_k(i)\\):\n\\[mC_k(i)  = \\frac{1}{\\sqrt{n}} L_k(i)\\]\n\n\nVariance\nNow, we compare variances computed with the scoreC and variances computed with the scoreRC.\n\nvarrowsC &lt;- varfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nWe have \\(sC_k^2(i) = \\frac{2\\mu_k}{n} ~ s^2_k(i)\\).\n\nres &lt;- varrowsC / (varrows %*% diag(2*mu) / n)\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\nHere too, we can prove the relationship above between the variance of the RC score and the variance of the C score.\n\\[\n\\begin{align}\nsC_k^2(i)\n&= \\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ \\text{scoreC}(i, j)^2 - mC_k(i)^2\\\\\n&= \\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ \\left(\\frac{C1_k(j)}{\\sqrt{n}}\\right)^2 - \\left(\\frac{L_k(i)}{\\sqrt{n}}\\right)^2\\\\\n&= \\frac{1}{n} \\left(\\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ C1_k(j)^2 - L_k(i)^2\\right)\\\\\n&= \\frac{1}{n} \\left(\\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ \\left( \\frac{C_k(j)}{\\sqrt{\\lambda_k}}\\right)^2 - L_k(i)^2\\right)\\\\\n&= \\frac{1}{n} \\times \\frac{1}{\\lambda_k} \\left(\\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ C_k(j)^2 - \\lambda_k L_k(i)^2\\right)\\\\\n&= \\frac{1}{n} \\times \\frac{1}{\\lambda_k} \\times 2\\lambda_k \\mu_k \\times \\frac{1}{2\\lambda_k \\mu_k} \\left(\\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ C_k(j)^2 - \\lambda_k L_k(i)^2\\right)\\\\\nsC_k^2(i) &= \\frac{2\\mu_k}{n} ~ s^2_k(i)\n\\end{align}\n\\]\n\n\n\nscoreR\n\nMean (unique)\nWe compute the mean score per site from the sites scores (i.e. the unique scoreR, since all R values are superimposed for the same site).\n\nmrowsR &lt;- meanfacwt(scoreR, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n\n# The mean per site (row) of scoreR is the same as the unique scores\nmrowsR_u &lt;- unique(scoreR)\nall(mrowsR/mrowsR_u - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# NB: weighting doesn't make a difference because all weights are the same for the same row\nmrowsR_nw &lt;- meanfacwt(scoreR, fac = Yfreq0$row)\n\nall(mrowsR/mrowsR_nw - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe have \\(mR_k(i) = \\frac{L1_k(i)}{\\sqrt{n}}\\).\n\nres &lt;- mrowsR * sqrt(n)/ca$l1\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nVariances (null)\nWe don’t compute variances per rows for the scoreR, because they are null.\n\n\n\nPlots\nBelow are R and C scores grouped by sites (rows):\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colspp,\n        plabels.col = params$colsite, \n        main = \"C scores grouped by sitse (rows)\")\n\n\n\n\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite, \n        main = \"R scores grouped by sites (rows)\")\n\n\n\n\nWe can compare these plots to the RC scores plot below (grouped by sites/rows):\n\ns.class(scoreRC_scaled, \n        wt = Yfreq0$Freq,\n        fac = Yfreq0$row,\n        labels = rownames(Y),\n        plabels.col = params$colsite,\n        main = \"RC scores grouped by sites (rows)\")\n\n\n\n\n\n\n\nFor columns = species (group per column)\n\nscoreC\n\nMean (unique)\nWe compute the mean score per species from the column scores.\n\nmcolsC &lt;- meanfacwt(scoreC, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nWe have \\(mC_k(j) = \\frac{C1_k(j)}{\\sqrt{n}}\\).\n\n# Check\nres &lt;- mcolsC * sqrt(n)/ca$c1\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nVariances (null)\nWe don’t compute variances (they are null).\n\n\n\nscoreR\n\nMean\nWe compute the mean score per species from the row scores.\n\nmcolsR &lt;- meanfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nWe have \\(mR_k(j) = \\frac{C_k(j)}{\\sqrt{n}}\\).\n\nres &lt;- mcolsR/(ca$co/sqrt(n))\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nVariances\nWe compute the variance of species (columns) from the R score:\n\nvarcolsR &lt;- varfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nWe have \\(sR_k^2(j) = \\frac{2\\mu_k}{n} ~ s^2_k(j)\\).\n\n# Check\nres &lt;- (varcolsR[-sp1, 1:kca] %*% diag(1/(2*mu)) * n)/varcols[-sp1, ]\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\nConclusion: using RC scores or using R scores only to compute species-wise means and variances is the same, but there are some multiplying factors.\n\n\n\nPlots\nBelow are R and C scores grouped by species (columns):\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp, \n        main = \"C scores grouped by species (columns)\")\n\n\n\n\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colsite,\n        plabels.col = params$colspp, \n        main = \"R scores grouped by species (columns)\")\n\n\n\n\nWe can compare these plots to the RC scores plot below (grouped by species/columns):\n\ns.class(scoreRC_scaled, \n               wt = Yfreq0$Freq,\n               fac = as.factor(Yfreq0$colind),\n               labels = colnames(Y),\n               plabels.col = params$colspp,\n               main = \"RC scores grouped by species (columns)\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can also compare means/variances extracted from the plots:\n\n\nCode\n# Plot with RC score = H\nxax &lt;- 2\nyax &lt;- 3\nsRC &lt;- s.class(scoreRC_scaled, \n               xax = xax, yax = yax,\n               wt = Yfreq0$Freq,\n               fac = as.factor(Yfreq0$colind),\n               plot = FALSE)\n\n# Plot with R score\nsR &lt;- s.class(scoreR,\n              xax = xax, yax = yax,\n              wt = Yfreq0$Freq,\n              fac = as.factor(Yfreq0$colind),\n              plot = FALSE)\n\n# Compare means\nfac &lt;- sqrt(mu)/sqrt(2*lambda)\nres &lt;- sRC@stats$means/(sR@stats$means %*% diag(fac[c(xax, yax)])*sqrt(n)) \nall(res - 1 &lt; zero) # means are the same\n\n\n[1] TRUE\n\n\nCode\n# Compare variances\nvarRC_ax1 &lt;- (sapply(sRC@stats$covvar, function(x) x[1, 1])*(2*mu[xax]/n))\nvarR_ax1 &lt;- sapply(sR@stats$covvar, function(x) x[1, 1])\n\nres &lt;- varRC_ax1[-sp1]/varR_ax1[-sp1]\nall(res - 1 &lt; zero) # Same on ax1\n\n\n[1] TRUE\n\n\nCode\nvarRC_ax2 &lt;- (sapply(sRC@stats$covvar, function(x) x[2, 2])*(2*mu[yax]/n))\nvarR_ax2 &lt;- sapply(sR@stats$covvar, function(x) x[2, 2])\n\nres &lt;- varRC_ax2[-sp1]/varR_ax2[-sp1]\nall(res - 1 &lt; zero) # Same on ax2\n\n\n[1] TRUE"
  },
  {
    "objectID": "recscal.html#ggplotting",
    "href": "recscal.html#ggplotting",
    "title": "Reciprocal scaling",
    "section": "ggplotting",
    "text": "ggplotting\n\n1d plots\n\n\nCode\n# Define plotting function\nplot_meanvar &lt;- function(mean, var, groupnames, x = 1, col = \"black\")  {\n  ggplot() +\n  geom_point(aes(x = mean[, x], \n                 y = reorder(groupnames, -mean[, x])),\n             colour = col, shape = 1) +\n  geom_linerange(aes(x = mean[, x], \n                     y = reorder(groupnames, -mean[, x]),\n                     xmin = mean[, x] - var[, x],\n                     xmax = mean[, x] + var[, x]),\n                 colour = col) +\n  xlab(paste(\"Axis\", x)) +\n  theme_linedraw() +\n  theme(axis.title.y = element_blank())\n}\n\n\nLet’s plot these means and variances along the first axis for rows and columns:\n\n\nCode\ngr &lt;- plot_meanvar(mean = mrows, \n                   var = 3*sqrt(varrows), \n                   groupnames = rownames(Y),\n                   col = params$colsite) +\n  ggtitle(\"Rows (sites) mean and variance\")\ngc &lt;- plot_meanvar(mean = mcols, \n                   var = 3*sqrt(varcols), groupnames = colnames(Y),\n                   col = params$colspp) +\n  ggtitle(\"Columns (species) mean and variance\")\n\ngr + gc\n\n\n\n\n\nSame result with ade4 function:\n\n\nCode\ns1d.distri(score = ca$li[, 1], \n           dfdistri = as.data.frame(Y),\n           ppoints.col = params$colspp,\n           plabels.col = params$colspp)\n\n\n\n\n\nCode\ns1d.distri(score = ca$co[, 1], \n           dfdistri = as.data.frame(t(Y)),\n           ppoints.col = params$colsite,\n           plabels.col = params$colsite)\n\n\n\n\n\n\n\nCode\ngr &lt;- ggplot() +\n  geom_point(aes(x = covrows_kl2, y = reorder(rownames(Y), -covrows_kl2)),\n             col = params$colsite) +\n  xlab(paste(\"Covariances between axes\", k, \"and\", l)) +\n  theme_linedraw() +\n  theme(axis.title.y = element_blank()) + \n  ggtitle(\"Rows (sites) covariances\")\n\ngc &lt;- ggplot() +\n  geom_point(aes(x = covcols_kl, y = reorder(colnames(Y), -covcols_kl)),\n             col = params$colspp) +\n  xlab(paste(\"Covariances between axes\", k, \"and\", l)) +\n  theme_linedraw() +\n  theme(axis.title.y = element_blank()) + \n  ggtitle(\"Columns (species) covariances\")\n\ngr + gc\n\n\n\n\n\n\n\n2d plots\nWe can also plot the ellipses in 2 dimensions.\nFor that, we need to plot the ellipse summarizing the Gaussian bivariate law for each group. For example, for site \\(i\\) on axes \\(k\\) and \\(l\\) reference blog post:\n\nthe mean vector is \\(\\mu(i) = (m_k(i), m_l(i))\\)\nthe variance-covariance matrix is \\(\\Sigma(i) = \\begin{pmatrix} \\sigma_k^2 ~ \\sigma_{kl}\\\\ \\sigma_{kl} ~ \\sigma_{l}^2 \\end{pmatrix}\\)\n\nThe simplest equation (covariance zero, centered on the origin) is:\n\\[\\left( \\frac{x}{\\sigma_k} \\right)^2 + \\left( \\frac{y}{\\sigma_l} \\right)^2 = s\\] The semi-axes are of length \\(\\sigma_k \\sqrt{s}\\) and \\(\\sigma_l \\sqrt{s}\\). \\(s\\) is the scaling factor allowing the ellipsis to encompass all data with a level of confidence \\(p\\). We have \\(s = -2 \\ln(1-p)\\).\nWe can show that this equation is equivalent to\n\\[\\begin{cases} x = \\sigma_k \\sqrt{s} \\cos(t)\\\\ y = \\sigma_l \\sqrt{s} \\sin(t)  \\end{cases}\\] With \\(t\\) being an angle between 0 and \\(2\\pi\\).\nWe write \\(a\\) the length of the semi-major axis and \\(b\\) the length of the semi-minor axis.\nNow in case the values \\(h_k(i, j)\\) and \\(h_l(i, j)\\) are correlated, the covariance is not zero. Then, the semi-axes lengths are the square root of the eigenvaluesof \\(\\Sigma(i)\\). Geometrically, we have an angle \\(\\theta\\) between axis \\(k\\) and the semi-major axis. \\(\\theta\\) can be computed as the direction of the first eigenvector \\(v_1\\): \\(\\theta = \\arctan(v_1(2)/v_1(1))\\).\nThe equation of the ellipsis is: \\[\\begin{cases} x = m_k(i) +  a  \\cos(\\theta) \\cos(t) - b \\sin(\\theta) \\sin(t) \\\\ y = m_l(i) + a \\sin(\\theta) \\cos(t) + b \\cos(\\theta) \\sin(t) \\end{cases}\\] With \\(a = \\sqrt{\\lambda_1} \\sqrt{s}\\) and \\(b = \\sqrt{\\lambda_2} \\sqrt{s}\\). (Here we assumed the origin could be different from zero and shifted the center with \\(m_k(i)\\) and \\(m_l(i)\\).)\n\n\nCode\ngaussian_ellipses &lt;- function(vars, covars, means, x = 1, y = 2,\n                              t = seq(0, 2*pi, 0.01), s = 1.5, ind = 1:nrow(vars)) {\n  # Length of angles\n  nt &lt;- length(t)\n  \n  # Initialize matrix\n  ellipses_mat &lt;- matrix(nrow = length(t)*nrow(vars), \n                         ncol = 3)\n  \n  for (i in ind) {\n    # Define variance covariance matrix\n    covar &lt;- covars[i]\n    varx &lt;- vars[i, x]\n    vary &lt;- vars[i, y]\n    mat &lt;- matrix(data = c(varx, covar,\n                           covar, vary),\n                  nrow = 2)\n    \n    # Eigenvalues\n    vp &lt;- eigen(mat)$values\n    \n    a &lt;- s*sqrt(max(vp)) # semi major axis\n    b &lt;- s*sqrt(min(vp)) # semi minor axis\n    \n    # angle (inclination of ellipse from axe x)\n    if(covar == 0 & varx &gt;= vary){ # covariance is zero and varx is big\n      theta &lt;- 0\n    }else if(covar == 0 & varx &lt; vary){ # covariance is zero and varx is small\n      theta &lt;- pi/2\n    }else{ # \"normal\" cases\n      # get eigenvector associated to largest eigenvalue\n      v1 &lt;- eigen(mat)$vectors[,1]\n      # theta is the angle of the eigenvector with x -&gt; ie\n      # arctan of the slope given by the first eigenvector\n      theta &lt;- atan(v1[2]/v1[1])\n    }\n    \n    # x and y coordinates of ellipse\n    xellipse &lt;- means[i, x] + a*cos(theta)*cos(t) - b*sin(theta)*sin(t)\n    yellipse &lt;- means[i, y] + a*sin(theta)*cos(t) + b*cos(theta)*sin(t)\n    \n    indmin &lt;- (i-1)*nt + 1\n    indmax &lt;- i*nt\n    ellipses_mat[indmin:indmax, ] &lt;- matrix(c(xellipse, yellipse, rep(i,nt)),\n                                           ncol = 3)\n  }\n  res &lt;- as.data.frame(ellipses_mat)\n  colnames(res) &lt;- c(\"xell\", \"yell\", \"group\")\n  return(res)\n}\n\n\n\n\nCode\nplot_ellipses &lt;- function(var, covar, mean, groupnames, \n                          H, Yfreq0, col = \"black\", ellipses = 1:nrow(var), s = 1.5, x = 1, y = 2) {\n  \n  if (all(groupnames %in% Yfreq0$row)) {\n    indivtype &lt;- \"row\"\n  } else {\n    indivtype &lt;- \"colind\"\n  }\n  \n  rows &lt;- which(Yfreq0[[indivtype]] %in% ellipses)\n  \n  # Get gaussian ellipses for the required groups\n  ell &lt;- gaussian_ellipses(var, covar, mean, s = s, x = k, y = l, ind = ellipses)\n  \n  # Plot ellipses from variance and covariance\n  ggplot() +\n    geom_hline(yintercept = 0) +\n    geom_vline(xintercept = 0) +\n    geom_point(aes(x = H[, x], y = H[, y], alpha = Yfreq0[[indivtype]] %in% ellipses),\n               col = col,\n               show.legend = FALSE) +\n    scale_alpha_manual(values = c(\"TRUE\" = 1, \"FALSE\" = 0.2)) +\n    # Label ellipse points only\n    geom_text_repel(aes(x = H[rows, x], y = H[rows, y], \n                        label = paste(Yfreq0$row[rows], Yfreq0$col[rows])),\n                    col = col) +\n    geom_polygon(data = ell, \n                 aes(x = xell, y = yell, group = group),\n                 fill = col, col = col, alpha = 0.5) +\n    theme_linedraw() +\n    geom_label(aes(x = mean[, x], y = mean[, y], label = groupnames),\n               colour = col) +\n    xlab(paste(\"Axis\", x)) +\n    ylab(paste(\"Axis\", y)) \n}\n\n\n\n\nCode\ngr &lt;- plot_ellipses(varrows, covrows_kl2, mrows, \n                    groupnames = rownames(Y), H = H, Yfreq0 = Yfreq0,\n                    col = params$colsite) + ggtitle(\"Rows (sites)\")\n\ngc &lt;- plot_ellipses(varcols, covcols_kl, mcols, \n                    groupnames = colnames(Y), H = H, Yfreq0 = Yfreq0, \n                    col = params$colspp) + ggtitle(\"Columns (species)\")\n\n\nWarning in sqrt(min(vp)): Production de NaN\n\nWarning in sqrt(min(vp)): Production de NaN\n\n\nCode\ngr + gc\n\n\nWarning: ggrepel: 196 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\nWarning: ggrepel: 196 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\nCode\n# Choose a subset of sites\ni &lt;- c(2, 13, 18)\ngr &lt;- plot_ellipses(varrows, covrows_kl2, mrows, \n                    groupnames = rownames(Y), H = H, Yfreq0 = Yfreq0,\n                    ellipses = i, col = params$colsite) + \n  ggtitle(\"Rows (sites)\")\n\n# Choose a subset of species\nj &lt;- c(16, 12, 20) # sp21 is index 20\ngc &lt;- plot_ellipses(varcols, covcols_kl, mcols, \n                    groupnames = colnames(Y), H = H, Yfreq0 = Yfreq0, \n                    ellipses = j, col = params$colspp) + \n  ggtitle(\"Columns (species)\")\n\ngr + gc\n\n\nWarning: ggrepel: 2 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\nReproduce the same plots with ade4:\n\n\nCode\ns.class(rec_ca[, 1:2],\n        wt = rec_ca$Weight, \n        fac = rec_ca$Row,\n        col = params$colsite,\n        main = \"Rows (sites)\")\n\n\n\n\n\nCode\ns.class(rec_ca[, 1:2], \n        wt = rec_ca$Weight, \n        fac = rec_ca$Col,\n        col = params$colspp,\n        main = \"Columns (species)\")"
  },
  {
    "objectID": "recscal.html#additional-developments",
    "href": "recscal.html#additional-developments",
    "title": "Reciprocal scaling",
    "section": "Additional developments",
    "text": "Additional developments\n\nFormula (3) in Thioulouse and Chessel (1992)\nLet’s test formula (3) in Thioulouse and Chessel (1992):\n\\[L_k(i) = \\sum_{j=1}^c p_{j|i} C_k(j)\\]\nwith \\(p_{j|i} = \\frac{y_{ij}}{y_{i \\cdot}}\\). This formula relates species and samples scores in CA.\n\n# Test formula for a given k\nk &lt;- 2\n\n# compute pj|i\npjcondi &lt;- sweep(Y, 1, yi_, \"/\")\n\n# Compute the formula that should be equal th Lk(i)\nres &lt;- vector(mode=\"numeric\", length=nrow(Y))\nfor (i in 1:nrow(Y)) {\n  res[i] &lt;- sum(pjcondi[i, ]*ca$co[, k])\n}\n\n\nres/ca$li[, k] # not equal\n\n [1] 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288\n [8] 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288\n[15] 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288\n[22] 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288\n\n\nWe find that in fact the correct formula is\n\\[L_k(i) = \\frac{1}{\\sqrt{\\lambda_k}}\\sum_{j=1}^c p_{j|i} C_k(j)\\]\n\nres/sqrt(lambda[k])/ca$li[, k]\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nWith this equality, we can indeed prove numerically the equivalence between mean computation using \\(h_k(i, j)\\) (Equations (12) and (14) in Thioulouse and Chessel (1992)) and using CA coordinates (computation in notebook not shown here).\n\n\nMean of means\nThe reciprocal scaling mean computed with \\(\\frac{\\sqrt{\\mu_k}}{\\sqrt{2 \\lambda_k}} v^\\star_k(i)\\) is the same as the weighted mean of the weighted means \\(\\frac{\\sqrt{\\mu_k}}{\\sqrt{2 \\lambda_k}} u^\\star_k(j)\\), where \\(j\\) is used to index all species occurring in site \\(i\\). So we can interpret species/site-wise means of the \\(H\\) scores as means of means of the other category.\n\ni &lt;- 1 # site\nk &lt;- 1:2 # axes\n\n# Get the correspondences for site i\nHsub &lt;- H[Yfreq0$row == i, k]\nj &lt;- Yfreq0$col[Yfreq0$row == i]\nrownames(Hsub) &lt;- paste0(\"s\", i, \"-\", j)\n\n# Get the weights of correspondences\nwth &lt;- Yfreq0$Freq[Yfreq0$row == i]\n\n# Weighted mean of correspondences\nh_i &lt;- meanfacwt(Hsub, wt = wth) \nh_i &lt;- data.frame(t(h_i))\nrownames(h_i) &lt;- paste(\"rec\", i)\n\n# Get reciprocal scaling means computed from CA coordinates\n# For site i\nca_i &lt;- ca$li[i, k]*sqrt(mu[k])/sqrt(2*lambda[k]) \nrownames(ca_i) &lt;- paste(\"CA\", i)\n\n# For species j present in site i (transformed coordinates)\nca_j &lt;- sweep(ca$co[j, k], 2, sqrt(mu[k])/sqrt(2*lambda[k]), \"*\")\n\n\n# Compare weighted means\nh_i/ca_i\n\n      X1 X2\nrec 1  1  1\n\n\nOn this plot, we plot the CA coordinates for site \\(i\\) and for all species \\(j\\) in site \\(i\\) (scaled with a factor \\(\\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}}\\). We surimpose the reciprocal scaling correspondences for site \\(i\\) (purple dots).\nNB: Means should be surimposed, I don’t know why they are not.\n\n\nCode\n# Plot correspondences and mean\ns.class(Hsub, \n        fac = factor(rep(paste(\"rec\", i), nrow(Hsub))),\n        wt = wth,\n        ppoints.col = \"darkgrey\",\n        main = \"Correspondences\")\ns.label(Hsub, \n        plabels.optim = TRUE, add = TRUE,\n        ppoints.col = \"darkorchid\",\n        plabels.col = \"darkorchid\")\ns.label(ca_i, \n        plabels.col = params$colsite, add = TRUE)\ns.label(h_i, \n        plabels.col = params$colsite, add = TRUE)\n\n\n\n\n\n\n\nCode\n# Plot CA and mean\n# On a separate plot because else ade4 goes crazy\ns.class(ca_j,\n        ppoints.col = \"grey\",\n        fac = factor(rep(i, nrow(ca_j))),\n        wt = wth,\n        main = \"Means\")\ns.label(ca_j, \n        plabels.optim = TRUE, add = TRUE,\n        plabels.col = params$colspp, \n        ppoints.col = params$colspp, )\ns.label(ca_i, \n        plabels.col = params$colsite, add = TRUE)\ns.label(h_i, \n        plabels.col = params$colsite, add = TRUE)"
  },
  {
    "objectID": "recscal.html#non-reciprocal-score",
    "href": "recscal.html#non-reciprocal-score",
    "title": "Reciprocal scaling",
    "section": "Non-reciprocal score",
    "text": "Non-reciprocal score\nIf we don’t want to find a new common space to plot correspondences in, we can remain in the 2 biplots showing \\(V\\) with \\(U^\\star\\) (c1 and li) (scaling type 1 = rows niches) and \\(U\\) and \\(V^\\star\\) (co and l1) (scaling type 2 = columns niches).\n\n\\(H_1\\) (scaling type 1, rows niches)\nTo do that, we define the “CA-correspondences” \\(h1_k(i, j)\\) for scaling type 1:\n\\[h1_k(i, j) = \\frac{u^\\star_k(i) + v_k(j)}{2}\\]\n\n\nCode\n# Initialize results matrix\nH1 &lt;- matrix(nrow = nrow(Yfreq0), \n             ncol = length(lambda))\n\nfor (k in 1:length(lambda)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H1[ind, k] &lt;- (ca$li[i, k] + ca$c1[j, k])/2\n    ind &lt;- ind + 1\n  }\n}\n\n\n\n\nCode\ncorresp &lt;- paste(Yfreq0$row, Yfreq0$col, sep = \"-\")\nmultiplot(indiv_row = as.data.frame(H1), \n          indiv_row_lab = corresp,\n          row_color = \"black\")\n\n\n\n\n\n\n# Groupwise mean\nmrows_nr &lt;- meanfacwt(H1, fac = Yfreq0$row, wt = Yfreq0$Freq)\nall(abs(abs(mrows_nr/ca$li) - 1) &lt; zero) # means correspond to li\n\n[1] TRUE\n\nres &lt;- mrows_nr %*% diag(sqrt(mu)/sqrt(2*lambda)) # factor sqrt(mu)/sqrt(2*lambda)\nall(abs(res/mrows - 1) &lt; zero) # same as recscal means with a factor sqrt(mu)/sqrt(2*lambda)\n\n[1] TRUE\n\n# Groupwise variance\nvarrows_nr &lt;- varfacwt(H1, fac = Yfreq0$row, wt = Yfreq0$Freq)\nres &lt;- varrows_nr %*% diag(2/mu) # Factor 2/mu\nall(abs(res/varrows) - 1 &lt; zero)\n\n[1] TRUE\n\n# We could also multiply H1 before computing the variance\nH1_scaled &lt;- H1 %*% diag(sqrt(2/mu)) # Factor sqrt(2/mu)\nvarrows_nr_scaled &lt;- varfacwt(H1_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\nall(abs(varrows_nr_scaled/varrows - 1) &lt; zero)\n\n[1] TRUE\n\n\n\n\nCode\ns.class(H1, fac = Yfreq0$row, main = \"Non-reciprocal scaling\")\n\n\n\n\n\nCode\ns.class(H, fac = Yfreq0$row, main = \"Reciprocal scaling\")\n\n\n\n\n\n\\(h1_k(i, j)\\) can also be defined from the canonical correlation scores:\n\\[h1_k(i, j) = \\frac{\\sqrt{n} (S_R \\Lambda^{1/2} + S_C)}{2}\\]\n\n# Find back the formula from the scores \nH1_cancor &lt;- (sqrt(n)*(scoreR[, 1:(c-1)] %*% diag(lambda^(1/2)) + scoreC))/2\n# H1_cancor_scaled &lt;- scalewt(H1_cancor, wt = wt/sum(wt))\n\nall(abs(abs(H1_cancor/H1) - 1) &lt; zero)\n\n[1] TRUE\n\n\n\n\n\\(H_2\\) (scaling type 2, columns niches)\nWe define the “CA-correspondences” \\(h2_k(i, j)\\) for scaling type 2:\n\\[h2_k(i, j) = \\frac{u_k(i) + v^\\star_k(j)}{2}\\]\n\n\nCode\n# Initialize results matrix\nH2 &lt;- matrix(nrow = nrow(Yfreq0), \n             ncol = length(lambda))\n\nfor (k in 1:length(lambda)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H2[ind, k] &lt;- (ca$l1[i, k] + ca$co[j, k])/2\n    ind &lt;- ind + 1\n  }\n}\n\n\n\n\nCode\ncorresp &lt;- paste(Yfreq0$row, Yfreq0$col, sep = \"-\")\nmultiplot(indiv_row = as.data.frame(H2), \n          indiv_row_lab = corresp,\n          row_color = \"black\")\n\n\n\n\n\n\n# Groupwise mean\nmcols_nr &lt;- meanfacwt(H2, fac = Yfreq0$col, wt = Yfreq0$Freq)\nall(abs(abs(mcols_nr/ca$co) - 1) &lt; zero) # equal to the co\n\n[1] TRUE\n\nres &lt;- mcols_nr %*% diag(sqrt(mu)/sqrt(2*lambda)) \nall(abs(res/mcols - 1) &lt; zero) # same as reciprocal scaling by a factor sqrt(mu)/sqrt(2*lambda)\n\n[1] TRUE\n\n# Groupwise variance\nvarcols_nr &lt;- varfacwt(H2, fac = Yfreq0$col, wt = Yfreq0$Freq)\nvarcols_nr_scaled &lt;- varcols_nr %*% diag(2/(mu)) # factor 2/mu\nall(abs(varcols_nr_scaled[-sp1, ]/varcols[-sp1, ] - 1) &lt; zero) # same as reciprocal scaling by a factor 2/mu\n\n[1] TRUE\n\n\n\n\nCode\ns.class(H2, fac = Yfreq0$row, main = \"Non-reciprocal scaling\")\n\n\n\n\n\nCode\ns.class(H, fac = Yfreq0$row, main = \"Reciprocal scaling\")\n\n\n\n\n\n\\(h2_k(i, j)\\) can also be defined from the canonical correlation scores:\n\\[h2_k(i, j) = \\frac{\\sqrt{n} (S_R + S_C  \\Lambda^{1/2})}{2}\\]\n\n# Find back the formula from the scores \nH2_cancor &lt;- (sqrt(n)*(scoreR[, 1:(c-1)] + scoreC %*% diag(lambda^(1/2))))/2\n\nall(abs(abs(H2_cancor/H2) - 1) &lt; zero)\n\n[1] TRUE"
  },
  {
    "objectID": "CCA.html",
    "href": "CCA.html",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(ggplot2)\nlibrary(CAnetwork)\nlibrary(patchwork)\nCode\n# Define bound for comparison to zero\nzero &lt;- 10e-10\nThe contents of this page relies heavily on Legendre and Legendre (2012)."
  },
  {
    "objectID": "CCA.html#introduction",
    "href": "CCA.html#introduction",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Introduction",
    "text": "Introduction\nCCA is a method of the family of canonical or direct gradient analyses, in which a matrix of predictor variables intervenes in the computation of the ordination vectors.\nCCA is an asymmetric method because the predictor variables and the response variables are not equivalent in the analysis.\nCCA takes two matrices in input:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables \\(E\\) (\\(r \\times l\\))\n\n\n\nCode\ndat &lt;- readRDS(here(\"data/Barbaro2012.rds\"))\nY &lt;- dat$comm\nE &lt;- dat$envir\n\nr &lt;- dim(Y)[1]\nc &lt;- dim(Y)[2]\nl &lt;- dim(E)[2]\n\nplotmat(r = r, c = c, l = l, \n        E = TRUE)\n\n\n\n\n\nHere, \\(Y\\) represents the abundance of different bird species (columns) at different sites (rows):\n\n\nCode\nknitr::kable(head(Y))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n\n\n\n\\(E\\) represents environmental variables (columns) associated to each site (rows).\n\n\nCode\nknitr::kable(head(E))\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- dim(E)[2])\n\n[1] 6"
  },
  {
    "objectID": "CCA.html#computation",
    "href": "CCA.html#computation",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nWe have a data matrix \\(Y\\) (\\(r \\times c\\)) and a matrix \\(E\\) (\\(r \\times l\\)) of predictors variables.\nWe regress \\(P_0\\) (“centered” \\(Y\\)) on \\(E_{stand}\\) (which is the centered and scaled \\(E\\) matrix):\n\\[\n\\hat{P_0} = D_r^{1/2} E_{stand}B\n\\]\nThen, we diagonalize matrix \\(S_{\\hat{P_0}^\\top \\hat{P_0}} = \\hat{P_0}^\\top\\hat{P_0}\\).\n\\[\nS_{\\hat{P_0}^\\top\\hat{P_0}} =  V_0 \\Lambda V_0^{-1}\n\\]\nThe matrix \\(V_0\\) (\\(c \\times \\text{mindim}\\)) contains the loadings of the columns (species) of the contingency table. There are \\(\\text{mindim} = \\min(r-1, c, l)\\) non-null eigenvalues.\nThen, we can find the rows (sites) observed scores \\(U_0\\) (\\(r \\times \\text{mindim}\\)) from the eigenvectors of the multivariate space using the following formula:\n\\[\nU_0 = P_0 V_0 \\Lambda^{-1/2}\n\\]\nHere, it is important to note that \\(U_0\\) contains the loadings of the sites computed from the observed data matrix \\(P_0\\), i.e. the latent ordination of the sites not taking into account the sites variables. The position of the sites taking into account the regression will be defined below in the scalings section.\nFinally, we define the following transformations of \\(U_0\\) and \\(V_0\\) (\\(V_0\\) corresponds to c1):\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U &= D_r^{-1/2} U_0\\\\\n  V &= D_c^{-1/2} V_0\\\\\n\\end{array}\n\\right.\n\\] This transformation is similar to the transformation applied to CA eigenvectors.\n\n\n\nTransform matrix\nWe start by “centering” the matrix \\(Y\\) to get \\(P_0\\) (just like with CA).\n\\[\nP = Y/y_{\\cdot \\cdot}\n\\]\n\\[\nP_0 = [p_{0ij}] = \\left[ \\frac{p_{ij} - p_{i\\cdot} p_{\\cdot j}}{\\sqrt{p_{i\\cdot} p_{\\cdot j}}} \\right]\n\\]\nHere, we have:\n\n\nCode\nP &lt;- Y/sum(Y)\n\n# Initialize P0 matrix\nP0 &lt;- matrix(ncol = ncol(Y), nrow = nrow(Y))\ncolnames(P0) &lt;- colnames(Y)\nrownames(P0) &lt;- rownames(Y)\n\nfor(i in 1:nrow(Y)) { # For each row\n  for (j in 1:ncol(Y)) { # For each column\n    # Do the sum\n    pi_ &lt;- sum(P[i, ])\n    p_j &lt;- sum(P[, j])\n    \n    # Compute the transformation\n    P0[i, j] &lt;- (P[i, j] - (pi_*p_j))/sqrt(pi_*p_j)\n  }\n}\n\n\n\n\nCode\nknitr::kable(head(P0))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n-0.0246174\n-0.0235678\n0.1819102\n0.0177849\n-0.0086058\n0.0190444\n-0.0060852\n0.0389306\n-0.0172115\n0.0177849\n0.0142185\n-0.0285421\n-0.0121704\n-0.0086058\n-0.0172115\n-0.0136069\n-0.0172115\n-0.0425963\n0.0259875\n-0.0227687\n-0.0250899\n\n\n-0.0700532\n-0.0430288\n-0.0192431\n-0.0075494\n-0.0157119\n-0.0362309\n-0.0111100\n0.0317935\n-0.0314238\n-0.0075494\n-0.0702658\n0.0257394\n0.3429284\n-0.0157119\n0.1622254\n0.2201063\n-0.0314238\n0.0004761\n-0.0290665\n-0.0415698\n0.0427538\n\n\n0.0325898\n-0.0342433\n-0.0153141\n0.0216502\n-0.0125039\n-0.0148135\n-0.0088416\n-0.0092517\n-0.0250078\n-0.0160655\n0.0166286\n-0.0414707\n-0.0176832\n-0.0125039\n-0.0250078\n-0.0197704\n-0.0250078\n0.0364300\n0.0331807\n-0.0330822\n0.0191867\n\n\n0.0149125\n-0.0283250\n-0.0126673\n-0.0444862\n-0.0103428\n0.0023441\n-0.0073135\n0.0865729\n0.0773724\n-0.0444862\n-0.0024017\n-0.0343033\n-0.0146270\n-0.0103428\n-0.0206857\n-0.0163535\n-0.0206857\n0.0280484\n-0.0407198\n-0.0273646\n0.0371130\n\n\n0.0381182\n-0.0333300\n-0.0149056\n-0.0135976\n-0.0121704\n-0.0123509\n-0.0086058\n-0.0058019\n-0.0243408\n-0.0523468\n0.0573758\n-0.0403646\n-0.0172115\n-0.0121704\n-0.0243408\n0.0861662\n-0.0243408\n0.0407749\n-0.0055815\n-0.0321998\n0.0216837\n\n\n-0.0648859\n-0.0351329\n-0.0157119\n-0.0184176\n-0.0128287\n0.0201080\n-0.0090713\n0.0163368\n0.0533995\n0.0183431\n-0.0220164\n-0.0425480\n-0.0181425\n-0.0128287\n0.0533995\n-0.0202840\n0.0533995\n0.0003888\n0.0298152\n-0.0339416\n0.1252960\n\n\n\n\n\n\n\nWeights on \\(E\\)\nWe standardize \\(E\\) as \\(E_{stand}\\), but we standardize so that the variables associated to the sites which have more observations have more weight. Therefore, we standardize \\(E\\) with the weights \\(y_{i\\cdot}/r\\).\n\nE_wt &lt;- rowSums(Y)/nrow(E)\n\nEstand &lt;- scalewt(E, wt = E_wt)\n\n\n\nCode\nknitr::kable(head(Estand))\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n-0.8940191\n-1.4578384\n-0.5429520\n-1.0404731\n1.0369741\n-1.0351817\n\n\n-0.8940191\n-1.3502706\n-0.5081483\n-0.3311255\n-0.4345644\n1.0954816\n\n\n-0.8940191\n0.8010856\n1.0902771\n0.3301082\n-1.3346326\n1.0954816\n\n\n-0.8940191\n0.7473017\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n-0.8940191\n0.6397339\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n-0.8940191\n1.1775730\n-0.6656140\n-1.0605165\n0.9946790\n-0.6293411\n\n\n\n\n\nConceptually, it is equivalent to using the inflated matrix \\(E_{infl}\\) to compute its mean \\(\\bar{E}_{infl}\\) and standard deviation \\(\\sigma(E_{infl})\\) per column. In \\(E_{infl}\\), the rows corresponding to each site are duplicates as many times as there are observations for this given site (so that \\(E_{infl}\\) is of dimension \\(y_{\\cdot \\cdot} \\times l\\)).\n\\[\nE_{stand} = \\frac{E - \\bar{E}_{infl}}{\\sigma(E_{infl})}\n\\]\nWith our data: first, we compute \\(E_{infl}\\):\n\n\nCode\nEinfl &lt;- matrix(data = 0,\n                ncol = ncol(E), \n                nrow = sum(Y))\ncolnames(Einfl) &lt;- colnames(E)\nrownames(Einfl) &lt;- 1:nrow(Einfl)\n\n# Get the number of times to duplicate each site\nnrep_sites &lt;- rowSums(Y)\n\nnrstart &lt;- 0\nfor (i in 1:nrow(E)) {\n  ri &lt;- as.matrix(E)[i, ]\n  \n  rname &lt;- rownames(E)[i]\n  \n  # Get how many times to duplicate this site\n  nr &lt;- nrep_sites[as.character(rname)]\n  \n  Einfl[(nrstart+1):(nrstart+nr), ] &lt;- matrix(rep(ri, nr), \n                                              nrow = nr, \n                                              byrow = TRUE)\n  \n  rownames(Einfl)[(nrstart+1):(nrstart+nr)] &lt;- paste(rname,\n                                                     1:nr,\n                                                     sep = \"_\")\n  nrstart &lt;- nrstart + nr\n}\n\npaste(\"Dimension of Einfl:\", paste(dim(Einfl), collapse = \" \"))\n\n\n[1] \"Dimension of Einfl: 493 6\"\n\n\nThen, we compute the mean and standard deviation per column and standardize \\(E\\).\n\n\nCode\nEinfl_mean &lt;- apply(Einfl, 2, mean)\n\nn &lt;- nrow(Einfl)\nEinfl_sd &lt;- apply(Einfl, 2, \n                  function(x) sd(x)*sqrt((n-1)/n))\n\n\n\n\nCode\nEstand2 &lt;- scale(E, \n                 center = Einfl_mean,\n                 scale = Einfl_sd)\n\nall(abs(Estand2/Estand - 1) &lt; zero)\n\n\n[1] TRUE\n\n\n\n\nRegression\nAfter that, we perform the weighted multiple linear regression of \\(P_0\\) by \\(E_{stand}\\). \\(P_0\\) is approximated by \\(\\hat{P_0}\\) using multiple linear regression on \\(E_{stand}\\): for each row, we can write \\(\\hat{p_{0i\\cdot}} = b_0 + b_1 e_{1\\cdot} + \\ldots + b_e e_{l\\cdot}\\), where \\(e_i\\) are columns of \\(E_{stand}\\) and \\(b_i\\) are regression coefficients.\nIn a matrix form, it is written:\n\\[\n\\hat{P_0} = D_r^{1/2}E_{stand}B\n\\]\nWhere\n\\[\nB = [E_{stand}^\\top D_r E_{stand}]^{-1}E_{stand}^\\top D_r^{1/2}P_0\n\\]\nWith our example:\n\n# Diagonal matrix weights\ndr &lt;- rowSums(P)\nDr &lt;- diag(dr)\ncolnames(Dr) &lt;- rownames(P)\n\n# Regression coefficient\nB &lt;- solve(t(Estand) %*% Dr %*% Estand) %*% t(Estand) %*% diag(dr^(1/2)) %*% P0\n\n# Compute predicted values\nP0hat &lt;- diag(dr^(1/2)) %*% Estand %*% B\ncolnames(P0hat) &lt;- colnames(P0)\nrownames(P0hat) &lt;- rownames(P0)\n\nNow, we can get the predicted values for \\(P_0\\). For instance, let’s plot predicted vs observed values for site 2:\n\n# Get predicted and observed values for one site\nind &lt;- 2\n\npred &lt;- P0hat[ind, ]\nobs &lt;- P0[ind, ]\n\n\n\nCode\ndf &lt;- data.frame(predicted = pred, \n                 observed = obs, \n                 names = names(pred))\ndf&lt;- df |&gt; \n  tidyr::pivot_longer(cols = c(\"predicted\", \"observed\"),\n                      names_to = \"type\")\n\nggplot(df, aes(x = reorder(names, value, decreasing = TRUE), \n               y = value, col = type, group = type)) +\n  geom_point() +\n  geom_line() +\n  theme_linedraw() +\n  ylab(\"Values of P0\") +\n  xlab(\"Species\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\nDiagonalization of \\(S_{\\hat{P_0}^\\top \\hat{P_0}}\\)\nThen, we diagonalize the covariance matrix of predicted values \\(S_{\\hat{P_0}^\\top \\hat{P_0}}\\).\nFirst, we compute the covariance matrix (note that here we don’t divide by the degrees of freedom).\n\\[\nS_{\\hat{P_0}^\\top \\hat{P_0}} = \\hat{P_0}^\\top \\hat{P_0}\n\\]\n\nSpp &lt;- t(P0hat) %*% P0hat\n\n\n\nCode\n# Covariance matrix of predicted P0 is equal to that\nSpe &lt;- t(P0hat) %*% diag(dr^(1/2)) %*% as.matrix(Estand)\nSee &lt;- t(Estand) %*% Dr %*% as.matrix(Estand)\nSpp2 &lt;- Spe %*% solve(See) %*% t(Spe)\n\nall(abs(Spp/Spp2 - 1) &lt; zero)\n\n\n[1] TRUE\n\n\nWe diagonalize \\(S_{\\hat{P_0}^\\top \\hat{P_0}}\\):\n\\[\nS_{\\hat{P_0}^\\top \\hat{P_0}} = V_0 \\Lambda V_0^{-1}\n\\]\n\\(\\Lambda\\) is the matrix of eigenvalues (there are \\(\\min(r-1, c, l)\\) non-null eigenvalues) and \\(V_0\\) contains the columns (species) loadings.\n\nneig &lt;- min(c(r-1, c, l))\n\nHere, \\(r-1 =\\) 25, \\(c =\\) 21 and \\(l =\\) 6 so the minimum (and the number of eigenvalues) is 6.\n\neig &lt;- eigen(Spp)\n\n(lambda &lt;- eig$values) # There are l = 6 non-null eigenvalues\n\n [1]  1.846574e-01  1.571586e-01  1.009501e-01  8.711508e-02  3.222443e-02\n [6]  1.476469e-02  9.276798e-18  8.416776e-18  2.476628e-18  1.422189e-18\n[11] -1.212603e-18 -1.597223e-18 -1.677170e-18 -2.007096e-18 -3.488219e-18\n[16] -3.614024e-18 -5.174948e-18 -5.675276e-18 -6.196745e-18 -6.258539e-18\n[21] -7.334976e-18\n\nlambda &lt;- lambda[1:neig]\n\nLambda &lt;- diag(lambda)\nV0 &lt;- eig$vectors[, 1:neig] # We keep only the eigenvectors\nrownames(V0) &lt;- colnames(Y)\n\nFinally, we can get the ordination of rows (sites) by projecting the observed values (matrix \\(P_0\\)) onto the axes defined by the diagonalization (\\(V_0\\)):\n\\[\nU_0 = P_0 V_0 \\Lambda^{-1/2}\n\\]\n\nU0 &lt;- P0 %*% V0 %*% diag(lambda^(-1/2))\nrownames(U0) &lt;- rownames(U0)\n\napply(U0, 2, varfacwt, wt = rowSums(P)) # Norm?\n\n[1] 0.06513814 0.06770504 0.08019396 0.07772885 0.12867946 0.10202597\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe rows loadings \\(U_0\\) are different from the loadings obtained by diagonalizing \\(S_{hat{P_0} \\hat{P_0}^\\top}\\) or performing the SVD of \\(\\hat{P_0}\\), because \\(U_0\\) does not contain the loadings of \\(\\hat{P_0}\\) but the loadings of \\(P_0\\).\n\n# This is not the same as diagonalizing S_ppt\nSppt &lt;- P0hat %*% t(P0hat)\neig2 &lt;- eigen(Sppt)\n\nall(abs(eig2$vectors[,1:neig]/U0 - 1) &lt; zero) # Eigenvectors are different\n\n[1] FALSE\n\n\n\n# We perform the SVD\nsv &lt;- svd(P0hat)\n\nall(abs(abs(sv$u[, 1:neig]/U0) - 1) &lt; zero) # Eigenvectors are different for U0\n\n[1] FALSE\n\nall(abs(abs(sv$v[, 1:neig]/V0) - 1) &lt; zero) # But they are the same for V0\n\n[1] TRUE\n\n\n\n# If U was computed as below (using the matrix of predicted values), it would give the same results as the diagonalization/SVD above (but it is not the case).\n\n# Compute rows loadings differently\nUhat &lt;- P0hat %*% V0 %*% diag(lambda^(-1/2))\n\nall(abs(abs(Uhat/eig2$vectors[,1:neig]) - 1) &lt; zero) # Eigenvectors are the same\n\n[1] TRUE\n\nall(abs(abs(sv$u[, 1:l]/eig2$vectors[,1:l]) - 1) &lt; zero) # Eigenvectors are the same\n\n[1] TRUE\n\n\n\n\n\n\nCompute \\(U\\) and \\(V\\)\nWe compute \\(U\\) and \\(V\\) as:\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U &= D_r^{-1/2} U_0\\\\\n  V &= D_c^{-1/2} V_0\\\\\n\\end{array}\n\\right.\n\\]\nFirst, we define the diagonal matrices with rows and columns weights (respectively \\(D_r\\) and \\(D_c\\)).\n\n# Define weights vectors and matrices\ndr &lt;- rowSums(P)\ndc &lt;- colSums(P)\n\nDr &lt;- diag(dr)\nDc &lt;- diag(dc)\n\n\n# Sites\nU &lt;- diag(dr^(-1/2)) %*% U0\n  \n# Species\nV &lt;- diag(dc^(-1/2)) %*% V0\n\n\napply(U, 2, varfacwt, wt = dr)/lambda # variance larger than lambda, because it contains the residuals of P0hat as well!!\n\n[1]   7.244385   9.261437  14.814747  19.935957  96.297789 180.619015\n\napply(V, 2, varfacwt, wt = dc) # variance is one\n\n[1] 1 1 1 1 1 1"
  },
  {
    "objectID": "CCA.html#scaling",
    "href": "CCA.html#scaling",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Scaling",
    "text": "Scaling\n\n\n\n\n\n\nTL;DR\n\n\n\nAs with CA, we have scalings type 1, 2 and 3. There are 2 differences with CA:\n\nFor the sites, we have 3 types of scores: the predicted sites scores \\(Z\\) (LC scores), computed from the regression, the “observed” sites scores \\(U\\) computed from the observed data matrix, and the weighted averages \\(U^\\star\\) (WA scores), computed from the species scores.\nThere are also scalings for the correlations of the explanatory variables with the axes.\n\nScaling type 1 (\\(\\alpha = 1\\))\n\nWA scores for rows (sites): \\(U^\\star = U \\Lambda^{1/2}\\) (ls)\nLC scores for rows (sites): \\(Z_1 = D_r^{-1/2} \\hat{P_0} V_0\\) (li)\nColumns (species) scores: \\(V = D_c^{-1/2} V_0\\) (c1)\nVariables scores: \\(BS_1 = E_{stand}^\\top D_r Z_{stand} \\Lambda^{1/2}\\)\n\nScaling type 2 (\\(\\alpha = 0\\))\n\nWA scores for rows (sites): \\(U = D_r^{-1/2} U_0\\) (not computed by ade4: sort of ls1, but variance not normed to one)\nLC scores for rows (sites): \\(Z_2 = D_r^{-1/2}\\hat{P_0} V_0 \\Lambda^{-1/2}\\) (l1)\nColumns (species) scores: \\(V^\\star = V \\Lambda^{1/2}\\) (co)\nVariables scores: \\(BS_2 = E_{stand}^\\top D_r Z_{stand}\\)\n\nScaling type 3 (\\(\\alpha = 1/2\\))\n\nWA scores for rows (sites): \\(\\hat{S}_3 = U \\Lambda^{1/4}\\)\nLC scores for rows (sites): \\(Z_3 = D_r^{-1/2}\\hat{P_0} V_0 \\Lambda^{-1/4}\\)\nColumns (species) scores: \\(S_3 = V \\Lambda^{1/4}\\)\nVariables scores: \\(BS_3 = E_{stand}' D_r Z_{stand}\\Lambda^{1/4}\\)\n\n\\(V^\\star\\) (columns/species) and \\(U^\\star\\) (rows/sites) correspond to weighted averagings, and cab be computed from \\(U\\) (rows/sites) (resp. \\(V\\) (columns/species)). See Equation 1 and Equation 2 below.\nHow to find the fa (i.e. correlation coefficients for each environmental variable in the multivariate space)??\n\n\nLet’s compute CCA with ade4 to compare results.\n\nca &lt;- dudi.coa(Y, \n               nf = c-1, \n               scannf = FALSE)\ncca &lt;- pcaiv(dudi = ca, \n             df = E,\n             scannf = FALSE,\n             nf = neig)\n\nlambda[1:neig]/cca$eig # Eigenvalues are the same as computed manually\n\n[1] 1 1 1 1 1 1\n\n\n\nPre-computations\nThe scores for the explanatory variables are computed from matrix \\(Z_{stand}\\): so we first need to standardize \\(Z\\) into \\(Z_{stand}\\) (the computation can involve \\(Z_1\\), \\(Z_2\\) or \\(Z_3\\) (defined below) and give the same result).\n\\(Z_1\\), \\(Z_2\\) or \\(Z_3\\) are defined as some variation of:\n\\[Z_i = D_r^{-1/2} \\hat{P}_0 V_0 \\Lambda^\\alpha\\] where \\(\\alpha\\) is an exponent equal to 0, -1/2 or -1/4. This equation corresponds to the projection of the predicted data matrix \\(\\hat{P}_0\\) onto the multivariate space.\n\n# Compute Z1\nZ1 &lt;- diag(dr^(-1/2)) %*% P0hat %*% V0\n\napply(Z1, 2, varfacwt)\n\n[1] 0.17463933 0.17429419 0.09984546 0.08291203 0.03437735 0.01521229\n\nZ_wt &lt;- E_wt\nZstand &lt;- scalewt(Z1, wt = Z_wt)\n\nIt is the same as computing with the inflated matrix (below):\n\n\nCode\n# Compute inflated matrix ------\nZinfl &lt;- matrix(data = 0,\n                ncol = ncol(Z1), \n                nrow = sum(Y))\nrownames(Zinfl) &lt;- 1:nrow(Zinfl)\n# Give names to Z1\nrownames(Z1) &lt;- rownames(Y)\n\n# Get the number of times to duplicate each site\nnrep_sites &lt;- rowSums(Y)\n\nnrstart &lt;- 0\nfor (i in 1:nrow(Z1)) {\n  ri &lt;- Z1[i, ]\n  \n  rname &lt;- rownames(Z1)[i]\n  \n  # Get how many times to duplicate this site\n  nr &lt;- nrep_sites[as.character(rname)]\n  \n  Zinfl[(nrstart+1):(nrstart+nr), ] &lt;- matrix(rep(ri, nr), \n                                              nrow = nr, \n                                              byrow = TRUE)\n  \n  rownames(Zinfl)[(nrstart+1):(nrstart+nr)] &lt;- paste(rname, \n                                                     1:nr, \n                                                     sep = \"_\")\n  nrstart &lt;- nrstart + nr\n}\n\n# Compute mean/sd ------\nZinfl_mean &lt;- apply(Zinfl, 2, mean)\n\nn &lt;- nrow(Zinfl)\nZinfl_sd &lt;- apply(Zinfl, 2, \n                  function(x) sd(x)*sqrt((n-1)/n))\n\n# Compute Zstand ------\nZstand2 &lt;- scale(Z1, \n                 center = Zinfl_mean,\n                 scale = Zinfl_sd)\n\nall(abs(Zstand2/Zstand - 1) &lt; zero)\n\n\n[1] TRUE\n\n\n\n\nScaling type 1\nHere, \\(\\chi^2\\) distances between rows (sites) are preserved they are positioned at the centroid of species.\n\nthe rows (sites) scores can be positioned by averaging: \\(U^\\star = U \\Lambda^{1/2}\\) (ls) or by predicted positions \\(Z_1 = D_r^{-1/2} \\hat{P_0} V_0\\) (li)\nthe columns (species) scores are positioned at variance 1 \\(V = D_c^{-1/2} V_0\\) (c1)\nthe explanatory variable score are \\(BS_1 = E_{stand}^\\top D_r Z_{stand}\\Lambda^{1/2}\\)\n\n\n# Rows WA scores\nUstar &lt;- U %*% diag(lambda^(1/2))\n\n# Variables correlation\nBS1 &lt;- t(Estand) %*% Dr %*% Zstand %*% sqrt(Lambda)\n\nIf we compare to the results obtained with ade4, we can see what each score corresponds to.\n\nall(abs(abs(Z1/cca$li) - 1) &lt; zero) # Predicted sites scores\n\n[1] TRUE\n\nall(abs(abs(Ustar/cca$ls) - 1) &lt; zero) # Averaging sites scores\n\n[1] TRUE\n\nall(abs(abs(V/cca$c1) - 1) &lt; zero) # Variance 1 species scores\n\n[1] TRUE\n\n# What does the BS1 correspond to?\nres &lt;- as.matrix(cca$cor)/(BS1 %*% diag(lambda^(-1/2)) )\nall(abs(abs(res) - 1) &lt; zero)\n\n[1] TRUE\n\n\nWe know that \\(V\\)/c1 is of variance 1 (computed above). Below we show that \\(Z_1\\)/li is of variance \\(\\lambda\\) and try to get the variance of \\(U^\\star\\)/ls.\n\n# The CCA weights can be recovered from data (modulo a constant)\ncca$lw/E_wt\n\n         1          2          3          4          5          6          7 \n0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 \n         8          9         10         11         12         13         14 \n0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 \n        15         16         17         18         19         20         21 \n0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 \n        22         23         24         25         26 \n0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 \n\ncca$cw/(colSums(Y)/ncol(Y))\n\n       sp1        sp2        sp3        sp4        sp5        sp6        sp7 \n0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 \n       sp8        sp9       sp10       sp11       sp12       sp13       sp14 \n0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 \n      sp15       sp16       sp17       sp18       sp19       sp21       sp22 \n0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 \n\n\n\napply(Z1, 2, varwt, wt = cca$lw)/cca$eig # Z1 variance = eigenvalues\n\n[1] 1 1 1 1 1 1\n\napply(Ustar, 2, varwt, wt = cca$lw)\n\n[1] 0.24702157 0.22874662 0.15097579 0.15129471 0.09999697 0.03937424\n\n\n\nWeighted averaging\nSimilarly to the CA case, \\(U^\\star\\) (sites coordinates) can be obtained from species coordinates, weighted by the observed data matrix:\n\\[\nU^\\star = \\left\\{\n\\begin{array}{ll}\n  D_r^{-1/2} P_0 V_0 \\qquad &\\text{(from } V_0 \\text{)}\\\\\n  D_r^{-1/2} P_0 D_c^{1/2} V \\qquad &\\text{(from } V \\text{)}\\\\\n   D_r^{-1} P V \\qquad &\\text{(from } V \\text{ and } P \\text{)}\\\\\n\\end{array}\n\\right.\n\\tag{1}\\]\n\n# With V0\nUstar_wa &lt;- diag(dr^(-1/2)) %*% P0 %*% V0\nres &lt;- Ustar_wa/Ustar\nall(res[, 1:neig] - 1 &lt; zero)\n\n[1] TRUE\n\n# With V\nUstar_wa_V &lt;- diag(dr^(-1/2)) %*% P0 %*% diag(dc^(1/2)) %*% V\nres &lt;- Ustar_wa_V/Ustar\nall(res[, 1:neig] - 1 &lt; zero)\n\n[1] TRUE\n\n# With V and P\nUstar_wa_legendre &lt;- diag(dr^(-1)) %*% P %*% V\nres &lt;- Ustar_wa_legendre/Ustar\nall(res[, 1:neig] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nPlots\nIn these plots, we use \\(V\\)/c1 for species coordinates.\nFor sites, we can plot the predicted scores for sites (LC scores = \\(Z_1\\)/li):\n\n\nCode\nmult &lt;- 10\n\n# LC scores\nmultiplot(indiv_row = Z1, indiv_col = V, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS1, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"LC scores for sites and species\\nnormed at 1\")\n\n\n\n\n\n\n\nCode\ns.label(cca$c1, # Species constrained at variance 1\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        main = \"LC scores for sites and species\\nnormed at 1\")\ns.label(cca$li, # Predicted sites scores\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        add = TRUE)\n\n\n\n\n\nWe can also plot the WA scores for sites (\\(U^\\star\\)/ls):\n\n\nCode\n# WA scores\nmultiplot(indiv_row = Ustar, indiv_col = V, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS1, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"WA scores for sites and species\\nnormed at 1\")\n\n\n\n\n\n\n\nCode\ns.label(cca$c1, # Species constrained at variance 1\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        main = \"WA scores for sites and species\\nnormed at 1\")\ns.label(cca$ls, # WA sites scores\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        add = TRUE)\n\n\n\n\n\n\n\n\nScaling type 2\nHere, \\(\\chi^2\\) distances between columns (species) are preserved they are positioned at the centroid of sites.\n\nthe rows (sites) scores can be \\(U = D_r^{-1/2} U_0\\) (variance 1) or \\(Z_2 = D_r^{-1/2} \\hat{P_0} V_0 \\Lambda^{-1/2}\\) (l1) (predicted sites scores)\nthe columns (species) scores are \\(V^\\star = V \\Lambda^{1/2}\\) (co) (WA scores from sites latent ordination)\nthe explanatory variable score are \\(BS_2 = E_{stand}^\\top D_r Z_{stand}\\)\n\n\n# Row predicted scores\nZ2 &lt;- diag(dr^(-1/2)) %*% P0hat %*% V0 %*% diag(lambda^(-1/2))\n\n# Columns WA scores\nVstar &lt;- V %*% Lambda^(1/2)\n\n# Variables correlation\nBS2 &lt;- t(Estand) %*% Dr %*% Zstand\n\nIf we compare to the results obtained with ade4, we can see what each score corresponds to.\n\nall(abs(abs(Z2/cca$l1) - 1) &lt; zero) # Predicted sites scores of variance 1\n\n[1] TRUE\n\n# U is not computed by ade4 so we compute it from ls (corresponding to Ustar)\nls1_ade4 &lt;- as.matrix(cca$ls) %*% diag(lambda^(-1/2))\nall(abs(abs(ls1_ade4/U) - 1) &lt; zero)\n\n[1] TRUE\n\nall(abs(abs(Vstar/cca$co) - 1) &lt; zero) # Averaging column scores\n\n[1] TRUE\n\nall(abs(abs(cca$cor/BS2) - 1) &lt; zero) # Variables correlations\n\n[1] TRUE\n\n\nBelow we show that \\(V^\\star\\)/co is of variance \\(\\lambda\\), \\(Z_2\\)/l1 is of variance 1 and try to get the variance of \\(U\\)/ls1.\n\napply(Vstar, 2, varwt, wt = cca$cw)/cca$eig # Vstar variance = eigenvalues\n\n[1] 1 1 1 1 1 1\n\napply(Z2, 2, varwt, wt = cca$lw) # Z variance = 1\n\n[1] 1 1 1 1 1 1\n\napply(ls1_ade4, 2, varwt, wt = cca$lw) # ?\n\n[1] 1.337729 1.455514 1.495549 1.736722 3.103141 2.666784\n\n\n\nWeighted averaging\n\\(V^\\star\\) (species coordinates) can be obtained from sites coordinates, weighted by the predicted data matrix. Contrary to the CA case, sites coordinates are not weighted by \\(P_0\\) (observed) but by \\(\\hat{P}_0\\) (predicted):\n\\[\nV^\\star = \\left\\{\n\\begin{array}{ll}\n  D_c^{-1/2} \\hat{P}_0^\\top U_0 \\qquad &\\text{(from } U_0 \\text{)}\\\\\n  D_c^{-1/2} \\hat{P}_0^\\top D_r^{1/2} U \\qquad &\\text{(from } U \\text{)}\n\\end{array}\n\\right.\n\\tag{2}\\]\n\n# U0\nVstar_wa &lt;- diag(dc^(-1/2)) %*% t(P0hat) %*% U0\nres &lt;- Vstar_wa/Vstar\nall(res[, 1:neig] - 1 &lt; zero)\n\n[1] TRUE\n\nVstar_wa_U &lt;- diag(dc^(-1/2)) %*% t(P0hat) %*% diag(dr^(1/2)) %*% U\nres &lt;- Vstar_wa_U/Vstar\nall(res[, 1:neig] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nPlots\nIn these plots, we always use WA scores (\\(V^\\star\\)/co) for the columns.\nWe can plot the columns WA scores (\\(V^\\star\\)/co) with the predicted scores for sites (LC scores) (\\(Z_2\\)/l1):\n\n\nCode\nmult &lt;- 1\n\n# LC scores\nmultiplot(indiv_row = Z2, indiv_col = Vstar, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS2, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"Specis WA scores with\\nsites LC scores of variance 1\")\n\n\n\n\n\n\n\nCode\ns.label(cca$l1, # Predicted sites scores of variance 1\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        main = \"Specis WA scores with\\nsites LC scores of variance 1\")\ns.label(cca$co, # Species WA\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        add = TRUE)\n\n\n\n\n\nCode\ns.corcircle(cca$cor)\n\n\n\n\n\nWe can also plot columns WA scores (\\(V^\\star\\)/co) with the sites observed scores (\\(U\\)/“ls1” (not computed by ade4)):\n\n\nCode\n# WA scores\nmultiplot(indiv_row = U, indiv_col = Vstar, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS2, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"Specis WA scores with\\nsites observed scores of variance 1\")\n\n\n\n\n\nade4 does not compute the sites observed scores normed at 1 (corresponding to \\(U\\)), so we compute them as \\(\\text{ls1} = \\text{ls} \\Lambda^{-1/2}\\):\n\n\nCode\nas.matrix(cca$ls) %*% diag(lambda^(-1/2))\n\n\n          [,1]        [,2]        [,3]        [,4]        [,5]         [,6]\n1  -0.88194233 -0.89920813 -0.21510290 -0.75716763 -3.36433191  5.943824594\n2   2.42444621 -0.30829774 -3.35321943  0.55963296  2.02916596  2.065563431\n3  -0.34444473 -0.54181178 -0.08013664  0.57546029 -0.80398947  0.006814482\n4   0.01419785 -1.26123684  1.34364884  1.79619359  1.59088842  1.764336111\n5   0.04325107 -0.64051246  0.03049116  1.11682527 -0.74470162  1.355608210\n6   0.71217106 -1.08445507  0.05021373  0.26782893  0.82751939 -1.185111342\n7   1.35808644 -0.32688745  1.36849015 -0.06717237  1.40265285 -1.169991512\n8   1.13927090  1.87131126  0.51489605  1.22937814 -1.90204431 -1.972136233\n9   0.18631749 -0.69064739  1.56174573  0.49605602 -1.54800058 -1.044143121\n10  1.24074453 -0.88393142  1.11709208 -1.88081630 -1.87523745  0.694839896\n11  1.17040343 -1.40649896 -1.45445191  0.15749382 -0.70665751 -1.226713778\n12  0.87979967  0.19023028  1.61346288 -0.66352718 -0.77675967 -1.410272996\n13  0.53426380  3.36712361  1.01348658 -1.59561837  1.77100897  1.536210292\n14 -1.42844996  0.48874250 -0.51552864  0.83759576 -1.39780352 -0.793502333\n15 -0.30279177  2.40395635 -0.90288926 -0.17353516  3.64804877  0.066157822\n16 -0.80715875 -0.15220790 -0.00359762  1.08059321  0.72058755  2.171252757\n17 -0.62521546 -1.10958406  0.42720293  0.71161391 -0.28552526  2.455843219\n18 -1.12871615 -0.45121491  0.52408704  1.79661165 -0.46072861  0.013919785\n19 -1.32962334 -0.02131165  0.22268095 -1.76305566  2.21983155 -0.645198949\n20 -0.71010429 -0.50179403  0.79488259  1.57807386  1.63438894 -2.298299831\n21 -1.49191348  0.43981741 -0.22249008  1.27068234 -1.31901558 -0.764324772\n22 -0.92914770 -0.56566757  0.17354832  0.51597625  0.01408031 -0.288080450\n23 -1.18010511 -0.17836577 -0.02322108 -2.68084807  3.05668242  0.997011359\n24 -1.71254285  0.11121758 -1.76025623 -2.07277698 -1.45573752 -2.393217624\n25 -0.79823857  1.75933428 -0.09999050  0.83358035 -3.48847449 -0.953485788\n26 -0.85502843  1.92516632  0.29281684  1.85795073 -2.41935625 -0.211052481\n\n\nCode\ns.label(ls1_ade4, # Sites WA scores U\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        main = \"Specis WA scores with\\nsites observed scores of variance 1\")\ns.label(cca$co, # Species WA\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        add = TRUE)\n\n\n\n\n\n\n\n\nScaling type 3\nThis type of scaling is a compromise between scalings type 1 and 2.\n\nthe rows (sites) scores can be \\(\\hat{S}_3 = U \\Lambda^{1/4}\\) or \\(Z_3 = D_r^{-1/2} \\hat{P_0} V_0 \\Lambda^{-1/4}\\)\nthe columns (species) scores are \\(S_3 = V \\Lambda^{1/4}\\)\nthe explanatory variable score are \\(BS_3 = E_{stand}^\\top D_r Z_{stand} \\Lambda^{1/4}\\)\n\n\n# Row scores\nShat3 &lt;- U %*% Lambda^(1/4) # Latent scores\nZ3 &lt;- diag(dr^(-1/2)) %*% P0hat %*% V0 %*% diag(lambda^(-1/4)) # Predicted scores\n\n# Columns scores\nS3 &lt;- V %*% Lambda^(1/4)\n\n# Variables correlation\nBS3 &lt;- t(Estand) %*% Dr %*% Zstand %*% Lambda^(1/4)\n\nThe corresponding ade4 values are not computed, but we can compute them:\n\nZ3_ade4 &lt;- as.matrix(cca$l1) %*% diag(cca$eig^(1/4))\nShat3_ade4 &lt;- ls1_ade4 %*% diag(cca$eig^(1/4))\nS3_ade4 &lt;- as.matrix(cca$c1) %*% diag(cca$eig^(1/4))\n\n\nall(abs(abs(Z3_ade4/Z3) - 1) &lt; zero) # LC scores for sites\n\n[1] TRUE\n\nall(abs(abs(Shat3_ade4/Shat3) - 1) &lt; zero) # sites scores\n\n[1] TRUE\n\nall(abs(abs(S3_ade4/S3) - 1) &lt; zero) # species scores\n\n[1] TRUE\n\n\n\n\nPlots\n\n\nCode\n# LC scores\nmultiplot(indiv_row = Z3, indiv_col = S3, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS3, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\n\n\n\n\n\ns.label(Z3_ade4,\n        plabels.optim = TRUE,\n        xlim = c(-3, 2),\n        ylim = c(-2, 3),\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite)\ns.label(S3_ade4,\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        add = TRUE)\n\n\n\n\n\n\nCode\nmult &lt;- 5\n\nmultiplot(indiv_row = Shat3, indiv_col = S3, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS3, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"Sites latent scores\")\n\n\n\n\n\n\ns.label(Shat3_ade4,\n        plabels.optim = TRUE,\n        xlim = c(-3, 2),\n        ylim = c(-2, 3),\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite)\ns.label(S3_ade4,\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        add = TRUE)"
  },
  {
    "objectID": "CCA.html#interpretation",
    "href": "CCA.html#interpretation",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Interpretation",
    "text": "Interpretation\nIn CCA, each ordination axis corresponds to a linear combination of the explanatory variables that maximizes the explained variance in the response data.\nThis analysis constrains rows (sites) scores to be linear combinations of the environmental variables (scaling \\(Z_i\\)).\nSpecies can be ordered along environmental variables axes by projecting species coordinates on the vector of this variable. This gives species niche optimum, but there are strong assumptions:\n\nunimodal distribution of niches preferences along the variable of interest\nspecies distributions are indeed controlled by the environment\nthe study gradient is long enough to capture the range of species abundance variation.\n\nThe part of variation explained by the environmental variables can be computed as\n\\[\n\\frac{\\sum_k \\lambda_k(CCA)}{\\sum_l \\lambda_l(CA)}\n\\]\n\nsum(lambda)/sum(ca$eig)\n\n[1] 0.3795835\n\n\nHere, the environmental variables explain 38 % of the total variation.\nWarning: in CCA, using noisy or not relevant explanatory variables leads to spurious relationships.\n\nResidual analysis\nIn order to examinate residuals, a CA can be performed on the table of residuals \\(P_{\\text{res}}\\):\n\\[\nP_{\\text{res}} = P_0 - \\hat{P}_0\n\\]\n\nPres &lt;- P0 - P0hat\n\nres_pca &lt;- dudi.pca(Pres, scannf = FALSE, nf = 27)\n\nscatter(res_pca)\n\n\n\n\n\n\nTests of significance\nIt is possible to test the significance of the the relationship between \\(E\\) and \\(Y\\) with a permutation test.\n\nrandtest(cca, nrepet = 999)\n\nMonte-Carlo test\nCall: randtest.pcaiv(xtest = cca, nrepet = 999)\n\nObservation: 0.3795835 \n\nBased on 999 replicates\nSimulated p-value: 0.001 \nAlternative hypothesis: greater \n\n    Std.Obs Expectation    Variance \n3.655831097 0.269413646 0.000908141"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "This website aims at summarizing the theory behind different methods to analyze count data:\nIt also describes reciprocal scaling (Thioulouse and Chessel 1992) (and its extensions with CCA and dc-CA). Reciprocal scaling is a method to compute and visualize the dispersion among count tables analyzed with multivariate methods."
  },
  {
    "objectID": "index.html#dataset",
    "href": "index.html#dataset",
    "title": "Introduction",
    "section": "Dataset",
    "text": "Dataset\nThroughout this document, we will use the data from Barbaro et al. (2012) on bird species distribution in New Zealand extracted from the CESTES database (Jeliazkov et al. 2020).\nThroughout this document, we will analyze a matrix \\(Y\\) (\\(r \\times c\\)) and two associated matrices \\(E\\) (\\(r \\times e\\)) and \\(T\\) (\\(t \\times c\\)). In our example:\n\n\\(Y\\) (\\(r =\\) 26 \\(\\times\\) \\(c =\\) 21) represents bird species counts in different sites\n\\(E\\) (\\(r =\\) 26 \\(\\times\\) \\(l =\\) 6) represents environmental variables in different sites\n\\(T\\) (\\(c =\\) 21 \\(\\times\\) \\(k =\\) 7) represents bird species traits"
  },
  {
    "objectID": "CA.html",
    "href": "CA.html",
    "title": "Correspondence analysis (CA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\nlibrary(CAnetwork)\nlibrary(patchwork)\n\n# Matrix algebra\nlibrary(expm)\nCode\n# Define bound for comparison to zero\nzero &lt;- 10e-10\nThe contents of this page relies heavily on Legendre and Legendre (2012)."
  },
  {
    "objectID": "CA.html#introduction",
    "href": "CA.html#introduction",
    "title": "Correspondence analysis (CA)",
    "section": "Introduction",
    "text": "Introduction\nCorrespondence analysis (CA) was developed independently by several authors between the 1930s and 1960s. It has been mainly applied to analysis of ecological data tables (species \\(\\times\\) environment) such as the data we will analyze here.\nNotably, Hill discovered it in 1973 with an iterative method that he called reciprocal averaging. It involves ordering species with sites initially positioned randomly, reciprocally order sites with species, etc. This iterative procedure converges to reach the same results as what is achieved with CA’s first axis.\nCA is designed to analyze contingency tables (count tables) such \\(Y\\):\n\n\n\n\n\nHere, \\(Y\\) represents the abundance of different bird species (columns) at different sites (rows) in New Zealand.\nHere is a preview of \\(Y\\) with our example dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n4\n0\n0\n0\n0\n2\n0\n4\n0\n2\n0\n4\n0\n0\n0\n0\n1\n5\n0\n0\n2\n\n\n2\n0\n0\n1\n0\n2\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n5\n1\n5\n1\n\n\n4\n0\n0\n0\n0\n0\n0\n2\n0\n0\n3\n0\n0\n0\n0\n0\n1\n1\n0\n0\n1\n\n\n2\n0\n1\n5\n0\n0\n0\n5\n0\n1\n1\n4\n0\n0\n0\n1\n2\n2\n0\n0\n2\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n2\n0\n0\n0\n4\n0\n1\n10\n3\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n4\n0\n2\n2\n4\n0\n0\n0\n0\n2\n1\n2\n0\n1\n\n\n5\n5\n0\n0\n1\n1\n0\n1\n0\n3\n0\n5\n0\n0\n0\n0\n0\n0\n1\n5\n1\n\n\n4\n0\n0\n1\n0\n2\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n3\n0\n0\n0\n1\n0\n0\n0\n0\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n5\n0\n4\n0\n1\n2\n0\n0\n0\n0\n0\n0\n1\n2\n0\n0\n\n\n4\n0\n1\n1\n0\n1\n0\n3\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n1\n0\n3\n2\n1\n2\n0\n0\n0\n0\n0\n0\n1\n3\n0\n0\n\n\n4\n2\n0\n1\n0\n0\n0\n2\n0\n2\n2\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n4\n0\n0\n1\n0\n2\n0\n2\n2\n2\n1\n1\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n4\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n5\n1\n0\n3\n0\n2\n0\n2\n1\n0\n2\n0\n0\n0\n0\n0\n0\n3\n1\n0\n0\n\n\n3\n5\n0\n4\n0\n2\n0\n5\n0\n4\n2\n0\n0\n1\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n2\n0\n7\n0\n1\n1\n0\n0\n4\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n6\n0\n0\n2\n0\n1\n0\n0\n0\n1\n3\n0\n0\n0\n0\n0\n0\n0\n3\n3\n0\n\n\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n\nMore generally, CA can be used to analyze tables which are dimensionally homogeneous and contain no negative values.\nCA preserves \\(\\chi^2\\) distances \\(D\\) between rows and columns of the contingency table:\n\\[\nD(x_1, x_2) = \\sqrt{\\sum_{j = 1}^p \\frac{1}{y_{\\cdot j}/y_{\\cdot \\cdot}}\\left(\\frac{y_{1j}}{y_{1\\cdot}} -  \\frac{y_{2j}}{y_{2\\cdot}}\\right)^2}\n\\]\nWhere \\(x_1\\) and \\(x_2\\) represent two items of the rows/columns. \\(p\\) is the number of rows (if \\(x_1\\) and \\(x_2\\) are items of columns) or columns else.\n\\(y_{\\cdot j}\\) represent either:\n\nif \\(x_1\\) and \\(x_2\\) are items of the columns: the sum of the \\(j\\)-th row. For a species x environment table, it is the total number of individuals in the \\(j\\)-th site.\nif \\(x_1\\) and \\(x_2\\) are items of the rows: the sum of the \\(j\\)-th column. For a species x environment table, it is the total number of individuals of the \\(j\\)-th species.\n\n\\(y_{\\cdot \\cdot}\\) is the sum of all individuals of the table.\n\\(\\frac{y_{1j}}{y_{1\\cdot}}\\) are relative frequencies of individuals per rows (if \\(x_1\\) and \\(x_2\\) are items of the rows) or columns.\nFor example, we compute the \\(\\chi^2\\) distance between sp1 and sp2:\n\n# Get total number of individuals in all sites\nytot &lt;- sum(Y)\n\n# Get how much each site contributed to the total count of species\ny_j &lt;- apply(Y, 2, FUN = function(x) x/sum(x))\n\nsqrt( sum(1/(rowSums(Y)/ytot)*(y_j[, \"sp1\"] - y_j[, \"sp2\"])^2 ) )\n\n[1] 2.090546\n\n\nAnd between sites 1 and 2:\n\n# Get the relative composition of species for each site\nyi_ &lt;- t(apply(Y, 1, FUN = function(x) x/sum(x)))\n\nsqrt( sum(1/(colSums(Y)/ytot)*(yi_[\"1\",] - yi_[\"2\", ])^2 ) )\n\n[1] 2.563363"
  },
  {
    "objectID": "CA.html#computation",
    "href": "CA.html#computation",
    "title": "Correspondence analysis (CA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nGiven a data matrix \\(Y\\), we “center-scale” this matrix (\\(P_0\\)).\nWe can perform the SVD of \\(P_0\\):\n\\[\nP_0 = U_0 \\Delta V_0^\\top\n\\]\n\\(V_0\\) (\\(c \\times c\\)) contains the loadings of the columns (species) of the contingency table.\n\\(U_0\\) (\\(r \\times c\\)) contains the loadings of the rows (sites) of the contingency table.\nThere are \\(k = \\min(c-1, r-1)\\) non-null eigenvalues. The CA eigenvalues are the squares of the SVD eigenvalues: \\(\\Lambda = \\Delta^2\\).\nAlso, there is a link between \\(U_0\\) and \\(V_0\\) given by the following transition formulae:\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U_0 &= P_0 V_0 \\Lambda^{-1/2}\\\\\n  V_0 &= P_0^\\top U_0 \\Lambda^{-1/2}\\\\\n\\end{array}\n\\right.\n\\]\nFinally, we define the following transformations of \\(U_0\\) and \\(V_0\\) (that have variance 1 and correspond to l1 and c1):\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U &= D_r^{-1/2} U_0\\\\\n  V &= D_c^{-1/2} V_0\\\\\n\\end{array}\n\\right.\n\\]\n\n\nLet’s perform a CA with ade4 to check results later.\n\nca &lt;- dudi.coa(Y, \n               scannf = FALSE, \n               nf = min(r, c))\n\n\nTransform the table\nWe transform values of the contingency table \\(Y\\) with counts \\(y_{ij}\\) into proportions \\(p_{ij}\\):\n\\[\nP = Y/y_{\\cdot \\cdot}\n\\]\nWith our example data:\n\nP &lt;- Y/sum(Y)\n\nThen we transform values of this table into a quantity related to \\(\\chi^2\\) values \\(P_0\\):\n\\[\nP_0 = [p_{0ij}] = \\left[ \\frac{p_{ij} - p_{i\\cdot} p_{\\cdot j}}{\\sqrt{p_{i\\cdot} p_{\\cdot j}}} \\right]\n\\]\n\n# Initialize P0 matrix\nP0 &lt;- matrix(ncol = ncol(Y), nrow = nrow(Y))\ncolnames(P0) &lt;- colnames(Y)\nrownames(P0) &lt;- rownames(Y)\n\nfor(i in 1:nrow(Y)) { # For each row\n  for (j in 1:ncol(Y)) { # For each column\n    # Do the sum\n    pi_ &lt;- sum(P[i, ])\n    p_j &lt;- sum(P[, j])\n    \n    # Compute the transformation\n    P0[i, j] &lt;- (P[i, j] - (pi_*p_j))/sqrt(pi_*p_j)\n  }\n}\n\nWe could also do this by matrix multiplication:\n\\[\nP_0 = D_r^{-1/2} (P - p_{i\\cdot} p_{\\cdot j}^\\top) D_c^{-1/2}\n\\]\nwhere \\(p_{i\\cdot}\\) and \\(p_{\\cdot j}\\) are the rows and columns sums vectors (respectively) and \\(D_r\\) and \\(D_c\\) are the associated diagonal matrices (respectively).\n\n# Define weights matrices\nDr &lt;- diag(rowSums(P))\nDc &lt;- diag(colSums(P))\n\n# Also define a variable for just the sums for easier manipulation\ndr &lt;- rowSums(P)\ndc &lt;- colSums(P)\n\n# Compute P0 with this computation\nP0_mat &lt;- diag(dr^(-1/2)) %*% (P - (dr %*% t(dc))) %*% diag(dc^(-1/2)) \n\nall((P0_mat/P0 - 1) &lt; zero) # It works\n\n[1] TRUE\n\n\nThe \\(p_{0ij}\\) values are equal to the \\(\\chi\\) values, a constant apart: \\(p_{0ij} = \\chi_{ij}/\\sqrt{y_{\\cdot \\cdot}}\\).\n\n\nSingular value decomposition of \\(P_0\\)\nWe perform the SVD of \\(P_0\\):\n\\[\nP_0 = U \\Delta V_0^\\top\n\\]\nWhere \\(P_0\\) is \\(r \\times c\\), \\(U_0\\) is \\(r \\times c\\), \\(\\Delta\\) is a \\(c \\times c\\) diagonal matrix (assuming \\(r \\geq c\\); the table can be transposed to meet this condition) and \\(V_0\\) is \\(c \\times c\\).\nNote that the last eigenvalue of this SVD will always be null (due to the centering).\n\nsv &lt;- svd(P0)\n\n# Eigenvalues\ndelta &lt;- sv$d # Last eigenvalue is zero\nlambda &lt;- delta^2\nLambda &lt;- diag(lambda)\n\n# Define the number of non-null eigenvalues\nk &lt;- min(c-1, r-1)\n\n# Eigenvectors\nU0 &lt;- sv$u\nV0 &lt;- sv$v\n\n\nSVD as a diagonalization\nThis SVD is equivalent to a diagonalization: with the SVD, we can rewrite \\(P_0^\\top P_0\\):\n\\[\nP_0^\\top P_0 = V_0 \\Delta^\\top U_0^\\top U_0 \\Delta V_0^\\top\n\\]\nWe have \\(U_0^\\top U_0 = I\\) (because \\(U_0\\) is orthonormal), so:\n\\[\nP_0^\\top P_0 =  V_0 \\Delta^\\top \\Delta V_0^\\top\n\\]\nIf we rewrite \\(\\Delta^\\top \\Delta\\) as \\(\\Lambda\\) (so \\(\\Delta = \\Lambda^{1/2}\\)), and since \\(V_0^\\top = V_0^{-1}\\) (\\(V_0\\) is orthonormal), then we can write this as a diagonalization:\n\\[\nP_0^\\top P_0 =  V_0 \\Lambda V_0^{-1}\n\\]\n\n# Diagonalize P0^t P0 ---\ndg1 &lt;- eigen(t(P0) %*% P0)\n\n# Eigenvalues are equal to the square roots of SVD eigenvalues\nall((dg1$values - lambda) &lt; zero)\n\n[1] TRUE\n\n# Eigenvectors are equal to V0\nall(abs(dg1$vectors/V0) - 1 &lt; zero)\n\n[1] TRUE\n\n\nSimilarly, we can rewrite \\(P_0 P_0^\\top\\):\n\\[\nP_0 P_0^\\top =  U_0 \\Lambda U_0^{-1}\n\\]\n\n# Diagonalize P0 P0^t ---\ndg2 &lt;- eigen(P0 %*% t(P0))\n\n# Eigenvalues are equal to the square roots of SVD eigenvalues\nall((dg1$values - lambda) &lt; zero)\n\n[1] TRUE\n\n# Eigenvectors corresponding to non-null eigenvalues are equal to U0\nall(abs(dg2$vectors[, 1:k]/U0[, 1:k]) - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nComparison with Carroll, Green, and Schaffer (1986)\nIn Carroll, Green, and Schaffer (1986), CA is defined as the SVD of matrix \\(H\\) defined as:\n\\[\nH = D(y_{i\\cdot})^{-1/2} Y D(y_{\\cdot j})^{-1/2}\n\\]\nWhere \\(D(y_{i \\cdot})\\) and \\(D(y_{\\cdot j})\\) are the equivalent of \\(D_r\\) and \\(D_c\\) for matrix \\(Y\\).\nWe compute this matrix and compare the results with the SVD of \\(P_0\\).\n\n# Define weights matrices\nDyi_ &lt;- diag(rowSums(Y))\nDy_j &lt;- diag(colSums(Y))\n\n# Also define a variable for just the sums for easier manipulation\ndyi_ &lt;- rowSums(Y)\ndy_j &lt;- colSums(Y)\n\n\n# Compute H with the formula from Caroll\nH &lt;- diag(dyi_^(-1/2)) %*% Y %*% diag(dy_j^(-1/2))\n\nres &lt;- H/P0 \nall((res - 1) &lt; zero) # It is not equal to P0\n\n[1] FALSE\n\n# We try to center it:\nH_centered &lt;- diag(dyi_^(-1/2)) %*% (Y - (dyi_ %*% t(dy_j))) %*% diag(dy_j^(-1/2))\n\nres &lt;- H_centered/P0\nall((res - 1) &lt; zero) # Not equal\n\n[1] FALSE\n\n\nWe compare the SVDs of \\(H\\) and \\(P_0\\): they give the same value.\n\n# SVD of H\nsvH &lt;- svd(H)\n\n# Eigenvalues are the same, except for the first eigenvalue equal to one\nres &lt;- svH$d[2:(k+1)]/delta[1:k]\nall((res - 1) &lt; zero)\n\n[1] TRUE\n\n# Eigenvectors are the same (but for the first one)\nres &lt;- svH$u[, 2:(k+1)]/U0[, 1:k]\nall((res - 1) &lt; zero)\n\n[1] TRUE\n\nres &lt;- svH$v[, 2:(k+1)]/V0[, 1:k]\nall((res - 1) &lt; zero)\n\n[1] TRUE\n\n\nNB: \\(P_0\\) is not equal to \\(H\\) defined in Carroll, Green, and Schaffer (1987). But they do not center the matrix, so the first eigenvalue is one and the rest are the same.\n\n\n\nRelationship between \\(U_0\\) and \\(V_0\\)\nWe have the following transition formulae between \\(U_0\\) and \\(V_0\\):\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U_0 &= P_0 V_0 \\Lambda^{-1/2}\\\\\n  V_0 &= P_0^\\top U_0 \\Lambda^{-1/2}\\\\\n\\end{array}\n\\right.\n\\]\n\n# Sites weighted averaging\nU0_wa &lt;- P0 %*% V0 %*% diag(lambda^(-1/2))\nres &lt;- U0_wa/U0\nall((abs(res[, 1:k]) - 1) &lt; zero)\n\n[1] TRUE\n\n# Species weighted averaging\nV0_wa &lt;- t(P0) %*% U0 %*% diag(lambda^(-1/2))\nres &lt;- V0_wa/V0\nall((abs(res[, 1:k]) - 1) &lt; zero)\n\n[1] TRUE\n\n\n\n\nDefine \\(U\\) and \\(V\\)\nWe define weighted versions of \\(U_0\\) and \\(V_0\\):\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U &= D_r^{-1/2} U_0\\\\\n  V &= D_c^{-1/2} V_0\\\\\n\\end{array}\n\\right.\n\\tag{1}\\]\n\n# Sites\nU &lt;- diag(dr^(-1/2)) %*% U0\n  \n# Species\nV &lt;- diag(dc^(-1/2)) %*% V0\n\nThese vectors have the property to be of variance 1 (when weighted by \\(D_r\\) and \\(D_c\\)): it is easier to interpret than vectors of norm 1 like \\(U_0\\) and \\(V_0\\).\n\n# Variance of columns vectors for columns\nvarV &lt;- apply(V, 2, varwt, wt = dc)\nres &lt;- varV[1:k]/1\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n# Variance of columns vectors for rows\nvarU &lt;- apply(U, 2, varwt, wt = dr)\nres &lt;- varU[1:k]/1\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe check that these are equal to the l1 and c1 of CA:\n\nres &lt;- U/ca$l1\nall((abs(res) - 1) &lt; zero)\n\n[1] TRUE\n\nres &lt;- V/ca$c1\nall((abs(res) - 1) &lt; zero)\n\n[1] TRUE"
  },
  {
    "objectID": "CA.html#scalings",
    "href": "CA.html#scalings",
    "title": "Correspondence analysis (CA)",
    "section": "Scalings",
    "text": "Scalings\n\n\n\n\n\n\nTL;DR\n\n\n\nTo plot rows and columns on separate plots, one can plot the eigenvectors \\(U_0\\) (rows = sites) and \\(V_0\\) (columns = species). But in data analyses, the weighted vectors \\(U\\) and \\(V\\) are more commonly used Equation 1.\nTo plot columns and rows individuals on the same biplot, different scalings have been proposed. For sites (rows), these scalings are equal to \\(S_\\alpha = U \\Lambda^{\\alpha/2}\\) and for species (columns), \\(S_\\alpha = V \\Lambda^{(1-\\alpha)/2}\\). (with \\(\\alpha =\\) 1, 0 or 1/2).\n\nScaling type 1 (\\(\\alpha = 1\\)): this scaling preserves the distances between rows. Rows (sites) are represented with \\(U^\\star = U \\Lambda^{1/2}\\) and species (columns) with \\(V\\).\nScaling type 2 (\\(\\alpha = 0\\)): this scaling preserves distances between columns. Rows (sites) are represented with \\(U\\) and species (columns) with \\(V^\\star = V \\Lambda^{1/2}\\).\nScaling type 3 (\\(\\alpha = 1/2\\)): this scaling is a compromise between scalings type 1 and 2. Rows (sites) are represented with \\(\\hat{S}_3 = U \\Lambda^{1/4}\\) and species (columns) with \\(S_3 = V \\Lambda^{1/4}\\).\n\nAs noted in Carroll, Green, and Schaffer (1987), if we plot distances of different scalings on the same biplot, we cannot interpret between-sets distances, but within-sets distances are still be interpretable. But this type of interpretation is often attempted with scaling type 4 (described below), and this scaling is what Carroll, Green, and Schaffer (1987) criticize.\n\n\n\nNo scaling\nOne can represent the eigenvectors \\(U_0\\) and \\(V_0\\) (or \\(U\\) and \\(V\\)) on separate plots.\n\\(U_0\\) and \\(V_0\\):\n\n\nCode\n# Plot sites ---\ng1 &lt;- multiplot(indiv_row = U0, \n          indiv_row_lab = rownames(Y), \n          row_color = params$colsite,\n          eig = lambda)\n\n# Plot species ---\ng2 &lt;- multiplot(indiv_row = V0, \n          indiv_row_lab = colnames(Y), \n          row_color = params$colspp,\n          eig = lambda)\n\n(g1 + g2) + plot_layout(axis_titles = \"collect\")\n\n\n\n\n\n\\(U\\) and \\(V\\):\n\n\nCode\n# Plot sites ---\ng1 &lt;- multiplot(indiv_row = U, \n          indiv_row_lab = rownames(Y), \n          row_color = params$colsite,\n          eig = lambda)\n\n# Plot species ---\ng2 &lt;- multiplot(indiv_row = V, \n          indiv_row_lab = colnames(Y), \n          row_color = params$colspp,\n          eig = lambda)\n\n(g1 + g2) + plot_layout(axis_titles = \"collect\")\n\n\n\n\n\n\n\nScaling type 1\nThis scaling preserves the row \\(\\chi^2\\) distances and is useful to interpret distances between row individuals (sites). In this scaling, the rows individuals (sites) are positioned at the barycentre of the corresponding column (species) individuals.\nFor that, we use:\n\n\\(U^\\star = U \\Lambda^{1/2}\\) (rows = sites): corresponds to the li\n\\(V = D_c^{-1/2} V_0\\) (columns = species): corresponds to the c1\n\n\n# Sites\nUstar &lt;- U %*% Lambda^(1/2)\n\nWe check that \\(U^\\star\\) corresponds to the li of CA:\n\nres &lt;- Ustar/ca$li\nall((abs(res) - 1) &lt; zero)\n\n[1] TRUE\n\n\nThese scalings correspond to fixed variances for rows and columns. With scaling type 1, variance of the columns is fixed at one (corresponds to c1) and variance of the rows correspond to the eigenvalues (corresponds to li).\n\n# Variance of columns vectors for rows\nvarUstar &lt;- apply(Ustar, 2, varwt, wt = ca$lw)\nres &lt;- varUstar[1:k]/ca$eig\nall(res -1 &lt; zero)\n\n[1] TRUE\n\n\n\nPlots\nPlot with our coordinates:\n\n\nCode\nmultiplot(indiv_row = Ustar, # variance lambda (averaging)\n          indiv_col = V, # variance 1\n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\nPlot with ade4:\n\n\nCode\ns.label(ca$c1,\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp,\n        plabels.optim = TRUE) # variance 1\ns.label(ca$li, \n        ppoints.col = params$colsite,\n        plabels.col = params$colsite,\n        plabels.optim = TRUE,\n        add = TRUE) # variance lambda (averaging)\n\n\n\n\n\nOther plotting method with ade4:\n\n\nCode\n# Check the agreement between li/c1 and scaling type\n# From the doc: when method = 2, rows variance 1 and columns by averaging\nscatter(ca, method = 2,\n        plabels.optim = TRUE,\n        posieig = 'none')\n\n\n\n\n\n\n\nWeighted averaging\n\\(U^\\star\\) (sites scores) can also be computed from the species scores using weighted averaging, since there is a correspondence between \\(V_0\\) and \\(U_0\\). This shows better the relationship between sites and species scores (sites are at the barycentre of their species with this scaling).\n\\(U^\\star\\) can be expressed by weighted averaging using the following formulas:\n\\[\nU^\\star = \\left\\{\n\\begin{array}{ll}\n  D_r^{-1/2} P_0 V_0 \\qquad &\\text{(from } V_0 \\text{)}\\\\\n  D_r^{-1/2} P_0 D_c^{1/2} V \\qquad &\\text{(from } V \\text{)}\\\\\n   D_r^{-1} P V \\qquad &\\text{(from } V \\text{ and } P \\text{)}\\\\\n\\end{array}\n\\right.\n\\tag{2}\\]\n\n# Compute sites coordinates using weighted averaging\n\n# With V0\nUstar_wa &lt;- diag(dr^(-1/2)) %*% P0 %*% V0\nres &lt;- Ustar_wa/Ustar\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# With V\nUstar_wa_V &lt;- diag(dr^(-1/2)) %*% P0 %*% diag(dc^(1/2)) %*% V\nres &lt;- Ustar_wa_V/Ustar\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# With V and P\nUstar_wa_legendre &lt;- diag(dr^(-1)) %*% P %*% V\nres &lt;- Ustar_wa_legendre/Ustar\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\n\nScaling type 2\nThis preserves \\(\\chi^2\\) distances between species on the plot. Here, species are positioned at the centroid of sites.\nWe use:\n\n\\(U = D_r^{-1/2} U_0\\) (rows = sites)\n\\(V^\\star = V \\Lambda^{1/2}\\) (columns = species)\n\n\n# Species\nVstar &lt;- V %*% diag(lambda^(1/2))\n\nWe check that \\(V^\\star\\) corresponds to the co of CA:\n\nres &lt;- Vstar/ca$co\nall((abs(res) - 1) &lt; zero)\n\n[1] TRUE\n\n\nThese scalings correspond to fixed variances for rows and columns. With scaling type 2, variance of the rows is fixed at one (corresponds to l1) and variance of the columns correspond to the eigenvalues (corresponds to co).\n\n# Variance of columns vectors for rows\nvarA &lt;- apply(Vstar, 2, varwt, wt = ca$cw)\nres &lt;- varA[1:k]/ca$eig\nall(res -1 &lt; zero)\n\n[1] TRUE\n\n\n\nPlots\nPlot with our coordinates:\n\n\nCode\nmultiplot(indiv_row = U, # variance 1 \n          indiv_col = Vstar, # variance lambda (weighted averaging)\n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\nPlot with ade4:\n\n\nCode\ns.label(ca$l1, # variance 1 (rows/sites)\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite,\n        plabels.optim = TRUE)\ns.label(ca$co, #  variance lambda (weighted averaging) (cols/spp)\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp,\n        plabels.optim = TRUE,\n        add = TRUE)\n\n\n\n\n\nOther plotting method with ade4:\n\n\nCode\n# ade4 doc: method = 3 -&gt; 3 columns variance 1 and rows by averaging \n# Error? here we have columns by WA and rows variance 1\n\nscatter(ca, method = 3, \n        plabels.optim = TRUE,\n        posieig = 'none')\n\n\n\n\n\n\n\nWeighted averaging\nLike \\(U^\\star\\), \\(V^\\star\\) (species scores) can also be computed from the sites scores. This shows better the relationship between species and sites scores (species are at the barycentre of their sites with this scaling).\n\\[\nV^\\star = \\left\\{\n\\begin{array}{ll}\n  D_c^{-1/2} P_0^\\top U_0 \\qquad &\\text{(from } U_0 \\text{)}\\\\\n  D_c^{-1/2} P_0^\\top D_r^{1/2} U \\qquad &\\text{(from } U \\text{)}\\\\\n   D_c^{-1} P U^\\top \\qquad &\\text{(from } U \\text{ and } P \\text{)}\\\\\n\\end{array}\n\\right.\n\\tag{3}\\]\n\n# U0\nVstar_wa &lt;- diag(dc^(-1/2)) %*% t(P0) %*% U0\nres &lt;- Vstar_wa/Vstar\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n# U\nVstar_wa_U &lt;- diag(dc^(-1/2)) %*% t(P0) %*% diag(dr^(1/2)) %*% U\nres &lt;- Vstar_wa_U/Vstar\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n# U and P\nVstar_wa &lt;- diag(dc^(-1)) %*% t(P) %*% U\nres &lt;- Vstar_wa/Vstar\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\n\nScaling type 3\nIt is a compromise between scalings 1 and 2. It preserves none of the \\(\\chi^2\\) distances.\nWe use:\n\n\\(S_r = U \\Lambda^{1/4}\\) (for sites)\n\\(S_c = V \\Lambda^{1/4}\\) (for species).\n\n\nSr &lt;- U %*% Lambda^(1/4)\nSc &lt;- V %*% Lambda^(1/4)\n\n\nPlots\nPlot with our values:\n\n\nCode\nmultiplot(indiv_row = Sr, indiv_col = Sc, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\nPlot with ade4 values:\n\n\nCode\nSr_ade4 &lt;- as.matrix(ca$l1) %*% diag(ca$eig^(1/4))\nSc_ade4 &lt;- as.matrix(ca$c1) %*% diag(ca$eig^(1/4))\n\ns.label(Sr_ade4, \n        ylim = c(-5, 5),\n        xlim = c(-5, 5),\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite,\n        plabels.optim = TRUE)\ns.label(Sc_ade4,\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp,\n        plabels.optim = TRUE,\n        add = TRUE)\n\n\n\n\n\n\n\n\nScaling type 4\nUse \\(U^\\star\\) (sites) and \\(V^\\star\\) (species). Then, both \\(\\chi^2\\) distances are preserved. It is useful for a table crossing two factors.\nPlot with our values:\n\n\nCode\nmultiplot(indiv_row = Ustar, \n          indiv_col = Vstar, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\nPlot with ade4 values:\n\n\nCode\ns.label(ca$li, \n        ylim = c(-2, 3),\n        xlim = c(-3, 2),\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite,\n        plabels.optim = TRUE)\ns.label(ca$co,\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp,\n        plabels.optim = TRUE,\n        add = TRUE)\n\n\n\n\n\nOther ade4 method:\n\n\nCode\n# 1 rows and columns with the coordinates of lambda variance\nscatter(ca, method = 1,\n        plabels.optim = TRUE,\n        posieig = 'none')"
  },
  {
    "objectID": "CA.html#interpretation",
    "href": "CA.html#interpretation",
    "title": "Correspondence analysis (CA)",
    "section": "Interpretation",
    "text": "Interpretation\nUsing the “transition formula” defined in Equation 2 and Equation 3, we can relate the ordination of rows (sites) (\\(U\\)) to the ordination of columns (species) (\\(V\\)) by expressing it as a weighted average of the other dimensions’ individuals.\nFor instance, the sites coordinates \\(U^\\star\\) (weighted average) represent the mean of the coordinates of species present in this site. The species coordinates \\(V^\\star\\) (weighted average) represent the mean of the coordinates of sites that this species is present in.\nThe eigenvalue \\(\\lambda_h\\) is a measure of the correlation of the rows and columns ordinations along axis \\(h\\).\nIf species have a unimodal (bell-shaped) response along the gradient defined by the sites ordination along a given axis, then their position should be close to their niche optimum.\nDepending on he position of, say, species, in the multivariate space, there are several interpretations:\n\nspecies that are absent from most sites: often at the edge, close to a site where they happen to be present. They have little influence on the analysis.\nspecies that are in the center: either have their optimum there, they have a multimodal niche or their niche is not influenced by the latent variables of the ordination axes.\nspecies found away from the center but not at the edges: more likely to display clear relationships with the axis\n\n\n\n\n\n\n\nNote\n\n\n\nRare species are generally not very interesting because they are exceptions, not a general tendency. So some authors propose strategies to remove them, notably an iterative procedure. First do the complete CA, then remove the species seen one, twice… etc. Note the total inertia and the eigenvalues. When there is a jump, stop.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen there is a succession of species, along an hypothetical gradient, the CA may lead to an arch shape. There are techniques to detrend it, but knowing how to interpret this effect is probably more important."
  },
  {
    "objectID": "dcCA.html",
    "href": "dcCA.html",
    "title": "Double constrained Correspondence Analysis (dc-CA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# dc-CA\nsource(here(\"functions/dpcaiv2-ade4.R\"))\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(CAnetwork)\nlibrary(patchwork)\nlibrary(ggplot2)\nCode\n# Define bound for comparison to zero\nzero &lt;- 10e-10\nCode\n#' Normalize row or columns vectors of a matrix\n#'\n#' @param M the matrix to normalize\n#' @param margin the margin (1 = rows, 2 = columns)\n#'\n#' @return The normalized matrix M\nnormalize &lt;- function(M, margin) {\n  \n  m_norm &lt;- apply(M,\n                  margin, \n                  function(x) sqrt(sum(x^2)))\n  M_norm &lt;- sweep(M, margin, m_norm, \"/\")\n  return(M_norm)\n}\nThe contents of this page relies heavily on Braak, Šmilauer, and Dray (2018)."
  },
  {
    "objectID": "dcCA.html#introduction",
    "href": "dcCA.html#introduction",
    "title": "Double constrained Correspondence Analysis (dc-CA)",
    "section": "Introduction",
    "text": "Introduction\nDouble constrained correspondence analysis (dc-CA) was developed as a natural extension of CCA and has been used to study the relationship between species traits and environmental variables.\nIn dc-CA, we have 3 matrices:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables \\(E\\) (\\(r \\times l\\))\nA matrix of predictor variables \\(T\\) (\\(c \\times k\\))\n\n\n\nCode\ndat &lt;- readRDS(here(\"data/Barbaro2012.rds\"))\nY &lt;- dat$comm\nE &lt;- dat$envir\nT_ &lt;- dat$traits\n\nr &lt;- dim(Y)[1]\nc &lt;- dim(Y)[2]\nl &lt;- dim(E)[2]\nk &lt;- dim(T_)[2]\n\nplotmat(r = r, c = c, \n        E = TRUE, T_ = TRUE,\n        l = l, k = k)\n\n\n\n\n\nThe aim of dc-CA is to find a linear combination of the predictor variables in \\(E\\) and \\(T\\) (environmental variables and traits) that maximizes the correlation.\nBelow are the first lines of these matrices for our data:\n\\(Y =\\)\n\n\nCode\nknitr::kable(head(Y))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n\n\n\n\\(E =\\)\n\n\nCode\nknitr::kable(head(E))\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n\n\n\n\\(T =\\)\n\n\nCode\nknitr::kable(head(T_))\n\n\n\n\n\n\nbiog\nforag\nmass\ndiet\nmove\nnest\neggs\n\n\n\n\nsp1\n1\n2\n2\n3\n1\n2\n2\n\n\nsp2\n1\n1\n1\n2\n1\n2\n2\n\n\nsp3\n1\n1\n2\n2\n2\n2\n1\n\n\nsp4\n1\n1\n1\n2\n1\n2\n2\n\n\nsp5\n1\n3\n3\n1\n2\n3\n4\n\n\nsp6\n1\n1\n4\n3\n2\n2\n1\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- dim(E)[2])\n\n[1] 6\n\n(k &lt;- dim(T_)[2])\n\n[1] 7\n\n\ndc-CA must not have to many traits compared to species: that is a disadvantage compared to RLQ, but on the other hand dc-CA allows to see relationships that RLQ would miss (Braak, Šmilauer, and Dray 2018).\nThere are several ways to perform dc-CA (Braak, Šmilauer, and Dray 2018), notably:\n\nsingular value decomposition (the method used here)\nan iterative method à la reciprocal averaging\ncanonical correlation analysis between \\(T\\) et \\(E\\), weighted by \\(P\\)"
  },
  {
    "objectID": "dcCA.html#computation",
    "href": "dcCA.html#computation",
    "title": "Double constrained Correspondence Analysis (dc-CA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nWe define matrix \\(D\\) as:\n\\[D = [E_{center}^\\top D_r E_{center}]^{-1/2} E_{center}^\\top P T_{center} [T_{center}^\\top D_c T_{center}]^{-1/2}\\]\nNote: contrary to Braak, Šmilauer, and Dray (2018), in this document we use the matrice of relative counts \\(P\\) instead of the matrix of absolte counts \\(Y\\).\nWe perform the SVD of \\(D\\):\n\\[\nD = B_0 \\Delta C_0^\\top\n\\]\nThis allows us to find the eigenvectors \\(B_0\\) (regression coefficients multiplying rows/environment variables) and \\(C_0\\) (regression coefficients multiplying columns/species traits).\nThe eigenvalues of the dc-CA are the squared eigenvalues of the SVD: \\(\\Lambda = \\Delta^2\\).\nThere are \\(\\min(k, l)\\) non-null eigenvalues???\nTransformation of \\(B_0\\) and \\(C_0\\)\nThen, we transform \\(B_0\\) and \\(C_0\\) (scaling):\n\n\\(B = [E_{center}^\\top D_r E_{center}]^{-1/2} B_0\\) (coefficients for rows/environmental variables)\n\\(C = [T_{center}^\\top D_c T_{center}]^{-1/2} C_0\\) (coefficients for columns/species traits)\n\nIndividuals coordinates\nThe individuals coordinates (species or sites) can be computed in two ways:\nLinear combinations (LC scores) are computed from those coefficients :\n\n\\(U = E_{center} B\\) for the rows (sites)\n\\(V = T_{center} C\\) for columns (species)\n\nWeighted averages (WA scores) are computed from the scores of the other individuals:\n\n\\(U^\\star = {D_r}^{-1} P V\\) for row (sites) scores\n\\(V^\\star = {D_c}^{-1} P^\\top U\\) for column (species) scores\n\n\n\n\nPre-computations\nTo check our results, we first perform a dc-CA with ade4:\n\nca &lt;- dudi.coa(Y, \n               nf = c-1, \n               scannf = FALSE)\n\ndcca &lt;- dpcaiv2(dudi = ca, \n                dfR = E,\n                dfQ = T_,\n                scannf = FALSE, \n                nf = min(k, l))\n\n\n\nCenter matrices\nWe define \\(P\\) as the relative counts of \\(Y\\):\n\nP &lt;- Y/sum(Y)\n\nFirst, we need to center the traits and environment matrices (resp. \\(T_{center}\\) and \\(E_{center}\\)). To do so, we use the occurrences in matrix \\(P\\) as weights:\n\nE_wt &lt;- rowSums(P)/nrow(E)\nEcenter &lt;- scalewt(E, wt = E_wt, scale = FALSE)\n\nT_wt &lt;- colSums(P)/nrow(T_)\nTcenter &lt;- scalewt(T_, wt = T_wt, scale = FALSE)\n\n\n# Check centering\nM1 &lt;- matrix(rep(1, nrow(P)), nrow = 1)\nall(abs(M1 %*% diag(rowSums(P)) %*% Ecenter) &lt; zero)\n\n[1] TRUE\n\nM1 &lt;- matrix(rep(1, ncol(P)), nrow = 1)\nall(abs(M1 %*% diag(colSums(P)) %*% Tcenter) &lt; zero)\n\n[1] TRUE\n\n\nThis is equivalent to centering “inflated” versions of these matrices matching the occurrence counts in \\(P\\) (below).\n\\[\nE_{center} = E - \\bar{E}_{infl} =\\left[e_i \\sum_i y_{i\\cdot}e_i/y_{\\cdot\\cdot} \\right]\n\\]\n\\[\nT_{center} = T - \\bar{T}_{infl} = \\left[t_j \\sum_j y_{\\cdot j}t_j/y_{\\cdot\\cdot} \\right]\n\\]\n\n\nCode\n# Center E -----\npi_ &lt;- rowSums(P)\nEcenter2 &lt;- matrix(nrow = nrow(E), ncol = ncol(E))\n\nfor(i in 1:ncol(Ecenter)) {\n  Ecenter2[, i] &lt;- E[, i] - sum(E[, i]*pi_)/sum(P)\n}\n# This is the same as computing a mean on inflated data matrix Einfl and centering E with these means\n\n# Center T -----\np_j &lt;- colSums(P)\nTcenter2 &lt;- matrix(nrow = nrow(T_), ncol = ncol(T_))\nrownames(Tcenter2) &lt;- rownames(T_)\ncolnames(Tcenter2) &lt;- colnames(T_)\n\nfor(j in 1:ncol(Tcenter)) {\n  Tcenter2[, j] &lt;- T_[, j] - (sum(T_[, j]*p_j)/sum(P))\n}\n\n\n\n\nCode\n# Check equivalence between the 2 methods\nall(abs(Ecenter/Ecenter2 - 1) &lt; zero)\n\n\n[1] TRUE\n\n\nCode\nall(abs(Tcenter/Tcenter2 - 1) &lt; zero)\n\n\n[1] TRUE\n\n\n\n\nRationale: regression\nThen, we search scores \\(u\\) and \\(v\\) that maximize the fourth-corner correlation \\(u^\\top P v\\) (where \\(u\\) are the sites (rows) scores and \\(v\\) are the species (columns) scores).\nIn this framework, we define \\(u\\) and \\(v\\) as linear combinations of traits and environmental variables: \\(u = E_{center}b\\) and \\(v = T_{center}c\\).\nSo in the end, we need to maximize \\(u^\\top P v\\) with respect to the coefficients vectors \\(b\\) and \\(c\\):\n\\[\n\\max_{b, c}(u^\\top P v) = \\max_{b, c}\\left(\\left[E_{center}b\\right]^\\top P  T_{center}c \\right)\n\\]\n\n\n\n\n\n\nNote\n\n\n\nThese equations are written for the first axis, but we can also write them in matrix form:\n\\[\n\\max_{B, C}(U^\\top P V) = \\max_{B, C}\\left(\\left[E_{center}B\\right]^\\top P T_{center}C \\right)\n\\]\n\n\nWe define the diagonal matrices \\(D_r\\) and \\(D_c\\), which contain the column and row sums (respectively). We introduce the following constraint on \\(U\\) and \\(V\\): \\(u^\\top D_r u = 1\\) and \\(v^\\top D_c v = 1\\). It means that the matrices \\(U\\) and \\(V\\) are orthonormal with respect to the weights \\(D_r\\) and \\(D_c\\). (In fact, these constraints will be relaxed later depending on the scaling (see below)).\nTo find the coefficients \\(B\\) and \\(C\\) defined above, we can perform a SVD or two diagonalizations (see below).\n\n\nSVD\nTo find the coefficients \\(B\\) and \\(C\\), we perform the SVD of a matrix \\(D\\) defined as:\n\\[\nD = \\underbrace{[E_{center}^\\top D_r E_{center}]^{-1/2}}_{L^{-1/2}} \\underbrace{E_{center}^\\top P T_{center}}_{R} \\underbrace{[T_{center}^\\top D_c T_{center}]^{-1/2}}_{K^{-1/2}}\n\\]\n\n# Define weights\ndr &lt;- rowSums(P)\ndc &lt;- colSums(P)\n\nDr &lt;- diag(dr)\nDc &lt;- diag(dc)\n\n\n# Define intermediate matrices\nL &lt;- t(Ecenter) %*% Dr %*% Ecenter\nR &lt;- t(Ecenter) %*% P %*% Tcenter\nK &lt;- t(Tcenter) %*% Dc %*% Tcenter\n\nWith our dataset:\n\nD &lt;- solve(sqrtm(t(Ecenter) %*% Dr %*% Ecenter)) %*%\n  t(Ecenter) %*% P %*% Tcenter %*%\n  solve(sqrtm(t(Tcenter) %*% Dc %*% Tcenter))\n\nWe perform the SVD of \\(D\\):\n\\[D = B_0 \\Delta C_0^\\top\\]\n\nsv &lt;- svd(D)\n\n# Singular values\ndelta &lt;- sv$d\nDelta &lt;- diag(delta)\n\n# Eigenvalues\nlambda &lt;- delta^2\nLambda &lt;- diag(lambda)\n\n# Eigenvectors\nB0 &lt;- sv$u\ndim(B0) # l x l\n\n[1] 6 6\n\nC0 &lt;- sv$v\ndim(C0) # k x l\n\n[1] 7 6\n\n\n\n\nDiagonalizations\nEquivalently, we can also diagonalize the matrices \\(M\\) and \\(M_2\\) defined below.\n\\(M\\) is defined as:\n\\[\nM = [\\underbrace{E_{center}^\\top D_r E_{center}}_{L} ]^{-1} \\underbrace{E_{center}^\\top P T_{center}}_{R} [ \\underbrace{T_{center}^\\top D_c T_{center}}_{K} ]^{-1} \\underbrace{T_{center}^\\top P^\\top E_{center}}_{R^\\top}\n\\tag{1}\\]\nWe can also view \\(M\\) as:\n\\[\nM = \\underbrace{\\left[E_{center}^\\top D_r E_{center} \\right]^{-1} E_{center}^\\top P T_{center}}_{\\hat{E}_{center} = \\beta T_{center}} \\underbrace{\\left[T_{center}^\\top D_c T_{center} \\right]^{-1} T_{center}^\\top P^\\top E_{center}}_{\\hat{T}_{center} = \\gamma E_{center}}\n\\]\nwhere \\(\\hat{E}_{center}\\) is the predicted values of sites variables from species traits. Reciprocally, \\(\\hat{T}_{center}\\) is the predicted values of species traits from sites variables. \\(\\beta\\) and \\(\\gamma\\) are the vectors of the regression coefficients. From Equation 1, we have \\(\\beta = \\left[E_{center}^\\top D_r E_{center} \\right]^{-1} E_{center}^\\top P\\) and \\(\\gamma = \\left[T_{center}^\\top D_c T_{center} \\right]^{-1} T_{center}^\\top P^\\top\\).\n\nM &lt;- solve(t(Ecenter) %*% Dr %*% Ecenter) %*% t(Ecenter) %*% P %*% Tcenter %*% solve(t(Tcenter) %*% Dc %*% Tcenter) %*% t(Tcenter) %*% t(P) %*% Ecenter\n\n\\(M_2\\) is defined as:\n\\[\nM_2 = \\underbrace{\\left[T_{center}^\\top D_c T_{center} \\right]^{-1} T_{center}^\\top P^\\top E_{center}}_{\\hat{T}_{center} = \\gamma E_{center}} \\underbrace{\\left[E_{center}^\\top D_r E_{center} \\right]^{-1} E_{center}^\\top P T_{center}}_{\\hat{E}_{center} = \\beta T_{center}}\n\\]\n\nM2 &lt;- solve(t(Tcenter) %*% Dc %*% Tcenter) %*% t(Tcenter) %*% t(P) %*% Ecenter %*% solve(t(Ecenter) %*% Dr %*% Ecenter) %*% t(Ecenter) %*% P %*% Tcenter \n\nThe eigenvectors matrices of these diagonalizations give us \\(B\\) and \\(C\\):\n\nTo find \\(B\\), we diagonalize \\(M\\):\n\n\\[\nM = B \\Lambda_b B^{-1}\n\\]\n\n# Diagonalize M\neigB &lt;- eigen(M)\nlambdaB &lt;- eigB$values\nlambdaB # All l = 6 non-null eigenvectors\n\n[1] 0.139487442 0.088736680 0.049183623 0.013797529 0.008736645 0.002485683\n\nB_diag &lt;- eigB$vectors\n\n# Check that the result checks out with SVD\nall(abs(abs(B_diag/B0) - 1) &lt; zero) # it isn't equal\n\n[1] FALSE\n\napply(B_diag, 2, function(x) sqrt(sum(x^2))) # but B_diag is of norm 1 (like B0)\n\n[1] 1 1 1 1 1 1\n\n\n\nSimilarly, to find \\(C\\), we must diagonalize \\(M_2\\):\n\n\\[\nM_2 = C \\Lambda_c C^{-1}\n\\]\n\n# Diagonalize M2\neigC &lt;- eigen(M2)\nlambdaC &lt;- eigC$values\nlambdaC # l = 6 non-null eigenvalues\n\n[1]  1.394874e-01  8.873668e-02  4.918362e-02  1.379753e-02  8.736645e-03\n[6]  2.485683e-03 -1.025803e-18\n\nC_diag &lt;- eigC$vectors\n\n# Check that the result checks out with SVD\nall(abs(abs(C_diag[, 1:l]/C0) - 1) &lt; zero) # it isn't equal\n\n[1] FALSE\n\napply(C_diag[, 1:l], 2, function(x) sqrt(sum(x^2))) # but C_diag is of norm 1 (like C0)\n\n[1] 1 1 1 1 1 1\n\n\n\n# The two diagonalizations have the same non-null eigenvectors\nall(lambdaB - lambdaC[1:l] &lt; zero)\n\n[1] TRUE\n\n\nThe eigenvalues of the SVD \\(\\Lambda = \\Delta^2\\) are the same as \\(\\Lambda_b\\) and \\(\\Lambda_c\\).\n\nall(abs(lambda - lambdaB) &lt; zero)\n\n[1] TRUE\n\n\n\n\nCompute \\(B\\) and \\(C\\)\nWe also define the following “scalings” for the coefficients:\n\\[\n\\left\\{\n\\begin{array}{ll}\n  B &= L^{-1/2} B_0\\\\\n  C &= K^{-1/2} C_0\n\\end{array}\n\\right.\n\\]\n(We recall that \\(L = E_{center}^\\top D_r E_{center}\\) and \\(K = T_{center}^\\top D_c T_{center}\\)).\n\nB &lt;- solve(sqrtm(L)) %*% B0 \nC &lt;- solve(sqrtm(K)) %*% C0\n\n\n# B0 and C0 are of norm 1\napply(B0, 2, function(x) sqrt(sum(x^2))) \n\n[1] 1 1 1 1 1 1\n\napply(C0, 2, function(x) sqrt(sum(x^2))) \n\n[1] 1 1 1 1 1 1\n\n# B and C are normed with L and K\napply(B, 2, function(x) sqrt(sum(x^2)))\n\n[1] 31.27063 57.99206 81.06909 67.68646 86.23340 88.33241\n\napply(C, 2, function(x) sqrt(sum(x^2)))\n\n[1] 1.905060 2.714419 3.397999 4.832457 1.714880 2.707478\n\n# t(B) L B is the identity matrix\nid_l &lt;- diag(1, nrow = l, ncol = l)\nall(abs((t(B) %*% L %*% B) - id_l) &lt; zero)\n\n[1] TRUE\n\n# t(C) K C is the identity matrix\nid_c &lt;- diag(c(rep(1, k-1), 0),\n             nrow = k, ncol = k) # Identity minus last vector (zero)\nC_k &lt;- cbind(C, rep(0, k)) # Add null eigenvector\nall(abs(t(C_k) %*% K %*% C_k - id_c) &lt; zero)\n\n[1] TRUE\n\n\n\n\nSites and species scores\n\nLC scores\nUsing the coefficients \\(B\\) and \\(C\\), we can now define scores for sites and species scores as a linear combination of their variables:\n\nsites scores predicted by environmental variables are \\(U = E_{center} B\\)\n\n\nU &lt;- Ecenter %*% B\n\n# Check it is the same as ade4 scores\nall(abs(U/dcca$l1) - 1 &lt; zero)\n\n[1] TRUE\n\n\n\nspecies scores predicted by their traits are \\(V = T_{center} C\\)\n\n\nV &lt;- Tcenter %*% C\n\n# Check it is the same as ade4 scores\nall(abs(V/dcca$c1) - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nWA scores\nWe can also define species scores as the mean of sites LC scores (and the reverse):\n\nsites scores as weighted averages of species scores are \\(U^\\star = D_r^{-1} P V\\)\n\n\nUstar &lt;- diag(dr^(-1)) %*% P %*% V\n\n# Check it is the same as ade4 scores\nall(abs(Ustar/dcca$lsR) - 1 &lt; zero)\n\n[1] TRUE\n\n\n\nspecies scores as weighted averages of sites scores are \\(V^\\star = D_c^{-1} P^\\top U\\)\n\n\nVstar &lt;- diag(dc^(-1)) %*% t(P) %*% U\n\n# Check it is the same as ade4 scores\nall(abs(Vstar/dcca$lsQ) - 1 &lt; zero)\n\n[1] TRUE"
  },
  {
    "objectID": "dcCA.html#scalings",
    "href": "dcCA.html#scalings",
    "title": "Double constrained Correspondence Analysis (dc-CA)",
    "section": "Scalings",
    "text": "Scalings\n\n\n\n\n\n\nTL;DR\n\n\n\nThere are two types of coordinates: linear combination scores (LC scores) and weighted averages scores (WA scores) for the sites and species individuals.\nThe general formulas are:\n\nthe LC scores for rows (sites) are \\(U_i = E_{center} B \\Lambda^{\\alpha/2}\\)\nthe LC scores for columns (species) are \\(V_i = T_{center}C_i \\Lambda^{(1 - \\alpha)/2}\\)\nthe WA scores for rows (sites) are \\(U^\\star_i = {D_r}^{-1} P V_i\\)\nthe WA scores for columns (species) are \\(V^\\star_i = {D_c}^{-1} P^\\top U_i\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_{Bi} = B \\Lambda^{\\alpha/2}\\)\nthe correlations with axes for the columns (species traits) are \\(BS_{Ci} = C \\Lambda^{(\\alpha - 1)/2}\\)\n\nIn these formulas, note that the WA scores for one dimension are computed from the predicted scores of the other dimension.\nScaling type 1 (\\(\\alpha = 1\\))\n\nthe LC scores for rows (sites) are \\(U_1 = E_{center} B \\Lambda^{1/2}\\) (li)\nthe LC scores for columns (species) are \\(V_1 = T_{center}C\\) (c1)\nthe WA scores for rows (sites) are \\(U^\\star_1 = {D_r}^{-1} P V_1\\) (lsR)\nthe WA scores for columns (species) are \\(V^\\star_1 = {D_c}^{-1} P^\\top U_1\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_{B1} = B \\Lambda^{1/2}\\)\nthe correlations with axes for the columns (species traits) are \\(BS_{C1} = C\\)\n\nScaling type 2 (\\(\\alpha = 0\\))\n\nthe LC scores for rows (sites) are \\(U_2 = E_{center} B\\) (l1)\nthe LC scores for columns (species) are \\(V_2 = T_{center}C \\Lambda^{1/2}\\) (co)\nthe WA scores for rows (sites) are \\(U^\\star_2 = {D_r}^{-1} P V_2\\)\nthe WA scores for columns (species) are \\(V^\\star_2 = {D_c}^{-1} P^\\top U_2\\) (lsQ)\nthe correlations with axes for the rows (environmental variables) are \\(BS_{B2} = B\\)\nthe correlations with axes for the columns (species traits) are \\(BS_{C2} = C \\Lambda^{1/2}\\)\n\nScaling type 3 (\\(\\alpha = 1/2\\))\n\nthe LC scores for rows (sites) are \\(U_3 = E_{center} B \\Lambda^{1/4}\\)\nthe LC scores for columns (species) are \\(V_3 = T_{center} C \\Lambda^{1/4}\\)\nthe WA scores for rows (sites) are \\(U^\\star_3 = {D_r}^{-1} P V_3\\)\nthe WA scores for columns (species) are \\(V^\\star_3 = {D_c}^{-1} P^\\top U_3\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_{B3} = B \\Lambda^{1/4}\\)\nthe correlations with axes for the columns (species traits) are \\(BS_{C3} = C \\Lambda^{1/4}\\)\n\n\\(\\alpha\\) changes the interpretation of the correlations vectors:\n\nthe following vectors are used for intra-set correlations: \\(BS_{B2}\\) (\\(\\alpha = 0\\)), to approximate the correlations between the environmental/row variables and the sites, and \\(BS_{C1}\\) (\\(\\alpha = 1\\)) for the correlations between the traits/column variables and the species.\ninter-set correlations (fourth-corner): \\(BS_{B1}\\) (\\(\\alpha = 1\\)) approximates the correlation between environmental/row variables and columns/species and \\(BS_{C2}\\) (\\(\\alpha = 0\\)) approximates the correlation between columns variables/traits and sites.\n\\(BS_{B3}\\) and \\(BS_{C3}\\) (\\(\\alpha = 1/2\\)) is the geometric mean of scalings 1 and 2.\n\nWhen plotting the correlation circle, to look at the correlations between variables of the same set (traits or environmental variables), we should use \\(BS_{B2}\\) and \\(BS_{C1}\\). There are the scores returned by ade4.\n\n\n\nScaling type 1\nThis type of scaling preserves the distances between rows (\\(\\alpha = 1\\)).\n\nthe rows (sites) scores can be \\(U^\\star_1\\) (WA scores) or \\(U_1\\) (LC scores)\n\nthe columns (species) scores can be \\(V^\\star_1\\) (WA scores) or \\(V_1\\) (LC scores)\nrows variables (environmental variables) correlations are \\(BS_{B1}\\).\ncolumns variables (species traits) correlations are \\(BS_{C1}\\)\n\nWith the scaling type 1, \\(BS_{B1}\\) represents the correlation between environmental variables and species and \\(BS_{C1}\\) represents the correlation between species traits and species.\n\n# LC scores\nU1 &lt;- Ecenter %*% B %*% Delta # rows\nV1 &lt;- Tcenter %*% C # columns\n\n# WA scores\nUstar1 &lt;- solve(Dr) %*% P %*% V1 # rows\nVstar1 &lt;- solve(Dc) %*% t(P) %*% U1  # columns\n\n# Variables scores\nBS_B1 &lt;- B %*% Delta\nBS_C1 &lt;- C\n\n# Normalize\nBS_B1norm &lt;- normalize(BS_B1, 1)\nBS_C1norm &lt;- normalize(BS_C1, 1)\n\n\n# Compare results to ade4\nall(abs(U1/dcca$li) - 1 &lt; zero) # sites LC\n\n[1] TRUE\n\nall(abs(V1/dcca$c1) - 1 &lt; zero) # spp LC\n\n[1] TRUE\n\nall(abs(Ustar1/dcca$lsR) - 1 &lt; zero) # sites WA\n\n[1] TRUE\n\nall(abs(abs(Vstar1/dcca$lsQ) - 1) &lt; zero) # not stored in ade4\n\n[1] FALSE\n\nall(abs(BS_B1norm/dcca$corR) - 1 &lt; zero) # not true\n\n[1] FALSE\n\nall(abs(BS_C1norm/dcca$corQ) - 1 &lt; zero) # not true, but should be\n\n[1] FALSE\n\n\n\nPlots\nWe can either plot:\n\nsites as \\(U_1\\) (li) and species as \\(V_1\\) (c1) (left)\nsites as \\(U^\\star_1\\) (lsR) and species as \\(V_1\\) (c1) (right)\n\n\n\nCode\n# LC scores\nglc &lt;- multiplot(indiv_row = U1, # LC for sites\n                 indiv_col = V1, # LC1 for spp\n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 # var_row = BS_B1norm, var_row_lab = colnames(E),\n                 # var_col = BS_C1norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"Sites LC scores with species\\nnormed at 1\")\n\n# WA scores\ngwa &lt;- multiplot(indiv_row = Ustar1, # WA for sites\n                 indiv_col = V1, # LC1 for spp\n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 # var_row = BS_B1norm, var_row_lab = colnames(E),\n                 # var_col = BS_C1norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"Sites LC scores\\nwith species\\nnormed at 1\")\n\nglc + gwa + \n  plot_layout(axis_titles = \"collect\")\n\n\n\n\n\nCode\ns.corcircle(BS_B1norm,\n            labels = colnames(E),\n            plabels.col = params$colsite)\ns.corcircle(BS_C1norm,\n            labels = colnames(T_),\n            plabels.col = params$colspp, add = TRUE)\n\n\n\n\n\nOn this plot, we can interpret 5 sets of pairs:\n\nrow and columns variables (\\(BS_{B1}\\) - \\(BS_{C1}\\)): angles between arrows of rows and environmental variables represent their fourth-corner correlation. For instance, the correlation between mass and perc_forests is large (arrows size + direction).\nspecies and environmental variables (\\(BS_{B1}\\) - \\(V\\)): species points on the right (e.g. sp1) are located in sites with a high location variable.\nsites and species traits (\\(BS_{C1}\\) - \\(U\\)): we can understand sites using their community weighted mean (eg site 26 has birds with high mass).\nspecies and species traits (\\(BS_{C1}\\) - \\(U\\)): for instance, species 12 has large eggs.\n\nThe last pair is the individuals on each plot:\n\nOn the first plot (with sites LC scores), \\(U_1\\) and \\(V_1\\) form a biplot of contingency ratio (Braak, Šmilauer, and Dray 2018)\nOn the second plot (with sites WA scores), \\(U^\\star_1\\) is placed at the mean of \\(V_1\\).\n\nMoreover, species traits (\\(BS_C^1\\)): arrows indicate intra-set correlations.\nThere is no interpretation for sites - environmental variables (\\(U_1\\) - \\(BS_{B1}\\)).\nSame plots with ade4:\n\n\nCode\ns.label(dcca$c1, # Species LC1\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        main = \"LC scores for sites\")\ns.label(dcca$li, # Sites LC\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        add = TRUE)\n\n\n\n\n\nCode\ns.label(dcca$c1, # Species LC1\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        main = \"WA scores for sites\")\ns.label(dcca$lsR, # Sites WA scores\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        add = TRUE)\n\n\n\n\n\nCode\ns.corcircle(dcca$corQ,\n            plabels.col = params$colspp)\ns.corcircle(dcca$corR,\n            plabels.col = params$colsite, add = TRUE)\n\n\n\n\n\n\n\n\nScaling type 2\nThis type of scaling preserves the distances between columns.\n\nthe rows (sites) scores can be \\(U^\\star_2\\) (WA scores) or \\(U_2\\) (LC scores)\n\nthe columns (species) scores can be \\(V^\\star_2\\) (WA scores) or \\(V_2\\) (LC scores)\nrows variables (environmental variables) correlations are \\(BS_{B2}\\).\ncolumns variables (species traits) correlations are \\(BS_{C2}\\)\n\nWith the scaling type 2, \\(BS_{B2}\\) represents the correlation between environmental variables and sites and \\(BS_{C2}\\) represents the correlation between species traits and sites.\n\n# LC scores\nU2 &lt;- Ecenter %*% B # rows\nV2 &lt;- Tcenter %*% C %*% Delta # columns\n\n# WA scores\nUstar2 &lt;- solve(Dr) %*% P %*% V2 # rows\nVstar2 &lt;- solve(Dc) %*% t(P) %*% U2 # columns\n\n# Variables scores\nBS_B2 &lt;- B\nBS_C2 &lt;- C %*% Delta\n\n# Normalize\nBS_B2norm &lt;- normalize(BS_B2, 1)\nBS_C2norm &lt;- normalize(BS_C2, 1)\n\n\nall(abs(U2/dcca$l1) - 1 &lt; zero) # LC sites\n\n[1] TRUE\n\nall(abs(V2/dcca$co) - 1 &lt; zero) # LC spp\n\n[1] TRUE\n\nall(abs(Vstar2/dcca$lsQ) - 1 &lt; zero) # WA spp\n\n[1] TRUE\n\nall(abs(Ustar2/dcca$lsR) - 1 &lt; zero) # not stored in ade4\n\n[1] TRUE\n\nall(abs(BS_B2norm/dcca$corR) - 1 &lt; zero) # Not equal, but should be\n\n[1] FALSE\n\nall(abs(BS_C2norm/dcca$corQ) - 1 &lt; zero) # Not equal\n\n[1] FALSE\n\n\n\nPlots\nWe can either plot:\n\nsites as \\(U_2\\) (l1) and species as \\(V_2\\) (co) (left)\nsites as \\(U_2\\) (l1) and species as \\(V^\\star_2\\) (lsQ) (right)\n\n\n\nCode\n# LC scores\nglc &lt;- multiplot(indiv_row = U2, indiv_col = V2, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 # var_row = BS_B2norm, var_row_lab = colnames(E),\n                 # var_col = BS_C2norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"Species LC scores with sites\\nnormed at 1\")\n\n# WA scores\ngwa &lt;- multiplot(indiv_row = U2, indiv_col = Vstar2, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 # var_row = BS_B2norm, var_row_lab = colnames(E),\n                 # var_col = BS_C2norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"Species WA scores with sites\\nnormed at 1\")\n\nglc + gwa + \n  plot_layout(axis_titles = \"collect\")\n\n\n\n\n\nCode\ns.corcircle(BS_B2norm,\n            labels = colnames(E),\n            plabels.col = params$colsite)\ns.corcircle(BS_C2norm,\n            labels = colnames(T_),\n            plabels.col = params$colspp, add = TRUE)\n\n\n\n\n\nThere is no interpretation for species - species traits (\\(V_2\\) - \\(BS_{C2}\\)).\nWith ade4:\n\n\nCode\ns.label(dcca$li, # LC1 sites\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        main = \"LC scores for species\")\ns.label(dcca$co, # LC species\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        add = TRUE)\n\n\n\n\n\nCode\ns.label(dcca$l1, # LC1 sites\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        main = \"WA scores for species\")\ns.label(dcca$lsQ, # WA species\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        add = TRUE)\n\n\n\n\n\n\n\n\nScaling type 3\nThis type of scaling is an intermediate between scalings 1 and 2.\n\nthe rows (sites) scores can be \\(U^\\star_3\\) (WA scores) or \\(U_3\\) (LC scores)\n\nthe columns (species) scores can be \\(V^\\star_3\\) (WA scores) or \\(V_3\\) (LC scores)\nrows variables (environmental variables) correlations are \\(BS_{B3}\\).\ncolumns variables (species traits) correlations are \\(BS_{C3}\\)\n\nWith the scaling type 3, \\(BS_{B3}\\) and \\(BS_{C3}\\) represent the geometric mean of their correlation with species and sites.\n\n# LC scores\nU3 &lt;- Ecenter %*% B %*% Delta^(1/2) # rows\nV3 &lt;- Tcenter %*% C %*% Delta^(1/2) # columns\n\n# WA scores\nUstar3 &lt;- solve(Dr) %*% P %*% V3 # rows\nVstar3 &lt;- solve(Dc) %*% t(P) %*% U3 # columns\n\n# Variables scores\nBS_B3 &lt;- B %*% Delta^(1/2)\nBS_C3 &lt;- C %*% Delta^(1/2)\n\n# Normalize\nBS_B3norm &lt;- normalize(BS_B3, 1)\nBS_C3norm &lt;- normalize(BS_C3, 1)\n\n\nPlots\n\n\nCode\n# LC scores\nglc &lt;- multiplot(indiv_row = U3, indiv_col = V3, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 # var_row = BS_B3norm, var_row_lab = colnames(E),\n                 # var_col = BS_C3norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"LC scores\")\n\n# WA scores\ngwa &lt;- multiplot(indiv_row = Ustar3, indiv_col = Vstar3, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 # var_row = BS_B3norm, var_row_lab = colnames(E),\n                 # var_col = BS_C3norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"WA scores\")\n\nglc + gwa + \n  plot_layout(axis_titles = \"collect\")\n\n\n\n\n\nCode\ns.corcircle(BS_B3norm,\n            labels = colnames(E),\n            plabels.col = params$colsite)\ns.corcircle(BS_C3norm,\n            labels = colnames(T_),\n            plabels.col = params$colspp, add = TRUE)"
  },
  {
    "objectID": "dcCA.html#interpretation",
    "href": "dcCA.html#interpretation",
    "title": "Double constrained Correspondence Analysis (dc-CA)",
    "section": "Interpretation",
    "text": "Interpretation\nThis method finds the linear correlation of row explanatory variables (environmental variables) and the linear correlation of columns explanatory variables (species traits) that maximizes the fourth-corner correlation, i.e. the correlation between these linear combinations of row and columns-variables.\nThere are other related methods, that have been better described and also more used in ecology: RLQ, community weighted means RDA (CMW-RDA).\nContrary to RLQ, dc-CA takes into account the correlation between the row and column variables. Thus, while RLQ can analyze any number of row and column variables, it is not the case with dc-CA the number of row and column variables must not be large compared to the number of rows/columns in the tables. Also, dc-CA maximizes correlation and RLQ maximizes covariance (Braak, Šmilauer, and Dray 2018).\nThe eigenvalues of dc-CA are the squares of the fourth-corner correlations."
  },
  {
    "objectID": "recscal_cca.html",
    "href": "recscal_cca.html",
    "title": "Reciprocal scaling with CCA",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# dc-CA\nsource(here(\"functions/dpcaiv2-ade4.R\"))\n\n# Reciprocal scaling\nsource(here(\"functions/reciprocal.R\"))\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(CAnetwork)\nCode\n# Define bound for comparison to zero\nzero &lt;- 10e-10"
  },
  {
    "objectID": "recscal_cca.html#introduction",
    "href": "recscal_cca.html#introduction",
    "title": "Reciprocal scaling with CCA",
    "section": "Introduction",
    "text": "Introduction\nThis is an extension of reciprocal scaling defined for correspondence analysis by Thioulouse and Chessel (1992) to canonical correspondence analysis.\nHere, we start from two matrices:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables (environmental variabnes) \\(E\\) (\\(r \\times l\\))\n\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- ncol(E))\n\n[1] 6"
  },
  {
    "objectID": "recscal_cca.html#computation",
    "href": "recscal_cca.html#computation",
    "title": "Reciprocal scaling with CCA",
    "section": "Computation",
    "text": "Computation\n\nFrom CCA scores\nWe compute the \\(H_k(i, j)\\) from the LC (for rows = sites) and WA (for columns = species) scores computed with CCA (noted \\(LC\\) and \\(C\\)). This formula is a direct extension of formula (11) in Thioulouse and Chessel (1992) but we replace the CA ordination scores with the CCA ordination scores.\nIn CCA, we have several scores for the sites. The notation \\(LC_k(i)\\) represents the LC scores (or the li of ade4). The \\(C_k(j)\\) are the species scores co.\n\\[\nH_k(i, j) = \\frac{LC_k(i) + C_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\n\nYdf &lt;- as.data.frame(Y)\nca &lt;- dudi.coa(Ydf, \n               scannf = FALSE,\n               nf = min(r - 1, c - 1))\n\nneig &lt;- min(c(r-1, c, l))\ncca &lt;- pcaiv(dudi = ca, \n             df = E,\n             scannf = FALSE,\n             nf = neig)\n\nL_CCA &lt;- cca$li\nC_CCA &lt;- cca$co\n\nlambda_CCA &lt;- cca$eig\nmu_CCA &lt;- 1 + sqrt(lambda_CCA)\n\nWe also compute reciprocal scaling for comparison (to check results, not shown):\n\nrec_cca &lt;- reciprocal.caiv(cca)\n\n\n# Transform matrix to count table\nYfreq &lt;- as.data.frame(as.table(Y))\ncolnames(Yfreq) &lt;- c(\"row\", \"col\", \"Freq\")\n\n# Remove the cells with no observation\nYfreq0 &lt;- Yfreq[-which(Yfreq$Freq == 0),]\nYfreq0$colind &lt;- match(Yfreq0$col, colnames(Y)) # match index and species names\n\n\n# Initialize results matrix\nH &lt;- matrix(nrow = nrow(Yfreq0), \n            ncol = length(lambda_CCA))\n\nfor (k in 1:length(lambda_CCA)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H[ind, k] &lt;- (L_CCA[i, k] + C_CCA[j, k])/sqrt(2*lambda_CCA[k]*mu_CCA[k])\n    ind &lt;- ind + 1\n  }\n}\n\n\n\nFrom canonical correlation analysis\nTo perform the canonical correlation analysis, we compute the inflated tables \\(R\\) (\\(n_{\\bar{0}} \\times l\\)) and \\(C\\) (\\(n_{\\bar{0}} \\times c\\)) from \\(Y\\) (\\(r \\times c\\)) and \\(E\\) (\\(r \\times l\\)). The difference with CA is that we use \\(E\\) instead of \\(Y\\) to compute the inflated table \\(R\\). \\(R\\) is equivalent to \\(E\\) where rows of \\(E\\) are duplicated as many times as there are correspondences in \\(Y\\).\nWe take the frequency table defined before and use it to compute the inflated tables (with weights):\n\n# Create indicator tables\ntabR &lt;- acm.disjonctif(as.data.frame(Yfreq0$row))\ntabR &lt;- as.matrix(tabR) %*% as.matrix(E) # duplicate rows of E according to the correspondences of Y\ntabC &lt;- acm.disjonctif(as.data.frame(Yfreq0$col))\ncolnames(tabC) &lt;- colnames(Y)\n\n# Get weights\nwt &lt;- Yfreq0$Freq\n\nBelow are the first lines of tables \\(R\\) and \\(C\\):\n\n\nCode\nknitr::kable(head(tabR, 30))\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n0\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n0\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n0\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n0\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n0\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n0\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n1\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n1\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n1\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n1\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n1\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n1\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n\n\n\nCode\nknitr::kable(head(tabC, 30))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\nThen, we perform a canonical correlation on the scaled tables \\(R_{scaled}\\) and \\(C_{scaled}\\). We find the coefficients \\(\\rho\\) and \\(\\gamma\\) maximizing the correlation between the scores \\(S_R = R_{scaled} \\rho\\) and \\(S_C = C_{scaled} \\gamma\\).\n\n# Center tables\ntabR_scaled &lt;- scalewt(tabR, wt, \n                       scale = FALSE)\ntabC_scaled &lt;- scalewt(tabC, wt, \n                       scale = FALSE)\n\nres &lt;- cancor(diag(sqrt(wt)) %*% tabR_scaled, \n              diag(sqrt(wt)) %*% tabC_scaled, \n              xcenter = FALSE, ycenter = FALSE)\n# res gives the coefficients of the linear combinations that maximizes the correlation between the 2 dimensions\ndim(res$xcoef) # l columns -&gt; R_scaled is of full rank\n\n[1] 6 6\n\ndim(res$ycoef) # c-1 columns -&gt; C_scaled is not of full rank\n\n[1] 20 20\n\n# Compute these scores from this coef\nscoreR &lt;- tabR_scaled[, 1:l]  %*% res$xcoef\nscoreC &lt;- tabC_scaled[, 1:(c-1)]  %*% res$ycoef\n\nWe have \\(H = (S_R + S_C)_{scaled}\\).\n\n# Get H\nscoreRC &lt;- scoreR[, 1:l] + scoreC[, 1:l] # here l &lt; c-1 so l axes\nscoreRC_scaled &lt;- scalewt(scoreRC, wt = wt)\n\n\n# Check result\nall(abs(scoreRC_scaled/H) - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nPlot RC scores\n\n\nCode\nmultiplot(indiv_row = H, \n          indiv_row_lab = paste0(\"site \", Yfreq0$row, \"/\", Yfreq0$col),\n          row_color = \"black\", eig = lambda_CCA)"
  },
  {
    "objectID": "recscal_cca.html#conditional-means-and-variances-from-rc-scores",
    "href": "recscal_cca.html#conditional-means-and-variances-from-rc-scores",
    "title": "Reciprocal scaling with CCA",
    "section": "Conditional means and variances from RC scores",
    "text": "Conditional means and variances from RC scores\n\n\n\n\n\n\nTL;DR\n\n\n\nOnce we have the correspondences scores, we can group them by row (site) or column (species) to compute conditional summary statistics:\n\nconditional mean for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional variance for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional covariance for site \\(i\\) or species \\(j\\) (between axes \\(k\\) and \\(l\\))\n\nThese conditional statistics can be computed using \\(H_k(i,j)\\) or using the CA scores:\nFormulas using \\(H_k(i,j)\\)\nThe means and variances are simply the weighted means/variances of the \\(H_k(i, j)\\) for a fixed \\(i\\) or \\(j\\).\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[m_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} H_k(i,j)\\]\n\\[m_k(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} H_k(i,j)\\]\n\n\nVariance for axis \\(k\\)\n\\[s_k^2(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} \\left(H_k(i,j) - m_k(i)\\right)^2\\]\n\\[s_k^2(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} \\left(H_k(i,j) - m_k(j)\\right)^2\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\\[c_{kl}(i) = \\frac{1}{y_{i \\cdot}}\\sum_{j=1}^c y_{ij}H_k(i, j)H_l(i, j) - m_k(i)m_l(i)\\]\n\\[c_{kl}(j) = \\frac{1}{y_{\\cdot j}}\\sum_{i=1}^r y_{ij}H_k(i, j)H_l(i, j) - m_k(j)m_l(j)\\]\n\n\n\nFormulas using CCA scores\nNote that the LC score (notation: \\(LC\\)) is used for the species variance and the WA score (notation: \\(L\\)) for the sites variance.\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[m_k(i) =  \\frac{1}{\\sqrt{2 \\mu_k}} \\times (LC1_k(i) + L_k(i))\\]\n\\[m_k(j) = \\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}} C_k(j)\\]\n\n\nVariance for axis \\(k\\)\n\\[s^2_k(i) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} C_k^2(j) \\right) - \\lambda_k L_k^2(i) \\right)\\]\n\\[s^2_k(j) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} LC_k^2(i) \\right) - \\lambda_k C_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\n\nLet’s start from the means/variances computed from the RC scores (\\(H\\)).\n\nfac &lt;- sqrt(mu_CCA)/sqrt(2*lambda_CCA)\nn &lt;- sum(Y)\n\n\nFor rows = sites\nBelow is a graphical illustration of scoreRC grouped by rows:\n\ns.class(scoreRC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        plabels.col = params$colsite, \n        main = \"With RC score (points = correspondences)\")\n\n\n\n\n\nFormula with RC scores (definition)\nWe compute the groupwise mean and variance.\n\n# With scaled values\nmrowsRC &lt;- meanfacwt(scoreRC_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\nmrowsRC/(as.matrix(cca$l1 + cca$ls) %*% diag(1/sqrt(2*mu_CCA)))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1 -1  1  1\n2   1  1  1 -1  1  1\n3   1  1  1 -1  1  1\n4   1  1  1 -1  1  1\n5   1  1  1 -1  1  1\n6   1  1  1 -1  1  1\n7   1  1  1 -1  1  1\n8   1  1  1 -1  1  1\n9   1  1  1 -1  1  1\n10  1  1  1 -1  1  1\n11  1  1  1 -1  1  1\n12  1  1  1 -1  1  1\n13  1  1  1 -1  1  1\n14  1  1  1 -1  1  1\n15  1  1  1 -1  1  1\n16  1  1  1 -1  1  1\n17  1  1  1 -1  1  1\n18  1  1  1 -1  1  1\n19  1  1  1 -1  1  1\n20  1  1  1 -1  1  1\n21  1  1  1 -1  1  1\n22  1  1  1 -1  1  1\n23  1  1  1 -1  1  1\n24  1  1  1 -1  1  1\n25  1  1  1 -1  1  1\n26  1  1  1 -1  1  1\n\n\n\n# With non-scaled values\nmrowsRC_ns &lt;- meanfacwt(scoreRC, fac = Yfreq0$row, wt = Yfreq0$Freq)\nmrowsRC_ns/((cca$l1 + cca$ls)*1/sqrt(n))\n\n   RS1 RS2 RS3 RS4 RS5 RS6\n1    1   1   1  -1   1   1\n2    1   1   1  -1   1   1\n3    1   1   1  -1   1   1\n4    1   1   1  -1   1   1\n5    1   1   1  -1   1   1\n6    1   1   1  -1   1   1\n7    1   1   1  -1   1   1\n8    1   1   1  -1   1   1\n9    1   1   1  -1   1   1\n10   1   1   1  -1   1   1\n11   1   1   1  -1   1   1\n12   1   1   1  -1   1   1\n13   1   1   1  -1   1   1\n14   1   1   1  -1   1   1\n15   1   1   1  -1   1   1\n16   1   1   1  -1   1   1\n17   1   1   1  -1   1   1\n18   1   1   1  -1   1   1\n19   1   1   1  -1   1   1\n20   1   1   1  -1   1   1\n21   1   1   1  -1   1   1\n22   1   1   1  -1   1   1\n23   1   1   1  -1   1   1\n24   1   1   1  -1   1   1\n25   1   1   1  -1   1   1\n26   1   1   1  -1   1   1\n\n\nVariances\n\n# With scaled values\nvarrowsRC &lt;- varfacwt(scoreRC_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n# With non-scaled values\nvarrowsRC_ns &lt;- varfacwt(scoreRC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n\n\nVariance formula with CCA scores\n\n# Get marginal counts\nyi_ &lt;- rowSums(Y)\ny_j &lt;- colSums(Y)\n\nvarrowsCCA &lt;- matrix(nrow = r, \n                     ncol = l)\n\nfor (i in 1:r) {\n  # Get CCA scores for site i\n  Li &lt;- cca$ls[i, ]\n  \n  # Compute the part with the sum on Cj\n  # we add all coordinates Cj^2 weighted by the number of observations on site i\n  sumCj &lt;- t(Y[i, ]) %*% as.matrix(cca$co)^2\n\n  # Fill i-th row with site i variance along each axis\n  varrowsCCA[i, ] &lt;- (1/(2*lambda_CCA*mu_CCA)) * (((1/yi_[i])*sumCj) - lambda_CCA*as.numeric(Li)^2)\n}\n\n\nvarrowsRC/varrowsCCA\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\n\n\n\nFor columns = species\nBelow is an illustration of the RC scores grouped by species.\n\ns.class(scoreRC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        plabels.col = params$colspp, \n        main = \"With RC score (points = correspondences)\")\n\n\n\n\n\nFormula with RC scores (definition)\n\nmcolsRC &lt;- meanfacwt(scoreRC_scaled, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsRC/(as.matrix(cca$co) %*% diag(fac))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1 -1  1  1\n2   1  1  1 -1  1  1\n3   1  1  1 -1  1  1\n4   1  1  1 -1  1  1\n5   1  1  1 -1  1  1\n6   1  1  1 -1  1  1\n7   1  1  1 -1  1  1\n8   1  1  1 -1  1  1\n9   1  1  1 -1  1  1\n10  1  1  1 -1  1  1\n11  1  1  1 -1  1  1\n12  1  1  1 -1  1  1\n13  1  1  1 -1  1  1\n14  1  1  1 -1  1  1\n15  1  1  1 -1  1  1\n16  1  1  1 -1  1  1\n17  1  1  1 -1  1  1\n18  1  1  1 -1  1  1\n19  1  1  1 -1  1  1\n20  1  1  1 -1  1  1\n21  1  1  1 -1  1  1\n\n\n\nmcolsRC_ns &lt;- meanfacwt(scoreRC, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsRC_ns/cca$co\n\n         Comp1     Comp2     Comp3      Comp4     Comp5    Comp6\nsp1  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp2  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp3  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp4  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp5  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp6  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp7  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp8  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp9  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp10 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp11 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp12 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp13 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp14 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp15 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp16 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp17 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp18 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp19 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp21 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp22 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\n\n\n\n# With scaled values\nvarcolsRC &lt;- varfacwt(scoreRC_scaled, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\n# With non-scaled values\nvarcolsRC_ns &lt;- varfacwt(scoreRC, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\n\n\nVariance formula with CCA scores\n\nvarcolsCCA &lt;- matrix(nrow = c, \n                     ncol = l)\n\nfor (j in 1:c) {\n  # Get CCA scores for species j\n  Cj &lt;- cca$co[j, ]\n  \n  # Compute the part with the sum on Li\n  # we add all coordinates Li^2 weighted by the number of observations on species j\n  sumLi &lt;- t(Y[, j]) %*% as.matrix(cca$li)^2\n\n  # Fill i-th row with site i variance along each axis\n  varcolsCCA[j, ] &lt;- (1/(2*lambda_CCA*mu_CCA)) * (((1/y_j[j])*sumLi) - lambda_CCA*as.numeric(Cj)^2)\n}\n\n\nvarcolsRC/varcolsCCA\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   0  0  0  0  0  0\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  0  0  0  0  0  0\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n\nvarcolsRC_ns/(varcolsCCA %*% diag(2*mu_CCA/n))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   0  0  0  0  0  0\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  0  0  0  0  0  0\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1"
  },
  {
    "objectID": "recscal_cca.html#conditional-means-and-variances-from-r-scores-and-c-scores",
    "href": "recscal_cca.html#conditional-means-and-variances-from-r-scores-and-c-scores",
    "title": "Reciprocal scaling with CCA",
    "section": "Conditional means and variances from R scores and C scores",
    "text": "Conditional means and variances from R scores and C scores\n\n\n\n\n\n\nTL;DR\n\n\n\nFor the scores computed with R scores and C scores, we have 3 types of formulas:\n\ndefinition (weighted mean/variance/covariance)\nformulas using the CCA scores\nrelation with the RC scores\n\nHere, we don’t show the definition.\nFormulas using CCA scores\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{1}{\\sqrt{n}} LC1_k(i)\\] (\\(LC1 =\\) normed LC score ($l1))\n\\[mR_k(j) =   \\frac{1}{\\sqrt{n}} C_k(j)\\]\n\n\nVariance for axis \\(k\\)\nNone\n\\[sR_k^2(j) = \\frac{1}{n\\lambda_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} LC_k^2(i) \\right) - \\lambda_k C_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[\\frac{1}{\\sqrt{n}} L_k(i)\\] (\\(L_k(i) =\\) WA score ($ls))\n\\[\\frac{1}{\\sqrt{n}} C1_k(j)\\] (\\(C1_k(j) =\\) normed species score ($c1))\n\n\nVariance for axis \\(k\\)\n\\[sC_k^2(i) = \\frac{1}{n\\lambda_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} C_k^2(j) \\right) - \\lambda_k L_k^2(i) \\right)\\]\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\nRelation between RC scores and R score / C score\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(i) - \\frac{1}{\\sqrt{n}} L_k(i)\\]\n\\[mR_k(j) = \\frac{\\sqrt{2 \\lambda_k}}{\\sqrt{n \\mu_k}} m_k(j)\\]\n\n\nVariance for axis \\(k\\)\nNone\n\\(sR^2_k(j) = \\frac{2\\mu_k}{n} s^2_k(j)\\)\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mC_k(i) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(i) - \\frac{1}{\\sqrt{n}} LC1_k(i)\\]\n\\[mC_k(j) = \\frac{\\sqrt{2}}{\\sqrt{n \\mu_k}} m_k(j)\\]\n\n\nVariance for axis \\(k\\)\n\\(sC^2_k(i) = \\frac{2\\mu_k}{n} s^2_k(i)\\)\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\n\n\nFor rows = sites (group per row)\nIn this section, we compute means and variances per row (for sites).\n\nscoreC\nBelow is a graphical illustration of scoreC grouped by rows:\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colspp,\n        plabels.col = params$colsite, \n        main = \"With C score (points = species scores)\")\n\n\n\n\nWe compute the following mean: \\(mC_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} \\text{scoreC}_k(i,j)\\). To compute these conditional means, we use the meanfacwt function from the ade4 package.\n\nmrowsC &lt;- meanfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nThen we compare this to a score obtained from CCA.\n\nmrowsC/(cca$ls * 1/sqrt(n))\n\n   Axis1 Axis2 Axis3 Axis4 Axis5 Axis6\n1      1     1     1    -1     1     1\n2      1     1     1    -1     1     1\n3      1     1     1    -1     1     1\n4      1     1     1    -1     1     1\n5      1     1     1    -1     1     1\n6      1     1     1    -1     1     1\n7      1     1     1    -1     1     1\n8      1     1     1    -1     1     1\n9      1     1     1    -1     1     1\n10     1     1     1    -1     1     1\n11     1     1     1    -1     1     1\n12     1     1     1    -1     1     1\n13     1     1     1    -1     1     1\n14     1     1     1    -1     1     1\n15     1     1     1    -1     1     1\n16     1     1     1    -1     1     1\n17     1     1     1    -1     1     1\n18     1     1     1    -1     1     1\n19     1     1     1    -1     1     1\n20     1     1     1    -1     1     1\n21     1     1     1    -1     1     1\n22     1     1     1    -1     1     1\n23     1     1     1    -1     1     1\n24     1     1     1    -1     1     1\n25     1     1     1    -1     1     1\n26     1     1     1    -1     1     1\n\n\n??????? axis 4 ?????\n\nmrowsC[, 1:k]/(mrowsRC %*% diag(sqrt(2*mu_CCA/n)) - 1/sqrt(n)*cca$l1)\n\n   RS1 RS2 RS3          RS4 RS5 RS6\n1    1   1   1   0.09963914   1   1\n2    1   1   1   0.14907635   1   1\n3    1   1   1   1.25974578   1   1\n4    1   1   1   0.14027240   1   1\n5    1   1   1   0.09215390   1   1\n6    1   1   1  -0.12717730   1   1\n7    1   1   1  -0.02156703   1   1\n8    1   1   1   0.16043829   1   1\n9    1   1   1 -27.85047682   1   1\n10   1   1   1   0.11861683   1   1\n11   1   1   1  -0.05434566   1   1\n12   1   1   1   0.29479392   1   1\n13   1   1   1   0.42847770   1   1\n14   1   1   1  -0.15449359   1   1\n15   1   1   1  -0.04815589   1   1\n16   1   1   1   0.69954078   1   1\n17   1   1   1   0.05783956   1   1\n18   1   1   1   0.13425888   1   1\n19   1   1   1   0.49606870   1   1\n20   1   1   1   0.29537502   1   1\n21   1   1   1   0.15333987   1   1\n22   1   1   1   0.88218079   1   1\n23   1   1   1   0.16678695   1   1\n24   1   1   1   0.45600697   1   1\n25   1   1   1  -4.87670247   1   1\n26   1   1   1   5.94689846   1   1\n\n\nNow let’s compute the variance of scoreC per row:\n\nvarrowsC &lt;- varfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nCompare it to the variance of the RC score:\n\nvarrowsC[, 1:ncol(varrowsRC)]/(varrowsRC %*% diag(2*mu_CCA/n))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\nWe can use this relationship to find the formula using CCA scores:\n\nvarrowsC_CCA &lt;- matrix(nrow = r, \n                       ncol = k)\n\nfor (i in 1:r) {\n  # Get CA scores for site i\n  Li &lt;- cca$ls[i, ]\n  \n  # Compute the part with the sum on Cj\n  # we add all coordinates Cj^2 weighted by the number of observations on site i\n  sumCj &lt;- t(Y[i, ]) %*% as.matrix(cca$co)^2\n\n  # Fill i-th row with site i variance along each axis\n  varrowsC_CCA[i, ] &lt;- 1/(n*lambda_CCA)*((1/yi_[i])*sumCj - lambda_CCA*as.numeric(Li)^2)\n}\n\n\nvarrowsC[, 1:ncol(varrowsRC)]/varrowsC_CCA\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\n\n\nscoreR\nNow, we compute the mean per row (site) from the row (sites) scores.\nBelow is a graphical illustration of scoreR grouped by rows:\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite, \n        main = \"With R score (points = sites scores)\")\n\n\n\n\nAll points of the same site ares superimposed.\n\nmrowsR &lt;- meanfacwt(scoreR, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nmrowsR/(cca$l1*1/sqrt(n))\n\n   RS1 RS2 RS3 RS4 RS5 RS6\n1    1   1   1  -1   1   1\n2    1   1   1  -1   1   1\n3    1   1   1  -1   1   1\n4    1   1   1  -1   1   1\n5    1   1   1  -1   1   1\n6    1   1   1  -1   1   1\n7    1   1   1  -1   1   1\n8    1   1   1  -1   1   1\n9    1   1   1  -1   1   1\n10   1   1   1  -1   1   1\n11   1   1   1  -1   1   1\n12   1   1   1  -1   1   1\n13   1   1   1  -1   1   1\n14   1   1   1  -1   1   1\n15   1   1   1  -1   1   1\n16   1   1   1  -1   1   1\n17   1   1   1  -1   1   1\n18   1   1   1  -1   1   1\n19   1   1   1  -1   1   1\n20   1   1   1  -1   1   1\n21   1   1   1  -1   1   1\n22   1   1   1  -1   1   1\n23   1   1   1  -1   1   1\n24   1   1   1  -1   1   1\n25   1   1   1  -1   1   1\n26   1   1   1  -1   1   1\n\n\nThe variance is null.\n\n\n\nFor columns = species (group per column)\n\nscoreC\nWe group the scoreC per species. Below is an illustration:\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp, \n        main = \"With C score (points = species scores)\")\n\n\n\n\n\nmcolsC &lt;- meanfacwt(scoreC, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsC/(cca$c1*1/sqrt(n))\n\n     CS1 CS2 CS3 CS4 CS5 CS6\nsp1    1   1   1  -1   1   1\nsp2    1   1   1  -1   1   1\nsp3    1   1   1  -1   1   1\nsp4    1   1   1  -1   1   1\nsp5    1   1   1  -1   1   1\nsp6    1   1   1  -1   1   1\nsp7    1   1   1  -1   1   1\nsp8    1   1   1  -1   1   1\nsp9    1   1   1  -1   1   1\nsp10   1   1   1  -1   1   1\nsp11   1   1   1  -1   1   1\nsp12   1   1   1  -1   1   1\nsp13   1   1   1  -1   1   1\nsp14   1   1   1  -1   1   1\nsp15   1   1   1  -1   1   1\nsp16   1   1   1  -1   1   1\nsp17   1   1   1  -1   1   1\nsp18   1   1   1  -1   1   1\nsp19   1   1   1  -1   1   1\nsp21   1   1   1  -1   1   1\nsp22   1   1   1  -1   1   1\n\n\nThe variance is null.\n\n\nscoreR\nBelow are the scoreR grouped by column:\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colsite,\n        plabels.col = params$colspp, \n        main = \"With R score (points = sites scores)\")\n\n\n\n\n\nmcolsR &lt;- meanfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsR/(cca$co*1/sqrt(n))\n\n     Comp1 Comp2 Comp3 Comp4 Comp5 Comp6\nsp1      1     1     1    -1     1     1\nsp2      1     1     1    -1     1     1\nsp3      1     1     1    -1     1     1\nsp4      1     1     1    -1     1     1\nsp5      1     1     1    -1     1     1\nsp6      1     1     1    -1     1     1\nsp7      1     1     1    -1     1     1\nsp8      1     1     1    -1     1     1\nsp9      1     1     1    -1     1     1\nsp10     1     1     1    -1     1     1\nsp11     1     1     1    -1     1     1\nsp12     1     1     1    -1     1     1\nsp13     1     1     1    -1     1     1\nsp14     1     1     1    -1     1     1\nsp15     1     1     1    -1     1     1\nsp16     1     1     1    -1     1     1\nsp17     1     1     1    -1     1     1\nsp18     1     1     1    -1     1     1\nsp19     1     1     1    -1     1     1\nsp21     1     1     1    -1     1     1\nsp22     1     1     1    -1     1     1\n\n\n\nvarcolsR &lt;- varfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\n\nvarcolsR/(varcolsRC %*% diag(2*mu_CCA/n))\n\n    X1  X2  X3  X4  X5  X6\n1    1   1   1   1   1   1\n2    1   1   1   1   1   1\n3    1   1   1   1   1   1\n4    1   1   1   1   1   1\n5    1   1   1   1   1   1\n6    1   1   1   1   1   1\n7  NaN NaN NaN NaN NaN NaN\n8    1   1   1   1   1   1\n9    1   1   1   1   1   1\n10   1   1   1   1   1   1\n11   1   1   1   1   1   1\n12   1   1   1   1   1   1\n13 NaN NaN NaN NaN NaN NaN\n14   1   1   1   1   1   1\n15   1   1   1   1   1   1\n16   1   1   1   1   1   1\n17   1   1   1   1   1   1\n18   1   1   1   1   1   1\n19   1   1   1   1   1   1\n20   1   1   1   1   1   1\n21   1   1   1   1   1   1\n\n\nSimilarly we can use this relationship to compute the variance directly from the CCA scores (see in table)."
  },
  {
    "objectID": "recscal_cca.html#non-reciprocal-score",
    "href": "recscal_cca.html#non-reciprocal-score",
    "title": "Reciprocal scaling with CCA",
    "section": "Non-reciprocal score",
    "text": "Non-reciprocal score\nWe can remain in the 2 biplots showing \\(V\\) with \\(U^\\star\\) (c1 and ls) (scaling type 1 = rows niches) and \\(U\\) and \\(V^\\star\\) (co and l1) (scaling type 2 = column niches).\n\n\\(H_1\\) (scaling type 1, rows niches)\nTo do that, we define the “CA-correspondences” \\(h1_k(i, j)\\) for scaling type 1:\n\\[h1_k(i, j) = \\frac{u^\\star_k(i) + v_k(j)}{2}\\]\n\n\nCode\n# Initialize results matrix\nH1 &lt;- matrix(nrow = nrow(Yfreq0), \n             ncol = length(lambda_CCA))\n\nfor (k in 1:length(lambda_CCA)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H1[ind, k] &lt;- (cca$ls[i, k] + cca$c1[j, k])/2\n    ind &lt;- ind + 1\n  }\n}\n\n\n\n\nCode\ncorresp &lt;- paste(Yfreq0$row, Yfreq0$col, sep = \"-\")\nmultiplot(indiv_row = as.data.frame(H1), \n          indiv_row_lab = corresp,\n          row_color = \"black\")\n\n\n\n\n\n\n# Groupwise mean\nmrows_nr &lt;- meanfacwt(H1, fac = Yfreq0$row, wt = Yfreq0$Freq)\nall(abs(abs(mrows_nr/cca$ls) - 1) &lt; zero)\n\n[1] TRUE\n\nhead(mrows_nr/mrowsRC) # It is different from the reciprocal scaling means\n\n           X1         X2          X3         X4         X5           X6\n1 -1.91923728  0.6120825  0.08846083 -0.2916656  0.4261649 0.9774285987\n2  0.78867737 -0.4889211  0.67852968 -0.4176046  0.7369286 1.6630053256\n3 -0.60324520  1.1089565 -2.31301798 -1.7944394 -0.1852356 0.0005468304\n4  0.02454259  0.4747999  0.54737729 -0.3959762 -0.8024670 0.2321154464\n5  0.07328637  0.2838636  0.02034193 -0.2716035  0.1932532 0.1820447750\n6  0.38184917  0.4689434  0.07004988  0.4690175  0.1447035 0.2326957266\n\n# Groupwise variance\nvarrows_nr &lt;- varfacwt(H1, fac = Yfreq0$row, wt = Yfreq0$Freq)\nres &lt;- varrows_nr %*% diag(2/mu_CCA) # Factor 2/mu\nall(abs(res/varrowsRC) - 1 &lt; zero)\n\n[1] TRUE\n\n# We could also multiply H1 before computing the variance\nH1_scaled &lt;- H1 %*% diag(sqrt(2/mu_CCA)) # Factor sqrt(2/mu)\nvarrows_nr_scaled &lt;- varfacwt(H1_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\nall(abs(varrows_nr_scaled/varrowsRC - 1) &lt; zero)\n\n[1] TRUE\n\n\n\n\nCode\ns.class(H1, \n        fac = Yfreq0$row, plabels.col = params$colsite, \n        main = \"Non-reciprocal scaling\")\n\n\n\n\n\nCode\ns.class(H,\n        fac = Yfreq0$row, plabels.col = params$colsite, \n        main = \"Reciprocal scaling\")\n\n\n\n\n\n\\(h1_k(i, j)\\) can also be defined from the canonical correlation scores:\n\\[h1_k(i, j) = \\frac{\\sqrt{n} (R \\bar{S_C} + S_C)}{2}\\] where \\(R \\bar{S_C}\\) corresponds to the duplicated version of \\(\\overline{S_C}\\), the mean of C-scores by rows.\n\nres &lt;- meanfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq) # get the mean of scoreC by row\ntabR &lt;- as.matrix(acm.disjonctif(as.data.frame(Yfreq0$row)))\nscoreRls &lt;- tabR %*% res # Duplicate means according to correspondences of R\n\n# Find back the formula from the scores \nH1_cancor &lt;- (sqrt(n)*(scoreRls[, 1:l] + scoreC[, 1:l]))/2\n# H1_cancor_scaled &lt;- scalewt(H1_cancor, wt = wt/sum(wt))\n\nall(abs(abs(H1_cancor/H1) - 1) &lt; zero)\n\n[1] TRUE\n\n\n\n\n\\(H_2\\) (scaling type 2, columns niches)\nWe define the “CA-correspondences” \\(h2_k(i, j)\\) for scaling type 2:\n\\[h2_k(i, j) = \\frac{u_k(i) + v^\\star_k(j)}{2}\\]\n\n\nCode\n# Initialize results matrix\nH2 &lt;- matrix(nrow = nrow(Yfreq0), \n             ncol = length(lambda_CCA))\n\nfor (k in 1:length(lambda_CCA)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H2[ind, k] &lt;- (cca$l1[i, k] + cca$co[j, k])/2\n    ind &lt;- ind + 1\n  }\n}\n\n\n\n\nCode\ncorresp &lt;- paste(Yfreq0$row, Yfreq0$col, sep = \"-\")\nmultiplot(indiv_row = as.data.frame(H2), \n          indiv_row_lab = corresp,\n          row_color = \"black\")\n\n\n\n\n\n\n# Groupwise mean\nmcols_nr &lt;- meanfacwt(H2, fac = Yfreq0$col, wt = Yfreq0$Freq)\nall(abs(abs(mcols_nr/cca$co) - 1) &lt; zero)\n\n[1] TRUE\n\nres &lt;- mcols_nr %*% diag(sqrt(mu_CCA)/sqrt(2*lambda_CCA)) # factor sqrt(mu)/sqrt(2*lambda)\nall(abs(res/mcolsRC - 1) &lt; zero) \n\n[1] FALSE\n\n# Groupwise variance\nvarcols_nr &lt;- varfacwt(H2, fac = Yfreq0$col, wt = Yfreq0$Freq)\nvarcols_nr_scaled &lt;- varcols_nr %*% diag(2/(mu_CCA)) # factor 2/mu\nall(abs(varcols_nr_scaled/varcolsRC - 1) &lt; zero)\n\n[1] NA\n\n\n\n\nCode\ns.class(H2, fac = Yfreq0$row, main = \"Non-reciprocal scaling\")\n\n\n\n\n\nCode\ns.class(H, fac = Yfreq0$row, main = \"Reciprocal scaling\")\n\n\n\n\n\n\\(h2_k(i, j)\\) can also be defined from the canonical correlation scores:\n\\[h2_k(i, j) = \\frac{\\sqrt{n} (S_R + S_C  \\Lambda^{1/2})}{2}\\]\n\n# Find back the formula from the scores \nH2_cancor &lt;- (sqrt(n)*(scoreR[, 1:l] + scoreC[, 1:l] %*% diag(lambda_CCA^(1/2))))/2\n\nall(abs(abs(H2_cancor/H2) - 1) &lt; zero)\n\n[1] TRUE"
  }
]