[
  {
    "objectID": "recscal_dcca.html",
    "href": "recscal_dcca.html",
    "title": "Reciprocal scaling with dcCA",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# dc-CA\nsource(here(\"functions/dpcaiv2-ade4.R\"))\n\n# Reciprocal scaling\nsource(here(\"functions/reciprocal.R\"))\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nsource(here(\"functions/plot.R\"))\nlibrary(gridExtra)"
  },
  {
    "objectID": "recscal_dcca.html#introduction",
    "href": "recscal_dcca.html#introduction",
    "title": "Reciprocal scaling with dcCA",
    "section": "Introduction",
    "text": "Introduction\nThis is an extension of reciprocal scaling defined for correspondence analysis by Thioulouse and Chessel (1992) to double-constrained correspondence analysis.\nHere, we have 3 matrices:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables \\(E\\) (\\(r \\times l\\))\nA matrix of predictor variables \\(T\\) (\\(c \\times k\\))\n\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- ncol(E))\n\n[1] 6\n\n(k &lt;- ncol(T_))\n\n[1] 7"
  },
  {
    "objectID": "recscal_dcca.html#computation",
    "href": "recscal_dcca.html#computation",
    "title": "Reciprocal scaling with dcCA",
    "section": "Computation",
    "text": "Computation\n\nFrom dcCA scores\nWe compute the \\(H_k(i, j)\\) from the LC scores computed with dcCA (noted \\(LC\\) for rows LS scores and \\(CC\\) for columns LC scores). This formula is a direct extension of formula (11) in Thioulouse and Chessel (1992) but we replace the ordination scores obtained with CA with the ordination scores obtained with dcCA.\n\\[\nH_k(i, j) = \\frac{LC_k(i) + CC_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\n\nYdf &lt;- as.data.frame(Y)\nca &lt;- dudi.coa(Ydf, \n               scannf = FALSE,\n               nf = min(r - 1, c - 1))\n\nneig &lt;- min(c(k, l))\ndcca &lt;- dpcaiv2(dudi = ca, \n                dfR = E,\n                dfQ = T_,\n                scannf = FALSE, \n                nf = neig)\n\nL_dcca &lt;- dcca$li\nC_dcca &lt;- dcca$co\n\nlambda_dcca &lt;- dcca$eig\nmu_dcca &lt;- 1 + sqrt(lambda_dcca)\n\nWe also compute reciprocal scaling for comparison:\n\nrec_dcca &lt;- reciprocal.dpcaiv(dcca)\n\n\n# Transform matrix to count table\nYfreq &lt;- as.data.frame(as.table(Y))\ncolnames(Yfreq) &lt;- c(\"row\", \"col\", \"Freq\")\n\n# Remove the cells with no observation\nYfreq0 &lt;- Yfreq[-which(Yfreq$Freq == 0),]\nYfreq0$colind &lt;- match(Yfreq0$col, colnames(Y)) # match index and species names\n\n\n# Initialize results matrix\nH &lt;- matrix(nrow = nrow(Yfreq0), \n            ncol = length(lambda_dcca))\n\nfor (kl in 1:length(lambda_dcca)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H[ind, kl] &lt;- (L_dcca[i, kl] + C_dcca[j, kl])/sqrt(2*lambda_dcca[kl]*mu_dcca[kl])\n    ind &lt;- ind + 1\n  }\n}\n\n\n\nFrom canonical correlation analysis\nTo perform the canonical correlation analysis, we compute the inflated tables \\(R\\) (\\(\\omega \\times l\\)) and \\(C\\) (\\(\\omega \\times k\\)) from \\(E\\) (\\(r \\times l\\)) and \\(T\\) (\\(r \\times k\\)). \\(R\\) and \\(C\\) are respectively equivalents to \\(E\\) and \\(T\\) where rows of are duplicated as many times as there are correspondences in \\(Y\\).\nWe take the frequency table defined before and use it to compute the inflated tables (with weights):\n\n# Create indicator tables\ntabR &lt;- acm.disjonctif(as.data.frame(Yfreq0$row))\ntabR &lt;- as.matrix(tabR) %*% as.matrix(E)\ntabC &lt;- acm.disjonctif(as.data.frame(Yfreq0$col))\ntabC &lt;- as.matrix(tabC) %*% as.matrix(T_)\n\n# Get weights\nwt &lt;- Yfreq0$Freq\n\nBelow are the first lines of tables \\(R\\) and \\(C\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n0\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n0\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n0\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n0\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n0\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n0\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n1\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n1\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n1\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n1\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n1\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n1\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n\n\n\n\n\n\nbiog\nforag\nmass\ndiet\nmove\nnest\neggs\n\n\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n2\n2\n3\n1\n2\n2\n\n\n1\n1\n1\n2\n1\n2\n2\n\n\n1\n1\n1\n2\n1\n2\n2\n\n\n1\n1\n1\n2\n1\n2\n2\n\n\n1\n1\n1\n2\n1\n2\n2\n\n\n\n\n\nThen, we perform a canonical correlation on the scaled tables \\(R_{scaled}\\) and \\(C_{scaled}\\). We find the coefficients \\(\\rho\\) and \\(\\gamma\\) maximizing the correlation between the scores \\(S_R = R_{scaled} \\rho\\) and \\(S_C = C_{scaled} \\gamma\\).\n\n# Center tables\ntabR_scaled &lt;- scalewt(tabR, wt, \n                       scale = FALSE)\ntabC_scaled &lt;- scalewt(tabC, wt, \n                       scale = FALSE)\n\nres &lt;- cancor(diag(sqrt(wt)) %*% tabR_scaled, \n              diag(sqrt(wt)) %*% tabC_scaled, \n              xcenter = FALSE, ycenter = FALSE)\n# res gives the coefficients of the linear combinations that maximizes the correlation between the 2 dimensions\ndim(res$xcoef) # l columns -&gt; R_scaled is of full rank\n\n[1] 6 6\n\ndim(res$ycoef) # k columns -&gt; C_scaled is of full rank\n\n[1] 7 7\n\n# Compute these scores from this coef\nscoreR &lt;- tabR_scaled[, 1:l]  %*% res$xcoef\nscoreC &lt;- tabC_scaled[, 1:k]  %*% res$ycoef\n\nWe have \\(H = (S_R + S_C)_{scaled}\\).\n\n# Get H\nscoreRC &lt;- scoreR[, 1:l] + scoreC[, 1:l] # here we have l &lt; k so l axes\nscoreRC_scaled &lt;- scalewt(scoreRC, wt = wt)\n\n\n# Check result\nall(abs(scoreRC_scaled/H) - 1 &lt; 10e-10)\n\n[1] TRUE\n\n\n\n\nPlot\n\n\nCode\nmultiplot(indiv_row = H, \n          indiv_row_lab = paste0(\"site \", Yfreq0$row, \"/\", Yfreq0$col),\n          row_color = \"black\", eig = lambda_dcca)"
  },
  {
    "objectID": "recscal_dcca.html#conditional-means-and-variances-from-rc-scores",
    "href": "recscal_dcca.html#conditional-means-and-variances-from-rc-scores",
    "title": "Reciprocal scaling with dcCA",
    "section": "Conditional means and variances from RC scores",
    "text": "Conditional means and variances from RC scores\n\n\n\n\n\n\nTL;DR\n\n\n\nOnce we have the correspondences scores, we can group them by row (site) or column (species) to compute conditional summary statistics:\n\nconditional mean for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional variance for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional covariance for site \\(i\\) or species \\(j\\) (between axes \\(k\\) and \\(l\\))\n\nThese conditional statistics can be computed using \\(H_k(i,j)\\) (weighted means/variances/covariances) or using the dcCA scores. We only present the dcCA scores formulas below.\nFormulas using dcCA scores\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[m_k(i) =  \\frac{1}{\\sqrt{2 \\mu_k}} \\times (LC1_k(i) + L_k(i))\\]\n\\[m_k(j) = \\frac{1}{\\sqrt{2 \\mu_k}} \\times (CC1_k(j) + C_k(j))\\]\n\n\nVariance for axis \\(k\\)\n\\[s^2_k(i) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} CC_k^2(j) \\right) - \\lambda_k L_k^2(i) \\right)\\]\n\\[s^2_k(j) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} LC_k^2(i) \\right) - \\lambda_k C_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\n\nLet’s compare the means obtained from canonical correlations scores and the dcCA scores.\n\nn &lt;- sum(Y)\n\n\nFor rows = sites\nBelow is a graphical illustration of scoreRC grouped by rows:\n\ns.class(scoreRC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        plabels.col = params$colsite, \n        main = \"With RC score (points = correspondences)\")\n\n\n\n\n\nFormula with RC scores (definition)\n\nmrowsRC &lt;- meanfacwt(scoreRC_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\nmrowsRC/(as.matrix(dcca$l1 + dcca$lsR) %*% diag(1/sqrt(2*mu_dcca)))\n\n   X1 X2 X3 X4 X5 X6\n1  -1  1 -1 -1 -1 -1\n2  -1  1 -1 -1 -1 -1\n3  -1  1 -1 -1 -1 -1\n4  -1  1 -1 -1 -1 -1\n5  -1  1 -1 -1 -1 -1\n6  -1  1 -1 -1 -1 -1\n7  -1  1 -1 -1 -1 -1\n8  -1  1 -1 -1 -1 -1\n9  -1  1 -1 -1 -1 -1\n10 -1  1 -1 -1 -1 -1\n11 -1  1 -1 -1 -1 -1\n12 -1  1 -1 -1 -1 -1\n13 -1  1 -1 -1 -1 -1\n14 -1  1 -1 -1 -1 -1\n15 -1  1 -1 -1 -1 -1\n16 -1  1 -1 -1 -1 -1\n17 -1  1 -1 -1 -1 -1\n18 -1  1 -1 -1 -1 -1\n19 -1  1 -1 -1 -1 -1\n20 -1  1 -1 -1 -1 -1\n21 -1  1 -1 -1 -1 -1\n22 -1  1 -1 -1 -1 -1\n23 -1  1 -1 -1 -1 -1\n24 -1  1 -1 -1 -1 -1\n25 -1  1 -1 -1 -1 -1\n26 -1  1 -1 -1 -1 -1\n\n\n\nvarrowsRC &lt;- varfacwt(scoreRC_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n\n\nVariance formula with dcCA scores\n\n# Get marginal counts\nyi_ &lt;- rowSums(Y)\ny_j &lt;- colSums(Y)\n\nvarrows_dcca &lt;- matrix(nrow = r, \n                       ncol = l)\n\nfor (i in 1:r) {\n  # Get CCA scores for site i\n  Li &lt;- dcca$lsR[i, ]\n  \n  # Compute the part with the sum on Cj\n  # we add all coordinates Cj^2 weighted by the number of observations on site i\n  sumCj &lt;- t(Y[i, ]) %*% as.matrix(dcca$co)^2\n\n  # Fill i-th row with site i variance along each axis\n  varrows_dcca[i, ] &lt;- (1/(2*lambda_dcca*mu_dcca)) * (((1/yi_[i])*sumCj) - lambda_dcca*as.numeric(Li)^2)\n}\n\n\nvarrowsRC/varrows_dcca\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\n\n\n\nFor columns = species\nBelow is an illustration of the RC scores grouped by species.\n\ns.class(scoreRC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        plabels.col = params$colspp, \n        main = \"With RC score (points = correspondences)\")\n\n\n\n\n\nFormula with RC scores (definition)\n\nmcolsRC &lt;- meanfacwt(scoreRC_scaled, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsRC/(as.matrix(dcca$lsQ + dcca$c1) %*% diag(1/sqrt(2*mu_dcca)))\n\n   X1 X2 X3 X4 X5 X6\n1  -1  1 -1 -1 -1 -1\n2  -1  1 -1 -1 -1 -1\n3  -1  1 -1 -1 -1 -1\n4  -1  1 -1 -1 -1 -1\n5  -1  1 -1 -1 -1 -1\n6  -1  1 -1 -1 -1 -1\n7  -1  1 -1 -1 -1 -1\n8  -1  1 -1 -1 -1 -1\n9  -1  1 -1 -1 -1 -1\n10 -1  1 -1 -1 -1 -1\n11 -1  1 -1 -1 -1 -1\n12 -1  1 -1 -1 -1 -1\n13 -1  1 -1 -1 -1 -1\n14 -1  1 -1 -1 -1 -1\n15 -1  1 -1 -1 -1 -1\n16 -1  1 -1 -1 -1 -1\n17 -1  1 -1 -1 -1 -1\n18 -1  1 -1 -1 -1 -1\n19 -1  1 -1 -1 -1 -1\n20 -1  1 -1 -1 -1 -1\n21 -1  1 -1 -1 -1 -1\n\n\n\nvarcolsRC &lt;- varfacwt(scoreRC_scaled, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\n\n\nVariance formula with dcCA scores\n\nvarcols_dcca &lt;- matrix(nrow = c, \n                       ncol = l)\n\nfor (j in 1:c) {\n  # Get CCA scores for species j\n  Cj &lt;- dcca$lsQ[j, ]\n  \n  # Compute the part with the sum on Li\n  # we add all coordinates Li^2 weighted by the number of observations on species j\n  sumLi &lt;- t(Y[, j]) %*% as.matrix(dcca$li)^2\n\n  # Fill i-th row with site i variance along each axis\n  varcols_dcca[j, ] &lt;- (1/(2*lambda_dcca*mu_dcca)) * (((1/y_j[j])*sumLi) - lambda_dcca*as.numeric(Cj)^2)\n}\n\n\nvarcolsRC/varcols_dcca\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   0  0  0  0  0  0\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  0  0  0  0  0  0\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1"
  },
  {
    "objectID": "recscal_dcca.html#conditional-means-and-variances-from-r-scores-and-c-scores",
    "href": "recscal_dcca.html#conditional-means-and-variances-from-r-scores-and-c-scores",
    "title": "Reciprocal scaling with dcCA",
    "section": "Conditional means and variances from R scores and C scores",
    "text": "Conditional means and variances from R scores and C scores\n\n\n\n\n\n\nTL;DR\n\n\n\nFor the scores computed with R scores and C scores, we have 3 types of formulas:\n\ndefinition (weighted mean/variance/covariance)\nformulas using the dcCA scores\nrelation with the RC scores\n\nHere, we don’t show the definition.\nFormulas using dcCA scores\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{1}{\\sqrt{n}} LC1_k(i)\\] (\\(LC1 =\\) normed LC score ($l1))\n\\[mR_k(j) =  \\frac{1}{\\sqrt{n}} C_k(j)\\] (\\(C =\\) species WA score ($lsQ))\n\n\nVariance for axis \\(k\\)\nNone\n\\[sR_k^2(j) = \\frac{1}{n\\lambda_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} LC_k^2(i) \\right) - \\lambda_k C_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[\\frac{1}{\\sqrt{n}} L_k(i)\\] (\\(L_k(i) =\\) sites WA score ($lsR))\n\\[\\frac{1}{\\sqrt{n}} CC1_k(j)\\] (\\(CC1_k(j) =\\) normed LC species score ($c1))\n\n\nVariance for axis \\(k\\)\n\\[sC_k^2(i) = \\frac{1}{n\\lambda_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} CC_k^2(j) \\right) - \\lambda_k L_k^2(i) \\right)\\]\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\nRelation between RC scores and R score / C score\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(i) - \\frac{1}{\\sqrt{n}} L_k(i)\\]\n\\[mR_k(j) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(j) - \\frac{1}{\\sqrt{n}} CC1_k(j)\\]\n\n\nVariance for axis \\(k\\)\nNone\n\\(sR^2_k(j) = \\frac{2\\mu_k}{n} s^2_k(j)\\)\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mC_k(i) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(i) - \\frac{1}{\\sqrt{n}} LC1_k(i)\\]\n\\[mC_k(j) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(j) - \\frac{1}{\\sqrt{n}} C_k(j)\\]\n\n\nVariance for axis \\(k\\)\n\\(sC^2_k(i) = \\frac{2\\mu_k}{n} s^2_k(i)\\)\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\n\n\nFor rows = sites\n\nscoreC\nBelow is a graphical illustration of scoreC grouped by rows:\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colspp,\n        plabels.col = params$colsite, \n        main = \"With C score (points = species scores)\")\n\n\n\n\n\nmrowsC &lt;- meanfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nmrowsC/(dcca$lsR*1/sqrt(n))\n\n   Axis1 Axis2 Axis3 Axis4 Axis5 Axis6\n1     -1     1    -1    -1    -1    -1\n2     -1     1    -1    -1    -1    -1\n3     -1     1    -1    -1    -1    -1\n4     -1     1    -1    -1    -1    -1\n5     -1     1    -1    -1    -1    -1\n6     -1     1    -1    -1    -1    -1\n7     -1     1    -1    -1    -1    -1\n8     -1     1    -1    -1    -1    -1\n9     -1     1    -1    -1    -1    -1\n10    -1     1    -1    -1    -1    -1\n11    -1     1    -1    -1    -1    -1\n12    -1     1    -1    -1    -1    -1\n13    -1     1    -1    -1    -1    -1\n14    -1     1    -1    -1    -1    -1\n15    -1     1    -1    -1    -1    -1\n16    -1     1    -1    -1    -1    -1\n17    -1     1    -1    -1    -1    -1\n18    -1     1    -1    -1    -1    -1\n19    -1     1    -1    -1    -1    -1\n20    -1     1    -1    -1    -1    -1\n21    -1     1    -1    -1    -1    -1\n22    -1     1    -1    -1    -1    -1\n23    -1     1    -1    -1    -1    -1\n24    -1     1    -1    -1    -1    -1\n25    -1     1    -1    -1    -1    -1\n26    -1     1    -1    -1    -1    -1\n\n\nNow let’s compute the variance of scoreC per row:\n\nvarrowsC &lt;- varfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nCompare it to the variance of the RC score:\n\nvarrowsC[, 1:ncol(varrowsRC)]/(varrowsRC %*% diag(2*mu_dcca/n))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\n\n\nscoreR\nNow, we compute the mean per row (site) from the row (sites) scores.\nBelow is a graphical illustration of scoreR grouped by rows:\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite, \n        main = \"With R score (points = sites scores)\")\n\n\n\n\n\nmrowsR &lt;- meanfacwt(scoreR, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nmrowsR/(dcca$l1*1/sqrt(n))\n\n    RS1 RS2 RS3 RS4 RS5 RS6\nX1   -1   1  -1  -1  -1  -1\nX2   -1   1  -1  -1  -1  -1\nX3   -1   1  -1  -1  -1  -1\nX4   -1   1  -1  -1  -1  -1\nX5   -1   1  -1  -1  -1  -1\nX6   -1   1  -1  -1  -1  -1\nX7   -1   1  -1  -1  -1  -1\nX8   -1   1  -1  -1  -1  -1\nX9   -1   1  -1  -1  -1  -1\nX10  -1   1  -1  -1  -1  -1\nX11  -1   1  -1  -1  -1  -1\nX12  -1   1  -1  -1  -1  -1\nX13  -1   1  -1  -1  -1  -1\nX14  -1   1  -1  -1  -1  -1\nX15  -1   1  -1  -1  -1  -1\nX16  -1   1  -1  -1  -1  -1\nX17  -1   1  -1  -1  -1  -1\nX18  -1   1  -1  -1  -1  -1\nX19  -1   1  -1  -1  -1  -1\nX20  -1   1  -1  -1  -1  -1\nX21  -1   1  -1  -1  -1  -1\nX22  -1   1  -1  -1  -1  -1\nX23  -1   1  -1  -1  -1  -1\nX24  -1   1  -1  -1  -1  -1\nX25  -1   1  -1  -1  -1  -1\nX26  -1   1  -1  -1  -1  -1\n\n\nThe variance is null.\n\n\n\nFor columns = species\n\nscoreC\nWe group the scoreC per species. Below is an illustration:\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp, \n        main = \"With C score (points = species scores)\")\n\n\n\n\n\nmcolsC &lt;- meanfacwt(scoreC, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsC/(dcca$c1*1/sqrt(n))\n\n     CS1 CS2 CS3 CS4 CS5 CS6\nsp1   -1   1  -1  -1  -1  -1\nsp2   -1   1  -1  -1  -1  -1\nsp3   -1   1  -1  -1  -1  -1\nsp4   -1   1  -1  -1  -1  -1\nsp5   -1   1  -1  -1  -1  -1\nsp6   -1   1  -1  -1  -1  -1\nsp7   -1   1  -1  -1  -1  -1\nsp8   -1   1  -1  -1  -1  -1\nsp9   -1   1  -1  -1  -1  -1\nsp10  -1   1  -1  -1  -1  -1\nsp11  -1   1  -1  -1  -1  -1\nsp12  -1   1  -1  -1  -1  -1\nsp13  -1   1  -1  -1  -1  -1\nsp14  -1   1  -1  -1  -1  -1\nsp15  -1   1  -1  -1  -1  -1\nsp16  -1   1  -1  -1  -1  -1\nsp17  -1   1  -1  -1  -1  -1\nsp18  -1   1  -1  -1  -1  -1\nsp19  -1   1  -1  -1  -1  -1\nsp21  -1   1  -1  -1  -1  -1\nsp22  -1   1  -1  -1  -1  -1\n\n\nThe variance is null.\n\n\nscoreR\nBelow are the scoreR grouped by column:\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colsite,\n        plabels.col = params$colspp, \n        main = \"With R score (points = sites scores)\")\n\n\n\n\n\nmcolsR &lt;- meanfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsR/(dcca$lsQ*1/sqrt(n))\n\n     Comp1 Comp2 Comp3 Comp4 Comp5 Comp6\nsp1     -1     1    -1    -1    -1    -1\nsp2     -1     1    -1    -1    -1    -1\nsp3     -1     1    -1    -1    -1    -1\nsp4     -1     1    -1    -1    -1    -1\nsp5     -1     1    -1    -1    -1    -1\nsp6     -1     1    -1    -1    -1    -1\nsp7     -1     1    -1    -1    -1    -1\nsp8     -1     1    -1    -1    -1    -1\nsp9     -1     1    -1    -1    -1    -1\nsp10    -1     1    -1    -1    -1    -1\nsp11    -1     1    -1    -1    -1    -1\nsp12    -1     1    -1    -1    -1    -1\nsp13    -1     1    -1    -1    -1    -1\nsp14    -1     1    -1    -1    -1    -1\nsp15    -1     1    -1    -1    -1    -1\nsp16    -1     1    -1    -1    -1    -1\nsp17    -1     1    -1    -1    -1    -1\nsp18    -1     1    -1    -1    -1    -1\nsp19    -1     1    -1    -1    -1    -1\nsp21    -1     1    -1    -1    -1    -1\nsp22    -1     1    -1    -1    -1    -1\n\n\nNow let’s compute the variance of scoreC per row:\n\nvarcolsR &lt;- varfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nCompare it to the variance of the RC score:\n\nvarcolsR/(varcolsRC %*% diag(2*mu_dcca/n))\n\n    X1  X2  X3  X4  X5  X6\n1    1   1   1   1   1   1\n2    1   1   1   1   1   1\n3    1   1   1   1   1   1\n4    1   1   1   1   1   1\n5    1   1   1   1   1   1\n6    1   1   1   1   1   1\n7  NaN NaN NaN NaN NaN NaN\n8    1   1   1   1   1   1\n9    1   1   1   1   1   1\n10   1   1   1   1   1   1\n11   1   1   1   1   1   1\n12   1   1   1   1   1   1\n13 NaN NaN NaN NaN NaN NaN\n14   1   1   1   1   1   1\n15   1   1   1   1   1   1\n16   1   1   1   1   1   1\n17   1   1   1   1   1   1\n18   1   1   1   1   1   1\n19   1   1   1   1   1   1\n20   1   1   1   1   1   1\n21   1   1   1   1   1   1"
  },
  {
    "objectID": "recscal_dcca.html#means-by-rc-scores-as-a-mean-of-lc-and-wa-scores",
    "href": "recscal_dcca.html#means-by-rc-scores-as-a-mean-of-lc-and-wa-scores",
    "title": "Reciprocal scaling with dcCA",
    "section": "Means by RC scores as a mean of LC and WA scores",
    "text": "Means by RC scores as a mean of LC and WA scores\nThe means of the RC scores by row (site) \\(m_k(i)\\) multiplied by a scaling factor \\(\\sqrt{2\\mu_k}\\) are equal to $lsR+$l1.\n\n\nCode\n# Invert first column\nmrowsRC_inv &lt;- mrowsRC\nmrowsRC_inv[, 1] &lt;- -mrowsRC_inv[, 1]\n\n\n\n(mrowsRC_inv[, 1:2] %*% diag(sqrt(2*mu_dcca[1:2])))/(dcca$l1[, 1:2]+dcca$lsR[, 1:2])\n\n    RS1 RS2\nX1    1   1\nX2    1   1\nX3    1   1\nX4    1   1\nX5    1   1\nX6    1   1\nX7    1   1\nX8    1   1\nX9    1   1\nX10   1   1\nX11   1   1\nX12   1   1\nX13   1   1\nX14   1   1\nX15   1   1\nX16   1   1\nX17   1   1\nX18   1   1\nX19   1   1\nX20   1   1\nX21   1   1\nX22   1   1\nX23   1   1\nX24   1   1\nX25   1   1\nX26   1   1\n\n\nHowever, perhaps it is more intuitive to see the \\(m_k(i)\\) as the mean between $lsR and $l1: for that, we divide \\(m_k(i) \\times \\sqrt{2\\mu_k}\\) by 2.\nThe graph below shows \\(\\frac{m_k(i) \\times \\sqrt{2\\mu_k}}{2}\\) along with the sites LS and WA scores. They are superimposed to the mean between $lsR and $l1 on the graph below:\n\n\nCode\n# Create a long df with $lsR and $l1 for the plot\nbindlsR &lt;- dcca$lsR\ncolnames(bindlsR) &lt;- colnames(dcca$l1)\nlscores &lt;- rbind(dcca$l1, bindlsR)\n\n\n\n\nCode\ns.class(lscores,\n        fac = as.factor(rep(rownames(Y), 2)),\n        ppoints.col = params$colsite,\n        wt = rep(dcca$lw, 2),\n        plabels.col = params$colsite)\ns.label((mrowsRC_inv %*% diag(sqrt(mu_dcca*2)/2)),\n        plabels.col = \"darkorchid3\",\n        add = TRUE)\n\n\n\n\n\n\nMeans of the not scaled scores\nThat was not too bad but it seems strange to compare LC1 and WA scores: LC and WA would be a better fit.\n\n\nCode\n# Create a long df with $lsR and $l1 for the plot\nbindlsR &lt;- dcca$lsR\ncolnames(bindlsR) &lt;- colnames(dcca$li)\nlscores &lt;- rbind(dcca$li, bindlsR)\n\n\n\n\nCode\ns.class(lscores,\n        fac = as.factor(rep(rownames(Y), 2)),\n        ppoints.col = params$colsite,\n        wt = rep(dcca$lw, 2),\n        plabels.col = params$colsite)\ns.label((mrowsRC_inv %*% diag(sqrt(mu_dcca*lambda_dcca*2)/2)),\n        plabels.col = \"darkorchid3\",\n        add = TRUE)\n\n\n\n\n\nBut then the mean of $lsR and $li is not superimposed to the means of the RC scores."
  },
  {
    "objectID": "recscal_dcca.html#tests",
    "href": "recscal_dcca.html#tests",
    "title": "Reciprocal scaling with dcCA",
    "section": "Tests",
    "text": "Tests\n\nFor rows = sites\nWe define the “new” RC score \\(H2\\) in which we replace \\(LC_k(i)\\) with \\(L_k(i)\\). Then, this should help to get the mean for the rows (which are at the mean of the \\(CC1_k(j)\\)).\n\\[\nH2_k(i, j) = \\frac{L_k(i) + CC_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\n\n# Initialize results matrix\nH2 &lt;- matrix(nrow = nrow(Yfreq0), \n             ncol = length(lambda_dcca))\n\nfor (kl in 1:length(lambda_dcca)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H2[ind, kl] &lt;- (dcca$lsR[i, kl] + dcca$co[j, kl])/sqrt(2*lambda_dcca[kl]*mu_dcca[kl])\n    ind &lt;- ind + 1\n  }\n}\n\n\nmultiplot(indiv_row = H2, \n          indiv_row_lab = paste0(\"site \", Yfreq0$row, \"/\", Yfreq0$col),\n          row_color = \"black\", eig = lambda_dcca)\n\nWarning: ggrepel: 188 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\ns.class(H2,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = \"black\",\n        plabels.col = params$colsite, \n        main = \"With H2 score (points = correspondences)\")\n\n\n\n\nWe compute the mean and variance per site and compare them to the scores of dcCA:\n\nmrowsH2 &lt;- meanfacwt(H2, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nvarrowsH2 &lt;- varfacwt(H2, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n\nmrowsH2/(as.matrix(dcca$lsR) %*% diag(sqrt(mu_dcca/(2*lambda_dcca))))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\nvarrowsH2/varrowsRC\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\nA test with the linear model:\n\nlmp &lt;- predict(lm(H2~tabR, weights = Yfreq0$Freq))\n\nmean_lmp &lt;- meanfacwt(lmp, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nmean_lmp/dcca$li\n\n       Axis1    Axis2    Axis3    Axis4    Axis5    Axis6\nX1  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX2  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX3  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX4  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX5  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX6  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX7  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX8  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX9  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX10 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX11 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX12 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX13 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX14 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX15 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX16 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX17 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX18 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX19 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX20 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX21 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX22 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX23 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX24 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX25 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nX26 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\n\n\nHowever, the mean/variance per species is meaningless here.\n\nmcolsH2 &lt;- meanfacwt(H2, fac = Yfreq0$colind, wt = Yfreq0$Freq)\nvarcolsH2 &lt;- varfacwt(H2, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsH2/dcca$lsQ\n\n           Comp1        Comp2      Comp3       Comp4       Comp5         Comp6\nsp1    3.1721005    2.2257491  8.0456109   2.4457589  -9.5427704  27.128970206\nsp2    1.4894490    3.7124342  1.7625561   0.6554804   1.9265042   0.004615235\nsp3  -17.7680994    1.5970024  2.6279553  -7.1066710  -0.7379612  10.260153611\nsp4    1.9561415    2.1957994  5.5071205   1.9726484  -2.5204434  -4.252155087\nsp5   -1.6489392    2.5191365  4.0469949 -49.9059050   3.4441372  -4.576441137\nsp6    0.9603452    5.0925401  2.7037890  -8.5587879   4.7879692 -98.197453857\nsp7    1.4048376   -0.4666054  9.5974168   0.9030955  22.4354045  -8.747350230\nsp8    1.8272738    2.9344011  2.8090008   3.2875546  -7.5758247  32.395342222\nsp9    1.6622589   15.8747171  0.3020535   1.0039006  17.0712865  -0.804358006\nsp10   2.3672733   12.3398100  4.6059711   0.3219771   4.3757411 -31.206686571\nsp11   2.0989334  -18.0793801  2.0009546  92.9893978  12.2178584  10.763766487\nsp12   2.6084569    0.6978122  2.6705161  -0.8576404 -21.7257780   5.991097869\nsp13   1.3226805    1.6545934  4.9422792   5.4797837   4.6591143   8.388746532\nsp14  -0.4374757    1.7843525  4.2323103   7.2628482  -1.1986834   4.125708950\nsp15   1.8856404 8332.6510569 10.7562105   1.5039389   1.8940721   1.410789789\nsp16   2.6601040    5.0194451 -3.7699792   1.6000497  26.1841692  -2.014859301\nsp17   0.9362322    1.1133181  8.8291583   1.1691430   1.4156353   2.629803146\nsp18   2.8663617   -0.5560764  3.3865213   7.4641528  24.4677196  -2.270444345\nsp19   2.0051832    1.9568447 -0.9538734   2.8850712  19.0902614  -1.637042599\nsp21   1.9937580    2.5283488  1.4380632   6.8869227  13.7934692  27.172582142\nsp22   1.8016377    5.3735973  3.0964368   8.3822682  -9.3522464  12.831808023\n\nmcolsH2/dcca$co\n\n          Comp1     Comp2      Comp3      Comp4        Comp5       Comp6\nsp1   2.2359729 2.9983863   3.268296  13.750847     3.893110   27.468317\nsp2   2.9137718 3.2363182   7.625567  -6.077396    27.874464    2.194562\nsp3   2.1906373 4.2341006   3.173427 -22.320754   -30.050361   44.748430\nsp4   2.5875232 3.0251143   4.046255  17.240704     8.674122 -610.552010\nsp5   1.0549936 2.6441720   5.448118   9.198649    38.999503  274.094872\nsp6   5.1632334 2.9102346 -17.637623   6.967819     7.199333   30.365053\nsp7   6.1373899 0.3194563   5.986492  27.202203    12.257489  248.519945\nsp8   3.7916517 3.0441123   4.194799   5.763669 -4247.960850   22.941222\nsp9   2.4126476 2.2559219  -2.838000  21.437875    20.084496  -76.735728\nsp10  2.1472417 2.6884632   4.852386   1.773712    34.771490 -778.702370\nsp11  3.5978402 2.9227011  -4.961039   5.488146    12.564308   88.065577\nsp12  2.3438215 3.2113965   5.660619   2.907402    17.504785   21.403629\nsp13 11.1225321 2.7586775   4.492777  10.379968    35.112702   29.771752\nsp14  0.7059009 3.9826952   3.778482   6.192765     9.827260   19.870641\nsp15  3.1261878 1.9662386  36.946807  38.966069     9.656518  -18.496878\nsp16  2.6177197 2.3009125   3.066024  -4.265742    21.730027    9.697308\nsp17  4.8156671 7.4653386   3.234967  15.590917    10.107525  266.151377\nsp18  2.3056252 2.2232527   4.482192   7.564967    16.225409  -34.033516\nsp19  3.1131485 4.4657178  -1.783710   8.069621    12.755563   30.421656\nsp21  2.4707257 3.5801951   5.585907  11.886959    18.366644   31.562575\nsp22  2.4061825 2.2265807   3.170301   6.625118     7.324043   17.113156\n\nvarcolsH2/varcolsRC\n\n          X1        X2          X3          X4        X5          X6\n1  1.1377128 1.7791439  1.54838504  2.72322197  7.610742   15.466704\n2  0.9203942 1.1883652  3.26222351  2.72755963  4.183128   10.485299\n3  0.9558951 0.1616186  1.51013335  0.03272000 46.312482  209.291128\n4  1.6821793 1.4660671  2.65605948  1.78012810  9.798209   18.798368\n5  0.6970483 1.5578290  0.01057866  0.63345426 43.055922  106.229048\n6  1.1769433 1.9214517  1.30570622  2.20564072  5.625168   16.790975\n7        NaN       NaN         NaN         NaN       NaN         NaN\n8  1.0936312 0.8282439  1.63201545  4.60450726  5.024470   17.632182\n9  0.4584740 1.3869340  0.71301294 53.02521613  7.601425    4.530647\n10 1.2756652 1.1966213  2.74996207  3.94249864  7.648603   22.120744\n11 1.0366799 1.8384221  1.16456197  1.43439740  4.372113   18.762307\n12 1.9034104 0.8544346  2.93210740  6.45324871  3.864234    7.095375\n13       NaN       NaN         NaN         NaN       NaN         NaN\n14 0.2827875 0.3916678  0.24119303  0.02483622  3.851086   29.053164\n15 7.0017018 0.4738255 37.93526893 14.00679054 23.248763    7.714720\n16 7.9986521 0.4814041  1.30374668  7.05305999  7.559875 3073.461359\n17 5.2310623 0.2063154  3.95703634  2.79907452  5.128149    4.991203\n18 1.2774806 2.1083621  1.47826586  2.99011450 10.648939   11.749369\n19 1.2593655 2.1382514  1.28287815  1.90887823  3.712536   19.335915\n20 1.3240046 5.5237061  2.13207502  0.91974195 11.607808   10.258192\n21 5.2610069 0.9717426  2.19714887  6.47927532  8.151182    9.462684\n\n\n\nlmp &lt;- predict(lm(H2~tabC, weights = Yfreq0$Freq))\n\nmean_lmp &lt;- meanfacwt(lmp, fac = Yfreq0$colind, wt = Yfreq0$Freq)\nmean_lmp/dcca$lsQ\n\n           Comp1         Comp2      Comp3       Comp4       Comp5       Comp6\nsp1    3.4603288     2.0912140  9.2187978   1.8773109 -10.7081460  26.1630841\nsp2    1.1652466     3.6274821  1.0685596  -0.7186386   1.7902422  -1.7295628\nsp3  -17.0410090     1.0291158  3.8955337   5.4858142   0.3130948   5.7779208\nsp4    1.7233115     2.2953483  6.2921531   0.7623652  -7.5266165  -5.7276532\nsp5   -3.6191196     2.8099043  3.3169991 -46.0768965   0.8576634  -0.5915182\nsp6    0.3471965     5.0810241  1.0431073  -5.1825116   6.2482161 -95.3046470\nsp7    0.4098358    -3.8261489  7.4470441   0.1036138  27.0521790  -1.6068768\nsp8    1.3479706     2.6876268  2.5429532   3.9848452  -3.4791715  36.5081081\nsp9    1.5066246    20.0290773 -0.6111781   1.1574824   9.0949215   0.5903676\nsp10   2.5131315    14.5145005  4.3882744   1.2095126   3.2596929 -32.9584246\nsp11   1.7087029   -24.9333635  1.3212730 104.1896607  13.1053838   6.0631603\nsp12   2.7834556     0.2875248  2.0261339  -2.6009856 -21.0276039   3.2102138\nsp13   0.4991459     1.6915589 -3.2531742   4.1825438   1.6901947   8.0712527\nsp14  -1.2725023     1.3384865  4.7787312   9.0307717  -0.7844371   5.7585956\nsp15   1.4786286 12128.2490042  0.9054809   0.3856299   3.3071122  -0.5954239\nsp16   2.4564707     5.9924007 -5.7500572  -2.9202161  18.0344684  -4.2319812\nsp17   0.3880595     0.5423809 10.7651738   1.1335473   0.8157060   1.7521408\nsp18   3.0839416    -0.9504501  3.0562161   8.9690221   4.0141830  -4.0628670\nsp19   1.8865313     1.7662282 -1.7518405   2.1984687  20.1699802  -2.6694273\nsp21   1.9804080     2.1839795  0.9062684   5.5909302   9.6412807  21.8884608\nsp22   1.6387409     6.3327667  3.8762639   8.7906121 -16.3255882  15.4586361\n\n\n\n\nFor columns = species\nWe define the “new” RC score \\(H3\\) in which we replace \\(CC_k(j)\\) with \\(C_k(j)\\). Then, this should help to get the mean for the columns (which are at the mean of the \\(LC1_k(i)\\)).\n\\[\nH3_k(i, j) = \\frac{LC_k(i) + C_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\n\n# Initialize results matrix\nH3 &lt;- matrix(nrow = nrow(Yfreq0), \n             ncol = length(lambda_dcca))\n\nfor (kl in 1:length(lambda_dcca)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H3[ind, kl] &lt;- (dcca$li[i, kl] + dcca$lsQ[j, kl])/sqrt(2*lambda_dcca[kl]*mu_dcca[kl])\n    ind &lt;- ind + 1\n  }\n}\n\n\nmultiplot(indiv_row = H3, \n          indiv_row_lab = paste0(\"site \", Yfreq0$row, \"/\", Yfreq0$col),\n          row_color = \"black\", eig = lambda_dcca)\n\nWarning: ggrepel: 195 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\ns.class(H3,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        labels = colnames(Y),\n        ppoints.col = \"black\",\n        plabels.col = params$colspp, \n        main = \"With H3 score (points = correspondences)\")\n\n\n\n\nWe compute the mean and variance per species:\n\nmcolsH3 &lt;- meanfacwt(H3, fac = Yfreq0$colind, wt = Yfreq0$Freq)\nvarcolsH3 &lt;- varfacwt(H3, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\n\nmcolsH3/(as.matrix(dcca$lsQ) %*% diag(sqrt(mu_dcca/(2*lambda_dcca))))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n\nvarcolsH3/varcolsRC\n\n    X1  X2  X3  X4  X5  X6\n1    1   1   1   1   1   1\n2    1   1   1   1   1   1\n3    1   1   1   1   1   1\n4    1   1   1   1   1   1\n5    1   1   1   1   1   1\n6    1   1   1   1   1   1\n7  NaN NaN NaN NaN NaN NaN\n8    1   1   1   1   1   1\n9    1   1   1   1   1   1\n10   1   1   1   1   1   1\n11   1   1   1   1   1   1\n12   1   1   1   1   1   1\n13 NaN NaN NaN NaN NaN NaN\n14   1   1   1   1   1   1\n15   1   1   1   1   1   1\n16   1   1   1   1   1   1\n17   1   1   1   1   1   1\n18   1   1   1   1   1   1\n19   1   1   1   1   1   1\n20   1   1   1   1   1   1\n21   1   1   1   1   1   1\n\n\nTest with the linear model:\n\nlmp &lt;- predict(lm(H3~tabC, weights = Yfreq0$Freq))\nmean_lmp &lt;- meanfacwt(lmp, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmean_lmp/dcca$co\n\n        Comp1    Comp2    Comp3    Comp4    Comp5    Comp6\nsp1  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp2  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp3  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp4  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp5  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp6  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp7  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp8  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp9  2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp10 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp11 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp12 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp13 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp14 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp15 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp16 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp17 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp18 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp19 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp21 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\nsp22 2.218854 2.704281 3.524278 6.363571 7.910721 14.53206\n\n\nHere too, the mean and variance per rows are meaningless."
  },
  {
    "objectID": "recscal_dcca.html#tests-with-wa-scores",
    "href": "recscal_dcca.html#tests-with-wa-scores",
    "title": "Reciprocal scaling with dcCA",
    "section": "Tests with WA scores",
    "text": "Tests with WA scores\nWe define another “RC score” \\(H4\\) in which we replace the LC scores with the WA scores (\\(LC_k(i)\\) with \\(L_k(i)\\) and \\(CC_k(j)\\) with \\(C_k(j)\\)).\n\\[\nH4_k(i, j) = \\frac{L_k(i) + C_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\n\n# Initialize results matrix\nH4 &lt;- matrix(nrow = nrow(Yfreq0), \n             ncol = length(lambda_dcca))\n\nfor (kl in 1:length(lambda_dcca)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H4[ind, kl] &lt;- (dcca$lsR[i, kl] + dcca$lsQ[j, kl])/sqrt(2*lambda_dcca[kl]*mu_dcca[kl])\n    ind &lt;- ind + 1\n  }\n}\n\n\nmrowsH4 &lt;- meanfacwt(H4, fac = Yfreq0$row, wt = Yfreq0$Freq)\nvarrowsH4 &lt;- varfacwt(H4, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nmrowsH4/dcca$lsR\n\n      Axis1     Axis2     Axis3      Axis4     Axis5       Axis6\n1  2.270027  2.967636  4.430313   2.992835 12.689288   15.813828\n2  2.592521  3.088789 -3.004761   8.921164  9.619403   26.317092\n3  2.284522  2.801875  3.661322   8.418460  8.324925   14.689479\n4  2.705616 -3.547532  4.102061   7.546086  6.095999    7.712939\n5  2.035428  1.985472  3.929971   4.585864  8.815705   13.935495\n6  2.496182  3.007403 45.878346   5.237350  7.210997   25.749088\n7  2.296055  2.221086  3.425723 -55.120178  6.925764   23.314684\n8  2.099708  2.873193 -1.856318   8.398362  8.270794   13.476107\n9  1.024596  7.713313  4.734499   8.700462  9.023951   17.737729\n10 2.435413  2.882193  3.166543   9.243710  1.451613   23.567851\n11 2.341279  3.848335  4.105384   9.962675  7.612015   26.976020\n12 2.604818  2.036947  3.467426 -19.691831 37.413755   22.726950\n13 1.955898  3.559485  5.006858   9.108917 11.276406   31.040815\n14 2.325569  2.872997  3.516224   7.438389  7.803118   13.638027\n15 2.175481  4.017754  4.025557   5.725958  9.365915   12.191450\n16 2.642423  2.442624  3.980543   6.497969  8.714516   14.014859\n17 2.147938  3.421432  4.269864   8.211518  6.492619   13.221953\n18 2.298041  2.240399  5.484913 -29.602215  8.300061   47.182408\n19 2.679121  2.785710  5.713113  22.297633  4.412854   14.836355\n20 2.516872  2.138374  7.436810   0.589299  7.697454 -225.671696\n21 2.417679  2.538907  4.019096   6.568227  8.377150   15.703047\n22 2.489391 -4.311585  4.165107   5.449022  6.736033   29.142316\n23 2.885546  2.759850  4.684898  12.684803 13.307348   15.451425\n24 2.391170  2.787685  3.818205   9.781579  9.168058   10.406594\n25 2.245071  2.970814  6.224657   5.894541  8.215408    3.021615\n26 2.245585  2.857861  1.026017   7.870284  8.455802   12.733211\n\n# mrowsH4/dcca$li\nvarrowsH4/varrowsRC\n\n           X1        X2        X3          X4          X5         X6\n1  1.70264218 2.0729305 1.1722902   6.5386740   8.7058923  11.626546\n2  1.57065667 1.5754298 1.5816798   4.9823452  15.2845031   9.948347\n3  1.01275861 1.2105254 1.1882241   3.0994839   1.2417846   4.014783\n4  1.19297236 0.4889474 5.0104224   1.9440473   1.4239826   8.798916\n5  1.00370789 1.0167785 0.8079631   2.8283974   0.9598539   8.624235\n6  1.95528944 0.5922523 1.1507306   8.2361876   4.0946035  15.605919\n7  1.03631184 1.4331191 1.3918104   3.0495043   5.1322497   3.580466\n8  1.09515266 2.0934594 5.0456958   2.6298815   1.3980502   3.038394\n9  1.62389696 1.6663649 0.2938323   1.5637986   3.2863719   5.435805\n10 1.22155081 2.2154625 0.9715276   5.7966036   9.1764144  12.717155\n11 1.58839514 0.9542661 0.7608778  19.7106576   4.0687925  18.554352\n12 1.26169428 1.9316403 0.9022768   4.6051185   3.5510944   8.860022\n13 1.04847004 1.3076400 4.2331141   1.5611813   7.2317012  10.749080\n14 0.06035882 1.0245946 0.6023734  11.2634540   1.3920137   5.818924\n15 0.66349415 0.7423038 1.4877679   0.7250288 100.8675005 120.822198\n16 1.15144495 0.7691622 1.2559675   3.5360942   1.6105552   2.631277\n17 0.89266448 1.0313946 3.0342011   6.9205279  30.2276420  16.376939\n18 1.08953186 0.5829859 5.6695321   8.7988524   1.1109562  24.816610\n19 0.91153514 2.3209605 2.8462581   5.2193875   8.7611000  15.109775\n20 0.95301191 0.4991820 4.9318302   9.3055248   2.7657559  22.295769\n21 0.01423399 1.6092493 0.4004353   7.1737807   1.2827811   4.028389\n22 0.89941311 0.9494112 4.1277482   8.7579996   2.3341084  16.226056\n23 1.18865522 1.7278136 3.9779006   7.9052158  10.8214223  11.384519\n24 2.61435121 1.0643875 2.4762697 185.6107858   3.6905685  18.823494\n25 0.88912545 1.8349537 4.7900171   5.7153114   1.1208567   3.698124\n26 0.75477171 2.1975153 5.8890080   3.5584121   1.1146244   2.968332\n\n\n\nmcolsH4 &lt;- meanfacwt(H4, fac = Yfreq0$colind, wt = Yfreq0$Freq)\nvarcolsH4 &lt;- varfacwt(H4, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsH4/dcca$lsQ\n\n         Comp1       Comp2      Comp3      Comp4      Comp5      Comp6\nsp1   2.495745    2.762661  3.8292099   7.127553 15.4249354  27.299975\nsp2   2.279144    3.405902  3.9803843   6.964341  8.6610126  13.817449\nsp3  -3.049421    2.894720  3.1237742  -3.225125  6.3188888  20.928344\nsp4   2.350339    2.767005  4.4656752   7.015736  6.8162032   9.493388\nsp5   2.491556    2.617664  4.7888328 -13.315714 10.0397521   9.496616\nsp6   2.275365    3.530103  6.0305406   4.130799  7.2111159 -39.592088\nsp7   2.650550    4.660357  7.8575122   6.408696 16.4282815   5.581800\nsp8   2.664230    3.009495  3.7619468   5.734022 -0.3542153  26.691052\nsp9   2.164716    3.296195  3.4936208   6.431889 18.1566560  12.892492\nsp10  2.201730    4.859858  4.7524554   4.982901 10.6998415 -17.919462\nsp11  2.771970   -3.106929  6.0489528   2.195562 12.4173437  22.913887\nsp12  2.426055    2.328664  4.1942235   6.516859 -5.5122710  15.958538\nsp13  2.746065    2.488498  4.6536790   8.168124 10.9336764  18.330465\nsp14  2.179211    2.934446  3.8858502   6.278836  6.9182600  15.093673\nsp15  2.526709 -495.290765 12.8009963   6.978807  7.7095744  16.308484\nsp16  2.633947    2.557664  2.6614280   9.430736 24.7012651  14.703096\nsp17  2.237655    2.886190  3.8409234   6.436768  7.6368987  16.334977\nsp18  2.473467    2.048674  4.0916510   7.540043 20.7926753  10.648076\nsp19  2.580137    3.127428  0.3881113   6.543762 15.4974412  12.949761\nsp21  2.305626    3.140503  3.5800067   9.282279 15.5948155  29.097838\nsp22  2.207526    2.428663  3.1636436   6.871899  7.1201869  16.294768\n\nmcolsH4/dcca$co\n\n          Comp1      Comp2       Comp3      Comp4       Comp5      Comp6\nsp1   1.7592189  3.7216796   1.5555052  40.073407   -6.292824   27.64146\nsp2   4.4586315  2.9690981  17.2208333 -64.571045  125.315630 6570.24883\nsp3   0.3759646  7.6747127   3.7721605 -10.129528  257.310111   91.27647\nsp4   3.1089555  3.8120546   3.2810721  61.316672  -23.458007 1363.12217\nsp5  -1.5941012  2.7475900   6.4467895   2.454351  113.684594 -568.77683\nsp6  12.2333525  2.0173485 -39.3390179  -3.362937   10.842849   12.24284\nsp7  11.5796033 -3.1906626   4.9012075 193.036791    8.975523 -158.58385\nsp8   5.5283632  3.1220139   5.6178739  10.052762 -198.617679   18.90165\nsp9   3.1419269  0.4684152 -32.8249646 137.350277   21.361441 1229.94336\nsp10  1.9970857  1.0588129   5.0067072  27.449863   85.025467 -447.14543\nsp11  4.7515118  0.5022642 -14.9973882   0.129580   12.769450  187.47384\nsp12  2.1799247 10.7167279   8.8903799 -22.092164    4.441319   57.01303\nsp13 23.0918880  4.1490329   4.2304249  15.472301   82.399979   65.05502\nsp14 -3.5163268  6.5497178   3.4691729   5.353734  -56.718512   72.69562\nsp15  4.1890103 -0.1168727  43.9704980 180.816302   39.305601 -213.82068\nsp16  2.5919794  1.1724326  -2.1644691 -25.142400   20.499377  -70.76447\nsp17 11.5097507 19.3533061   1.4072982  85.836475   54.526860 1653.19469\nsp18  1.9895911 -8.1908171   5.4154588   7.641882   13.788357  159.61257\nsp19  4.0057926  7.1371080   0.7257545  18.303076   10.354944 -240.64931\nsp21  2.8572018  4.4470178  13.9059137  16.021389   20.765220   33.79887\nsp22  2.9482674  1.0063306   3.2391110   5.431363   -5.576046   21.73154\n\nvarcolsH4/varcolsRC\n\n          X1        X2          X3          X4        X5          X6\n1  1.1377128 1.7791439  1.54838504  2.72322197  7.610742   15.466704\n2  0.9203942 1.1883652  3.26222351  2.72755963  4.183128   10.485299\n3  0.9558951 0.1616186  1.51013335  0.03272000 46.312482  209.291128\n4  1.6821793 1.4660671  2.65605948  1.78012810  9.798209   18.798368\n5  0.6970483 1.5578290  0.01057866  0.63345426 43.055922  106.229048\n6  1.1769433 1.9214517  1.30570622  2.20564072  5.625168   16.790975\n7        NaN       NaN         NaN         NaN       NaN         NaN\n8  1.0936312 0.8282439  1.63201545  4.60450726  5.024470   17.632182\n9  0.4584740 1.3869340  0.71301294 53.02521613  7.601425    4.530647\n10 1.2756652 1.1966213  2.74996207  3.94249864  7.648603   22.120744\n11 1.0366799 1.8384221  1.16456197  1.43439740  4.372113   18.762307\n12 1.9034104 0.8544346  2.93210740  6.45324871  3.864234    7.095375\n13       NaN       NaN         NaN         NaN       NaN         NaN\n14 0.2827875 0.3916678  0.24119303  0.02483622  3.851086   29.053164\n15 7.0017018 0.4738255 37.93526893 14.00679054 23.248763    7.714720\n16 7.9986521 0.4814041  1.30374668  7.05305999  7.559875 3073.461359\n17 5.2310623 0.2063154  3.95703634  2.79907452  5.128149    4.991203\n18 1.2774806 2.1083621  1.47826586  2.99011450 10.648939   11.749369\n19 1.2593655 2.1382514  1.28287815  1.90887823  3.712536   19.335915\n20 1.3240046 5.5237061  2.13207502  0.91974195 11.607808   10.258192\n21 5.2610069 0.9717426  2.19714887  6.47927532  8.151182    9.462684"
  },
  {
    "objectID": "recscal.html",
    "href": "recscal.html",
    "title": "Reciprocal scaling",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# dc-CA\nsource(here(\"functions/dpcaiv2-ade4.R\"))\n\n# Reciprocal scaling\nsource(here(\"functions/reciprocal.R\"))\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nsource(here(\"functions/plot.R\"))\nlibrary(patchwork)\nCode\n# Define bound for comparison to zero\nzero &lt;- 10e-10"
  },
  {
    "objectID": "recscal.html#introduction",
    "href": "recscal.html#introduction",
    "title": "Reciprocal scaling",
    "section": "Introduction",
    "text": "Introduction\nReciprocal scaling was introduced by Thioulouse and Chessel (1992). It is a technique allowing to compute the coordinates of each row/column cell in the multivariate space, and to plot them in a single space, which then allows to get the conditional mean and variance per row or column.\nThis technique was initially defined in the frame of correspondence analysis, but it is extended to canonical CA in reciprocal scaling (CCA) and double-constrained CA in in reciprocal scaling (dcCA).\nHere, we will analyze matrix \\(Y\\):\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21"
  },
  {
    "objectID": "recscal.html#computation",
    "href": "recscal.html#computation",
    "title": "Reciprocal scaling",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nReciprocal scaling gives a score per correspondence (row/column pair) on each ordination axis (instead of a score per row and per column in CA).\nThese scores can be presented in a matrix \\(H\\) (\\(n_\\bar{0} \\times K\\)). Here, \\(n_\\bar{0}\\) is the number of nonzero cells in \\(Y\\), also called correspondences (\\(n_\\bar{0} = \\sum_Y y_{ij} \\neq 0\\)) and \\(K\\) is the number of eigenvalues (axes) of the CA. Each row of \\(H\\) corresponds to a row/column pair.\nFrom CA scores\n\\(H\\) can be computed from the scores of the correspondence analysis of \\(Y\\). The score \\(h_k(i, j)\\) for row \\(i\\), column \\(j\\) and axis \\(k\\) is:\n\\[\nh_k(i, j) = \\frac{b_k(i) + a_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\nwhere \\(a_k(j)\\) and \\(b_k(i)\\) are the matrices of scores obtained by weighted averaging for CA (respectively equal to co and li).\nif \\(y_{ij} = 0\\), then the score \\(h_k(i, j)\\) is not defined.\nFrom canonical correlation analysis\nWe transform the table \\(Y\\) in two tables:\n\n\\(R\\) (\\(n_\\bar{0} \\times r\\))\n\\(C\\) (\\(n_\\bar{0} \\times c\\))\n\nEach row of \\(R\\) and \\(C\\) contains an indicator vector. The 1 is in the column corresponding to the row (for \\(R\\)) or column (for \\(C\\)) of the nonzero cell in \\(Y\\).\nAdditionally, we have a weights vector \\(w = y_{ij}\\) (the same for \\(R\\) and \\(C\\)).\nThen, we perform a (weighted) canonical correlation analysis of \\(R_{scaled}\\) and \\(C_{scaled}\\). \\(X_{scaled}\\) corresponds to \\(X\\) center and scaled (here, with the weights \\(w\\)).\nCanonical correlation analysis gives the vectors of canonical coefficients \\(\\rho\\) and \\(\\gamma\\) (resp. for \\(R_{scaled}\\) and \\(C_{scaled}\\)). The scores of the matrices are then \\(S_R = R_{scaled} \\rho\\) and \\(S_C = C_{scaled} \\gamma\\).\nFinally, \\(H\\) is computed as:\n\\[\nH = (S_R + S_C)_{scaled}\n\\]\n\n\n\nFrom CA\nWe perform the CA of table \\(Y\\) (\\(r \\times c\\)).\n\nkca &lt;- min(r - 1, c - 1) # non-null eigenvalues\n\nYdf &lt;- as.data.frame(Y)\nca &lt;- dudi.coa(Ydf, \n               scannf = FALSE,\n               nf = kca)\n\nB &lt;- ca$li\nA &lt;- ca$co\n\nlambda &lt;- ca$eig\n\nWe compute the reciprocal scaling score for comparison:\n\nrec_ca &lt;- reciprocal.coa(ca)\n\nWe can get the coordinates of row-column pairs (ie each cell in the original table \\(Y\\)) with:\n\\[\nh_k(i, j) = \\frac{b_k(i) + a_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\nwhere \\(b_k(i)\\) is the coordinate of row (site) \\(i\\) on axis \\(k\\) and \\(a_k(j)\\) is the same for column (species) \\(j\\) and \\(\\mu_k = 1 + \\sqrt{\\lambda_k}\\).\n\nmu &lt;- 1 + sqrt(lambda)\n\nLet’s compute \\(H\\) from the CA scores with our example dataset.\n\n# Transform matrix to count table\nYfreq &lt;- as.data.frame(as.table(Y))\ncolnames(Yfreq) &lt;- c(\"row\", \"col\", \"Freq\")\n\n# Remove the cells with no observation\nYfreq0 &lt;- Yfreq[-which(Yfreq$Freq == 0),]\nYfreq0$colind &lt;- match(Yfreq0$col, colnames(Y)) # match index and species names\n\n# Initialize results matrix\nH &lt;- matrix(nrow = nrow(Yfreq0), \n            ncol = length(lambda))\n\nfor (k in 1:length(lambda)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H[ind, k] &lt;- (B[i, k] + A[j, k])/sqrt(2*lambda[k]*mu[k])\n    ind &lt;- ind + 1\n  }\n}\n\nThe result is a matrix \\(H\\) with \\(n_\\bar{0} = \\sum_Y y_{ij} \\neq 0\\) rows (one row for each nonzero cell in \\(Y\\), called correspondences) and \\(K\\) columns (one column per principal axis of the CA):\n\n\nCode\nplotmat(r = sum(Y != 0), c = length(lambda),\n        Yname = \"italic(H)\",\n        rname = \"italic(n[bar(0)])\",\n        cname = \"italic(K)\",\n        plot.margin.x = 10)\n\n\n\n\n\nWe check that the loop did what we want:\n\n\nCode\n# Choose one element of H\ni &lt;- 1 # row\nj &lt;- 3 # column\njtxt &lt;- colnames(Y)[j]\nl &lt;- 2 # axis\n\nHtest &lt;- H[Yfreq0$row == i & Yfreq0$col == jtxt, k]\n\n# Compute one value with the formula\nHkij &lt;- (B[i, k] + A[j, k])/sqrt(2*lambda[k]*mu[k])\n\n# Compare\nHtest/Hkij\n\n\n[1] 1\n\n\nCompare the results computed above with the results from reciprocal.coa function in ade4:\n\nall(H/rec_ca[, 1:kca] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nFrom canonical correlation analysis\nCanonical correlation analysis is the extension of correlation to multidimensional analysis. This method allows to find the coefficients to maximize the correlation between the columns of two matrices.\nFirst, we compute the inflated tables \\(R\\) (\\(n_\\bar{0} \\times r\\)) and \\(C\\) (\\(n_\\bar{0} \\times c\\)) from \\(Y\\) (\\(r \\times c\\)).\nWe take the frequency table defined before and use it to compute the inflated tables (with weights):\n\n# Create indicator tables\ntabR &lt;- acm.disjonctif(as.data.frame(Yfreq0$row))\ncolnames(tabR) &lt;- rownames(Y)\ntabC &lt;- acm.disjonctif(as.data.frame(Yfreq0$col))\ncolnames(tabC) &lt;- colnames(Y)\n\n# Get weights\nwt &lt;- Yfreq0$Freq\n\nBelow are the first lines of tables \\(R\\) and \\(C\\) (respectively):\n\n\nCode\nknitr::kable(head(tabR, 30))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n\n\n\nCode\nknitr::kable(head(tabC, 30))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\nThen, we perform a canonical correlation on the scaled tables \\(R_{scaled}\\) and \\(C_{scaled}\\). We find the coefficients \\(\\rho\\) and \\(\\gamma\\) maximizing the correlation between the scores \\(S_R = R_{scaled} \\rho\\) and \\(S_C = C_{scaled} \\gamma\\).\n\n# Center tables\ntabR_scaled &lt;- scalewt(tabR, wt, \n                       scale = FALSE)\ntabC_scaled &lt;- scalewt(tabC, wt, \n                       scale = FALSE)\n\nres &lt;- cancor(diag(sqrt(wt)) %*% tabR_scaled, \n              diag(sqrt(wt)) %*% tabC_scaled, \n              xcenter = FALSE, ycenter = FALSE)\n# res gives the coefficients of the linear combinations that maximizes the correlation between the 2 dimensions\nncol(res$xcoef) # r-1 columns -&gt; R_scaled is not of full rank\n\n[1] 25\n\nncol(res$ycoef) # c-1 columns -&gt; C_scaled is not of full rank\n\n[1] 20\n\n# Compute these scores from this coef\nscoreR &lt;- tabR_scaled[, 1:(r-1)]  %*% res$xcoef\nscoreC &lt;- tabC_scaled[, 1:(c-1)]  %*% res$ycoef\n\nFinally, we compute \\(H = (S_R + S_C)_{scaled}\\).\n\n# Get H\nscoreRC &lt;- scoreR[, 1:(c-1)] + scoreC[, 1:(c-1)] # here c-1 &lt; r so c-1 axes\nscoreRC_scaled &lt;- scalewt(scoreRC, wt = wt) # normalisation à 1\n\nWe check the agreement of \\(H\\) defined with CA of with canonical correlation analysis:\n\n# Check agreement of RC score and H score defined above\nall(abs(scoreRC_scaled/H) - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nPlots\nThe scores \\(H\\) are displayed below on the first two axes:\n\n\nCode\nmultiplot(indiv_row = H, \n          indiv_row_lab = paste0(\"site \", Yfreq0$row, \"/\", Yfreq0$col),\n          row_color = \"black\", eig = lambda)\n\n\n\n\n\nWe can group those scores by sites:\n\n\nCode\n# Group by sites\ns.label(H,\n        labels = paste(Yfreq0$row, Yfreq0$col, sep = \"-\"),\n        plabels.optim = TRUE,\n        plabels.col = \"darkgrey\",\n        main = \"Sites\")\ns.class(H, \n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        plabels.col = params$colsite,\n        add = TRUE)\n\n\n\n\n\nOr by species:\n\n\nCode\n# Group by species\ns.label(H,\n        labels = paste(Yfreq0$row, Yfreq0$col, sep = \"-\"),\n        plabels.optim = TRUE,\n        plabels.col = \"darkgrey\",\n        main = \"Species\")\ns.class(H, \n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        labels = colnames(Y),\n        plabels.col = params$colspp,\n        add = TRUE)\n\n\n\n\n\nWe will demonstrate more in-depth below how these groups are linked to the CA scores (means and variances can be computed directly from the CA scores.)"
  },
  {
    "objectID": "recscal.html#conditional-means-and-variances-of-rc-scores",
    "href": "recscal.html#conditional-means-and-variances-of-rc-scores",
    "title": "Reciprocal scaling",
    "section": "Conditional means and variances of RC scores",
    "text": "Conditional means and variances of RC scores\n\n\n\n\n\n\nTL;DR\n\n\n\nOnce we have the correspondences scores, we can group them by row (site) or column (species) to compute conditional summary statistics:\n\nconditional mean for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional variance for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional covariance for site \\(i\\) or species \\(j\\) (between axes \\(k\\) and \\(l\\))\n\nThese conditional statistics can be computed using \\(h_k(i, j)\\) or using the CA scores:\nFormulas using \\(h_k(i, j)\\)\nThe means are simply the weighted means of the \\(h_k(i, j)\\) for a fixed \\(i\\) or \\(j\\) (corresponds to meanfacwt). Similarly, the variances are weighted variances (can be computed with varfacwt).\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[m_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} h_k(i, j)\\]\n\\[m_k(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} h_k(i, j)\\]\n\n\nVariance for axis \\(k\\)\n\\[s_k^2(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} \\left(h_k(i, j) - m_k(i)\\right)^2\\]\n\\[s_k^2(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} \\left(h_k(i, j) - m_k(j)\\right)^2\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\\[c_{kl}(i) = \\frac{1}{y_{i \\cdot}}\\sum_{j=1}^c y_{ij}h_k(i, j)h_l(i, j) - m_k(i)m_l(i)\\]\n\\[c_{kl}(j) = \\frac{1}{y_{\\cdot j}}\\sum_{i=1}^r y_{ij}h_k(i, j)h_l(i, j) - m_k(j)m_l(j)\\]\n\n\n\nFormulas using CA scores\nSummary statistics are also related to CA scores.\nMore precisely, the means by species or site is equivalent to the CA coordinates (co and li) but with a proportionality a factor \\(\\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}}\\).\nThe variances are equivalent to a “weighted variance” (the formula resembles the variance developed formula: \\(\\frac{\\sum x_i^2}{n} - \\bar{x}^2\\)).\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[m_k(i) = \\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}} b_k(i)\\]\n\\[m_k(j) = \\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}} a_k(j)\\]\n\n\nVariance for axis \\(k\\)\n\\[s^2_k(i) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} a_k^2(j) \\right) - \\lambda_k b_k^2(i) \\right)\\]\n\\[s^2_k(j) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} b_k^2(i) \\right) - \\lambda_k a_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\\[c_{kl}(i) = \\frac{1}{2\\sqrt{\\lambda_k \\lambda_l} \\sqrt{\\mu_k \\mu_l}} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c y_{ij} a_k(j) a_l(j) - \\sqrt{\\lambda_k \\lambda_l} b_k(i)b_l(i) \\right)\\]\n\\[c_{kl}(j) = \\frac{1}{2\\sqrt{\\lambda_k \\lambda_l} \\sqrt{\\mu_k \\mu_l}} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} b_k(i) b_l(i) - \\sqrt{\\lambda_k \\lambda_l} a_k(j)a_l(j) \\right)\\]\n\n\n\nNote: formulas for the variances \\(s^2_k(i)\\) and \\(s^2_k(j)\\) are different from formula (15) in Thioulouse and Chessel (1992) (no square root at the denominator \\(2\\lambda_k\\mu_k\\)).\n\n\n\nUsing scores \\(h_k(i, j)\\)\n\nFor rows = sites\nWe compute the weighted mean of \\(h_k(i, j)\\) per row = site \\(i\\).\n\\[\nm_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} h_k(i, j)\n\\] We can compute means using a loop:\n\n\nCode\n# Get marginal counts\nyi_ &lt;- rowSums(Y)\ny_j &lt;- colSums(Y)\n\n\n\n\nCode\n# Initialize mean vector\nmrows &lt;- matrix(nrow = r, \n                ncol = kca) \n\nfor (i in 1:r) {\n  # Get nonzero cells for site i\n  rows &lt;- which(Yfreq0$row == i)\n  \n  # Get scores for site i\n  Hi &lt;- H[rows, ]\n  \n  # Get counts for site i\n  yij &lt;- Yfreq0$Freq[rows]\n  \n  # Fill i-th row with site i mean score along each axis\n  # (colSums sums all species j in site i)\n  if (is.matrix(Hi)) { # There are several species in site i\n    mrows[i, ] &lt;- 1/yi_[i]*colSums(diag(yij) %*% Hi)\n  } else { # Only one species in that site\n    mrows[i, ] &lt;- 1/yi_[i]*colSums(yij %*% Hi)\n  }\n}\n\n\nWe can also compute the mean using meanfacwt:\n\nmrows2 &lt;- meanfacwt(H, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n# Check\nres &lt;- mrows2/mrows\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# Check agreement with ade4 method\nmrows_ade4 &lt;- meanfacwt(rec_ca[, 1:kca], \n                        fac = rec_ca$Row, \n                        wt = rec_ca$Weight)\n\nall(abs(mrows_ade4/mrows) - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe compute the (weighted) variance of \\(h_k(i, j)\\) per row = site \\(i\\).\n\\[\ns_k^2(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} \\left(h_k(i, j) - m_k(i)\\right)^2\n\\]\nNB: in the original article (Thioulouse and Chessel 1992) they use the compact variance formula, \\(s_k^2(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c \\left(y_{ij} h_k(i, j)^2\\right) - m_k(i)^2\\) but I prefer the other formula.\nWe can use a loop:\n\n\nCode\n# Initialize mean vector\nvarrows &lt;- matrix(nrow = r, \n                  ncol = kca) \n\nfor (i in 1:r) {\n  # Get nonzero cells for site i\n  rows &lt;- which(Yfreq0$row == i)\n  \n  # Get scores for site i\n  Hi &lt;- H[rows, ]\n  \n  # Get counts for site i\n  yij &lt;- Yfreq0$Freq[rows]\n  \n  # Fill i-th row with site i variance along each axis\n  varrows[i, ] &lt;- 1/yi_[i]*colSums(diag(yij) %*% sweep(Hi, 2, mrows[i, ], \"-\")^2)\n}\n\n\nWe can also use varfacwt:\n\nvarrows2 &lt;- varfacwt(H, \n                     fac = Yfreq0$row, \n                     wt = Yfreq0$Freq)\n\n# Check\nres &lt;- varrows2/varrows\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# Check agreement with ade4 method\nvarrows_ade4 &lt;- varfacwt(rec_ca[, 1:kca], \n                         fac = rec_ca$Row, \n                         wt = rec_ca$Weight)\n\nall(abs(varrows_ade4/varrows) - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# We can also plot graphs and get back the variance graphical parameter\nvarrows_plot &lt;- s.class(rec_ca[,  1:2], \n                        fac = rec_ca$Row,\n                        wt = rec_ca$Weight, \n                        plot = FALSE)\nvarrows_ax1 &lt;- sapply(varrows_plot@stats$covvar, function(x) x[1,1])\n\nall(varrows_ax1/varrows[, 1] - 1 &lt; zero)\n\n[1] TRUE\n\n\nFinally, we can compute the covariance between scores on the several axes per row = site \\(i\\). The covariance between two axes \\(l\\) and \\(m\\) of the multivariate space for site = row \\(i\\) is defined as:\n\\[\nc_{kl}(i) = \\frac{1}{y_{i \\cdot}}\\sum_{j=1}^c y_{ij}h_k(i, j)h_l(i, j) - m_k(i)m_l(i)\n\\]\n\nk &lt;- 1\nl &lt;- 2\n\nBelow, we compute the covariance between axes \\(k =\\) 1 and \\(l =\\) 2.\n\n# Test to compute covariance for site 3 only\ni &lt;- 3\nrows &lt;- which(Yfreq0$row == i)\n\ncovrow1 &lt;- (1/yi_[i])*sum(Yfreq0$Freq[rows] * H[rows, k] * H[rows, l]) - mrows[i, k]*mrows[i, l]\n\n\n# Compute covariances for all sites\n\n# Create a df containing intermediate computation and row = site identifier\ndf &lt;- data.frame(var = Yfreq0$Freq*H[, k]*H[, l], \n                 by = Yfreq0$row)\n# Get the sum over the different species for each site\nsum_per_site &lt;- aggregate(df$var, list(df$by), sum)$x\n\n# Then vector-compute covariances\ncovrows_kl &lt;- (1/yi_)*sum_per_site - mrows[, k]*mrows[, l]\n\nWe check that the loop does what we want:\n\n\nCode\ncovrows_kl[i]/covrow1\n\n\n3 \n1 \n\n\nWe could also obtain the same result with covfacwt.\n\ncovrows &lt;- covfacwt(H, fac = Yfreq0$row, wt = Yfreq0$Freq)\n# Output: a list of length fac (here, sites) with the variance covariance matrices for each site\n\ncovrows_kl2 &lt;- sapply(covrows, function(c) c[k, l])\n\nres &lt;- covrows_kl/covrows_kl2\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe can also retrieve results from ade4:\n\n# Get results with covfacwt\ncovrows_ade4 &lt;- covfacwt(rec_ca[, 1:kca], \n                         fac = rec_ca$Row, \n                         wt = rec_ca$Weight)\n\nres &lt;- lapply(seq_along(covrows_ade4), \n              function(i) covrows_ade4[[i]]/covrows[[i]])\nreslist &lt;- sapply(res, \n                  function(ri) all(ri - 1 &lt; zero))\nall(reslist)\n\n[1] TRUE\n\n\n\n# Get results from ade4 plot\ncovrows_plot &lt;- s.class(rec_ca[,  k:l], \n                        fac = rec_ca$Row,\n                        wt = rec_ca$Weight, \n                        plot = FALSE)\ncovrows_kl_plot &lt;- sapply(covrows_plot@stats$covvar, function(x) x[k, l])\n\n# Check\nall(covrows_kl_plot/covrows_kl2 - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nFor columns = species\nSymetrically, we can compute the means, variances and covariances per columns = species \\(j\\).\n\\[\nm_k(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} h_k(i, j)\n\\]\n\n\nCode\nmcols &lt;- meanfacwt(H, \n                   fac = Yfreq0$col, \n                   wt = Yfreq0$Freq)\nmcols_ade4  &lt;- meanfacwt(rec_ca[,1:kca], \n                         fac = Yfreq0$col, \n                         wt = Yfreq0$Freq)\nres &lt;- mcols/mcols_ade4\nall(res - 1 &lt; zero)\n\n\n[1] TRUE\n\n\n\\[\ns_k^2(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} \\left(h_k(i, j) - m_k(j)\\right)^2\n\\]\n\n\nCode\nvarcols &lt;- varfacwt(H, \n                   fac = Yfreq0$col, \n                   wt = Yfreq0$Freq)\nvarcols_ade4  &lt;- varfacwt(rec_ca[,1:kca], \n                          fac = Yfreq0$col, \n                          wt = Yfreq0$Freq)\n\n\nTo check results, we treat as a special case species 7 and 13 because they appear in one site only:\n\ncolSums(Y != 0) == 1\n\n  sp1   sp2   sp3   sp4   sp5   sp6   sp7   sp8   sp9  sp10  sp11  sp12  sp13 \nFALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE \n sp14  sp15  sp16  sp17  sp18  sp19  sp21  sp22 \nFALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE \n\nsp1 &lt;- c(7, 13)\n\nIndeed, for this species the variance is null:\n\nvarcols[sp1, ]\n\n     X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 X11 X12 X13 X14 X15 X16 X17 X18 X19 X20\nsp7   0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0\nsp13  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0\n\n\n\nres &lt;- varcols[-sp1, ]/varcols_ade4[-sp1, ]\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\\[c_{kl}(j) = \\frac{1}{y_{\\cdot j}}\\sum_{i=1}^r y_{ij}h_k(i, j)h_l(i, j) - m_k(j)m_l(j)\\]\n\n\nCode\ncovcols &lt;- covfacwt(H, \n                   fac = Yfreq0$col, \n                   wt = Yfreq0$Freq)\ncovcols_ade4  &lt;- covfacwt(rec_ca[,1:kca], \n                          fac = Yfreq0$col, \n                          wt = Yfreq0$Freq)\n\nres &lt;- lapply(seq_along(covcols_ade4), \n              function(i) covcols_ade4[[i]]/covcols[[i]])\nreslist &lt;- sapply(res, \n                  function(ri) all(ri - 1 &lt; zero))\nall(reslist[-sp1])\n\n\n[1] TRUE\n\n\n\n\n\nUsing CA scores\n\nFor rows = sites\nThe conditional means and variances of rows scores on axis \\(k\\) for row \\(i\\) can also be computed as:\n\\[\nm_k(i) = \\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}} b_k(i)\n\\]\nwhere \\(b_k(i)\\) corresponds to the li for site \\(i\\) on axis \\(k\\).\n\nmrows_ca &lt;- sweep(ca$li, 2, sqrt(mu)/sqrt(2*lambda), \"*\")\n\n# Check with ade4 value\nall(mrows_ca/mrows_ade4 - 1 &lt; zero)\n\n[1] TRUE\n\n\nThe variance can be computed as:\n\\[\ns^2_k(i) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} a_k^2(j) \\right) - \\lambda_k b_k^2(i) \\right)\n\\]\nNote: this formula is different from formula (15) in Thioulouse and Chessel (1992) (no square root at the denominator \\(2\\lambda_k\\mu_k\\). Numerical computations suggest this is the correct formula.\n\nvarrows_ca &lt;- matrix(nrow = r, \n                     ncol = kca)\n\nfor (i in 1:r) {\n  # Get CA scores for site i\n  Li &lt;- B[i, ]\n  \n  # Compute the part with the sum on Cj\n  # we add all coordinates Cj^2 weighted by the number of observations on site i\n  sumCj &lt;- t(Y[i, ]) %*% as.matrix(A)^2\n\n  # Fill i-th row with site i variance along each axis\n  varrows_ca[i, ] &lt;- 1/(2*lambda*mu)*((1/yi_[i])*sumCj - lambda*as.numeric(Li)^2)\n}\n\n\n# Check with ade4 value\nall(varrows_ca/varrows_ade4 - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe can also compute the covariance using CA coordinates:\n\\[\nc_{kl}(i) = \\frac{1}{2\\sqrt{\\lambda_k \\lambda_l} \\sqrt{\\mu_k \\mu_l}} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c y_{ij} a_k(j) a_l(j) - \\sqrt{\\lambda_k \\lambda_l} b_k(i)b_l(i) \\right)\n\\]\nWe will use the same values as above for \\(k\\) and \\(l\\): \\(k =\\) 1 and \\(l =\\) 2.\n\n# Each site is multiplied by its score (Y*A[, k] by column) and then summed per site\nsum_per_site &lt;- rowSums(Y %*% diag(A[, k]) %*% diag(A[, l]))\n\ncovrows_ca_kl &lt;- 1/(2*sqrt(lambda[k]*lambda[l])*sqrt(mu[k]*mu[l]))*(1/yi_*sum_per_site - sqrt(lambda[k]*lambda[l])*B[, k]*B[, l])\n\nCheck that the CA formulas give the same result as the weighted covariance of correspondences:\n\n# Check result\n\nall(covrows_ca_kl/covrows_kl2 - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nFor columns = species\nSimilarly, column statistics can be computed from CA with the following formulas:\n\\[\nm_k(j) = \\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}} a_k(j)\n\\]\n\nmcols_ca &lt;- sweep(ca$co, 2, sqrt(mu)/sqrt(2*lambda), \"*\")\n\n# Check\nall(mcols_ca/mcols_ade4 - 1 &lt; zero)\n\n[1] TRUE\n\n\n\\[\ns^2_k(j) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} b_k^2(i) \\right) - \\lambda_k a_k^2(j) \\right)\n\\]\n\nvarcols_ca &lt;- matrix(nrow = c, \n                     ncol = kca)\n\nfor (j in 1:c) {\n  # Get CA scores for species j\n  Cj &lt;- A[j, ]\n  \n  # Compute the part with the sum on Li\n  sumLi &lt;- t(Y[, j]) %*% as.matrix(B)^2\n\n  # Fill i-th row with site i variance along each axis\n  varcols_ca[j, ] &lt;- 1/(2*lambda*mu)*((1/y_j[j])*sumLi - lambda*as.numeric(Cj)^2)\n}\n\n\n# Check\nall(varcols_ca[-sp1, ]/varcols_ade4[-sp1, ] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\\[\nc_{kl}(j) = \\frac{1}{2\\sqrt{\\lambda_k \\lambda_l} \\sqrt{\\mu_k \\mu_l}} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} b_k(i) b_l(i) - \\sqrt{\\lambda_k \\lambda_l} a_k(j)a_l(j) \\right)\n\\]\nWe use the same values of \\(k =\\) 1 and \\(l =\\) 2 as above.\n\n# Each spp is multiplied by its score (Y*B[, k] by row) and then summed per spp\nsum_per_spp &lt;- colSums(diag(B[, k]) %*% diag(B[, l]) %*% Y)\n\ncovcols_kl_ca &lt;- 1/(2*sqrt(lambda[k]*lambda[l])*sqrt(mu[k]*mu[l]))*(1/y_j*sum_per_spp - sqrt(lambda[k]*lambda[l])*A[, k]*A[, l])\n\n\n# Check\ncovcols_kl &lt;- sapply(covcols_ade4,\n                     function(x) x[k, l])\n\nall(covcols_kl[-sp1]/covcols_kl_ca[-sp1] - 1 &lt; zero)\n\n[1] TRUE"
  },
  {
    "objectID": "recscal.html#conditional-means-and-variances-of-r-scores-and-c-scores",
    "href": "recscal.html#conditional-means-and-variances-of-r-scores-and-c-scores",
    "title": "Reciprocal scaling",
    "section": "Conditional means and variances of R scores and C scores",
    "text": "Conditional means and variances of R scores and C scores\nNote: in this part, we change the notation (notation previously used in this part) and use \\(L_k(i)\\) for li and \\(L1_k(i)\\) for l1 (and the same with \\(C_k(j)\\) for co and \\(C1_k(j)\\) for c1).\n\n\n\n\n\n\nTL;DR\n\n\n\nWe can also compute compute means, variances and covariances with the R score or the C score.\nWe use the notation \\(m_k(i)\\)/\\(s^2_k(i)\\) for the mean/variances of sites (index \\(i\\)) computed with the RC scores and \\(mR_k(i)\\)/\\(sR^2_k(i)\\) for the mean/variances of sites computed with the R score. For the means computed for species, we use index \\(j\\) and for the means/variances computed with C scores, we use \\(mC\\)/\\(sC^2\\).\nDefinition\nThe definitions are simply the groupwise mean, variance and covariance.\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_j y_{ij} ~ \\text{scoreR}_k(i, j)\\]\n\\[mR_k(j) = \\frac{1}{y_{\\cdot j}} \\sum_i y_{ij} ~ \\text{scoreR}_k(i, j)\\]\n\n\nVariance for axis \\(k\\)\n\\[sR^2_k(i) = \\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ \\text{scoreR}(i, j)^2 - mR_k(i)^2\\]\n\\[sR^2_k(j) = \\frac{1}{y_{i \\cdot}} \\sum_j y_{ij} ~ \\text{scoreR}(i, j)^2 - mR_k(j)^2\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mC_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_j y_{ij} ~ \\text{scoreC}_k(i, j)\\]\n\\[mC_k(j) = \\frac{1}{y_{\\cdot j}} \\sum_i y_{ij} ~ \\text{scoreC}_k(i, j)\\]\n\n\nVariance for axis \\(k\\)\n\\[sC^2_k(i) = \\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ \\text{scoreC}(i, j)^2 - mC_k(i)^2\\]\n\\[sC^2_k(j) = \\frac{1}{y_{i \\cdot}} \\sum_j y_{ij} ~ \\text{scoreC}(i, j)^2 - mC_k(j)^2\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\nFormulas using CA score\nNow we can “prove” that the values defined above can be recomputed from the CA scores too.\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\(\\frac{1}{\\sqrt{n}} L1_k(i)\\)\n\\(\\frac{1}{\\sqrt{n}} C_k(j)\\)\n\n\nVariance for axis \\(k\\)\nNone\n\\[\\frac{1}{n \\lambda_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} L_k^2(i) \\right) - \\lambda_k C_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\nNone\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\(L_k(i) \\times \\frac{1}{\\sqrt{n}}\\)\n\\(C1_k(j) \\times \\frac{1}{\\sqrt{n}}\\)\n\n\nVariance for axis \\(k\\)\n\\[\\frac{1}{n \\lambda_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} C_k^2(j) \\right) - \\lambda_k L_k^2(i) \\right)\\]\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\nNone\n\n\n\nRelation between RC scores and R score / C score\nFinally, we can relate the quantity computed above (with the definition or with the CA scores) with the means/variances/covariances computed with the RC scores.\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{\\sqrt{2}}{\\sqrt{\\mu_k n}} m_k(i)\\]\n\\[mR_k(j) = \\frac{\\sqrt{2 \\lambda_k}}{\\sqrt{\\mu_k n}} m_k(j)\\]\n\n\nVariance for axis \\(k\\)\nNone\n\\[sR^2_k(j) = \\frac{2 \\mu_k}{n} s^2_k(j)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mC_k(i) =  \\frac{\\sqrt{2 \\lambda_k}}{\\sqrt{\\mu_k n}} m_k(i)\\]\n\\[mC_k(j) = \\frac{\\sqrt{2}}{\\sqrt{\\mu_k n}} m_k(j) \\]\n\n\nVariance for axis \\(k\\)\n\\[sC^2_k(i) = \\frac{2 \\mu_k}{n} s^2_k(i)\\]\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\n\nThis is not at all developed in the article of Thioulouse and Chessel (1992), but we could also use directly the R scores and the C scores to compute the groupwise (species- or sites-wise) mean and variances. In fact, the means and variances computed from the scoresR and scoresC should be related to the means and variances computed from \\(L_k(i)\\) = li and \\(C_k(j)\\) = co, since scoreR = l1 and scoreC = c1.\nWe bother computing these because with CCA and dc-CA, we can’t use directly RC scores.\n\nFor rows = sites (group per row)\n\nn &lt;- sum(Y)\n\n\nscoreC\n\nMean\nWe compute the mean score per site from the column scores.\n\nmrowsC &lt;- meanfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nWe have \\(mC_k(i) = \\frac{L_k(i)}{\\sqrt{n}}\\).\n\nres &lt;- mrowsC/(ca$li * 1/sqrt(n))\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe can prove that equality: we begin by writing the weighted mean formula of scoreC:\n\\[mC_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_i y_{ij} ~ \\text{scoreC}_k(i, j)\\] We replace scoreC with \\(\\frac{C1_k(j)}{\\sqrt{n}}\\) (this equality remains to be proven):\n\\[mC_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_i y_{ij} \\frac{C1_k(j)}{\\sqrt{n}}\\]\nThen we remove \\(\\frac{1}{n}\\) from the sum:\n\\[mC_k(i) = \\frac{1}{\\sqrt{n}}\\frac{1}{y_{i\\cdot}} \\sum_i y_{ij} C1_k(j)\\] By definition, the li are at the mean of the c1 so we can replace \\(\\frac{1}{y_{i\\cdot}} \\sum_i y_{ij} C1_k(j)\\) with \\(L_k(i)\\):\n\\[mC_k(i)  = \\frac{1}{\\sqrt{n}} L_k(i)\\]\n\n\nVariance\nNow, we compare variances computed with the scoreC and variances computed with the scoreRC.\n\nvarrowsC &lt;- varfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nWe have \\(sC_k^2(i) = \\frac{2\\mu_k}{n} ~ s^2_k(i)\\).\n\nres &lt;- varrowsC / (varrows %*% diag(2*mu) / n)\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\nHere too, we can prove the relationship above between the variance of the RC score and the variance of the C score.\n\\[\n\\begin{align}\nsC_k^2(i)\n&= \\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ \\text{scoreC}(i, j)^2 - mC_k(i)^2\\\\\n&= \\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ \\left(\\frac{C1_k(j)}{\\sqrt{n}}\\right)^2 - \\left(\\frac{L_k(i)}{\\sqrt{n}}\\right)^2\\\\\n&= \\frac{1}{n} \\left(\\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ C1_k(j)^2 - L_k(i)^2\\right)\\\\\n&= \\frac{1}{n} \\left(\\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ \\left( \\frac{C_k(j)}{\\sqrt{\\lambda_k}}\\right)^2 - L_k(i)^2\\right)\\\\\n&= \\frac{1}{n} \\times \\frac{1}{\\lambda_k} \\left(\\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ C_k(j)^2 - \\lambda_k L_k(i)^2\\right)\\\\\n&= \\frac{1}{n} \\times \\frac{1}{\\lambda_k} \\times 2\\lambda_k \\mu_k \\times \\frac{1}{2\\lambda_k \\mu_k} \\left(\\frac{1}{y_{\\cdot j}} \\sum_j y_{ij} ~ C_k(j)^2 - \\lambda_k L_k(i)^2\\right)\\\\\nsC_k^2(i) &= \\frac{2\\mu_k}{n} ~ s^2_k(i)\n\\end{align}\n\\]\n\n\n\nscoreR\n\nMean (unique)\nWe compute the mean score per site from the sites scores (i.e. the unique scoreR, since all R values are superimposed for the same site).\n\nmrowsR &lt;- meanfacwt(scoreR, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n\n# The mean per site (row) of scoreR is the same as the unique scores\nmrowsR_u &lt;- unique(scoreR)\nall(mrowsR/mrowsR_u - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# NB: weighting doesn't make a difference because all weights are the same for the same row\nmrowsR_nw &lt;- meanfacwt(scoreR, fac = Yfreq0$row)\n\nall(mrowsR/mrowsR_nw - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe have \\(mR_k(i) = \\frac{L1_k(i)}{\\sqrt{n}}\\).\n\nres &lt;- mrowsR * sqrt(n)/ca$l1\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nVariances (null)\nWe don’t compute variances per rows for the scoreR, because they are null.\n\n\n\nPlots\nBelow are R and C scores grouped by sites (rows):\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colspp,\n        plabels.col = params$colsite, \n        main = \"C scores grouped by sitse (rows)\")\n\n\n\n\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite, \n        main = \"R scores grouped by sites (rows)\")\n\n\n\n\nWe can compare these plots to the RC scores plot below (grouped by sites/rows):\n\ns.class(scoreRC_scaled, \n        wt = Yfreq0$Freq,\n        fac = Yfreq0$row,\n        labels = rownames(Y),\n        plabels.col = params$colsite,\n        main = \"RC scores grouped by sites (rows)\")\n\n\n\n\n\n\n\nFor columns = species (group per column)\n\nscoreC\n\nMean (unique)\nWe compute the mean score per species from the column scores.\n\nmcolsC &lt;- meanfacwt(scoreC, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nWe have \\(mC_k(j) = \\frac{C1_k(j)}{\\sqrt{n}}\\).\n\n# Check\nres &lt;- mcolsC * sqrt(n)/ca$c1\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nVariances (null)\nWe don’t compute variances (they are null).\n\n\n\nscoreR\n\nMean\nWe compute the mean score per species from the row scores.\n\nmcolsR &lt;- meanfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nWe have \\(mR_k(j) = \\frac{C_k(j)}{\\sqrt{n}}\\).\n\nres &lt;- mcolsR/(ca$co/sqrt(n))\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nVariances\nWe compute the variance of species (columns) from the R score:\n\nvarcolsR &lt;- varfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nWe have \\(sR_k^2(j) = \\frac{2\\mu_k}{n} ~ s^2_k(j)\\).\n\n# Check\nres &lt;- (varcolsR[-sp1, 1:kca] %*% diag(1/(2*mu)) * n)/varcols[-sp1, ]\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\nConclusion: using RC scores or using R scores only to compute species-wise means and variances is the same, but there are some multiplying factors.\n\n\n\nPlots\nBelow are R and C scores grouped by species (columns):\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp, \n        main = \"C scores grouped by species (columns)\")\n\n\n\n\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colsite,\n        plabels.col = params$colspp, \n        main = \"R scores grouped by species (columns)\")\n\n\n\n\nWe can compare these plots to the RC scores plot below (grouped by species/columns):\n\ns.class(scoreRC_scaled, \n               wt = Yfreq0$Freq,\n               fac = as.factor(Yfreq0$colind),\n               labels = colnames(Y),\n               plabels.col = params$colspp,\n               main = \"RC scores grouped by species (columns)\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can also compare means/variances extracted from the plots:\n\n\nCode\n# Plot with RC score = H\nxax &lt;- 2\nyax &lt;- 3\nsRC &lt;- s.class(scoreRC_scaled, \n               xax = xax, yax = yax,\n               wt = Yfreq0$Freq,\n               fac = as.factor(Yfreq0$colind),\n               plot = FALSE)\n\n# Plot with R score\nsR &lt;- s.class(scoreR,\n              xax = xax, yax = yax,\n              wt = Yfreq0$Freq,\n              fac = as.factor(Yfreq0$colind),\n              plot = FALSE)\n\n# Compare means\nfac &lt;- sqrt(mu)/sqrt(2*lambda)\nres &lt;- sRC@stats$means/(sR@stats$means %*% diag(fac[c(xax, yax)])*sqrt(n)) \nall(res - 1 &lt; zero) # means are the same\n\n\n[1] TRUE\n\n\nCode\n# Compare variances\nvarRC_ax1 &lt;- (sapply(sRC@stats$covvar, function(x) x[1, 1])*(2*mu[xax]/n))\nvarR_ax1 &lt;- sapply(sR@stats$covvar, function(x) x[1, 1])\n\nres &lt;- varRC_ax1[-sp1]/varR_ax1[-sp1]\nall(res - 1 &lt; zero) # Same on ax1\n\n\n[1] TRUE\n\n\nCode\nvarRC_ax2 &lt;- (sapply(sRC@stats$covvar, function(x) x[2, 2])*(2*mu[yax]/n))\nvarR_ax2 &lt;- sapply(sR@stats$covvar, function(x) x[2, 2])\n\nres &lt;- varRC_ax2[-sp1]/varR_ax2[-sp1]\nall(res - 1 &lt; zero) # Same on ax2\n\n\n[1] TRUE"
  },
  {
    "objectID": "recscal.html#ggplotting",
    "href": "recscal.html#ggplotting",
    "title": "Reciprocal scaling",
    "section": "ggplotting",
    "text": "ggplotting\n\n1d plots\n\n\nCode\n# Define plotting function\nplot_meanvar &lt;- function(mean, var, groupnames, x = 1, col = \"black\")  {\n  ggplot() +\n  geom_point(aes(x = mean[, x], \n                 y = reorder(groupnames, -mean[, x])),\n             colour = col, shape = 1) +\n  geom_linerange(aes(x = mean[, x], \n                     y = reorder(groupnames, -mean[, x]),\n                     xmin = mean[, x] - var[, x],\n                     xmax = mean[, x] + var[, x]),\n                 colour = col) +\n  xlab(paste(\"Axis\", x)) +\n  theme_linedraw() +\n  theme(axis.title.y = element_blank())\n}\n\n\nLet’s plot these means and variances along the first axis for rows and columns:\n\n\nCode\ngr &lt;- plot_meanvar(mean = mrows, \n                   var = 3*sqrt(varrows), \n                   groupnames = rownames(Y),\n                   col = params$colsite) +\n  ggtitle(\"Rows (sites) mean and variance\")\ngc &lt;- plot_meanvar(mean = mcols, \n                   var = 3*sqrt(varcols), groupnames = colnames(Y),\n                   col = params$colspp) +\n  ggtitle(\"Columns (species) mean and variance\")\n\ngr + gc\n\n\n\n\n\nSame result with ade4 function:\n\n\nCode\ns1d.distri(score = ca$li[, 1], \n           dfdistri = as.data.frame(Y),\n           ppoints.col = params$colspp,\n           plabels.col = params$colspp)\n\n\n\n\n\nCode\ns1d.distri(score = ca$co[, 1], \n           dfdistri = as.data.frame(t(Y)),\n           ppoints.col = params$colsite,\n           plabels.col = params$colsite)\n\n\n\n\n\n\n\nCode\ngr &lt;- ggplot() +\n  geom_point(aes(x = covrows_kl2, y = reorder(rownames(Y), -covrows_kl2)),\n             col = params$colsite) +\n  xlab(paste(\"Covariances between axes\", k, \"and\", l)) +\n  theme_linedraw() +\n  theme(axis.title.y = element_blank()) + \n  ggtitle(\"Rows (sites) covariances\")\n\ngc &lt;- ggplot() +\n  geom_point(aes(x = covcols_kl, y = reorder(colnames(Y), -covcols_kl)),\n             col = params$colspp) +\n  xlab(paste(\"Covariances between axes\", k, \"and\", l)) +\n  theme_linedraw() +\n  theme(axis.title.y = element_blank()) + \n  ggtitle(\"Columns (species) covariances\")\n\ngr + gc\n\n\n\n\n\n\n\n2d plots\nWe can also plot the ellipses in 2 dimensions.\nFor that, we need to plot the ellipse summarizing the Gaussian bivariate law for each group. For example, for site \\(i\\) on axes \\(k\\) and \\(l\\) reference blog post:\n\nthe mean vector is \\(\\mu(i) = (m_k(i), m_l(i))\\)\nthe variance-covariance matrix is \\(\\Sigma(i) = \\begin{pmatrix} \\sigma_k^2 ~ \\sigma_{kl}\\\\ \\sigma_{kl} ~ \\sigma_{l}^2 \\end{pmatrix}\\)\n\nThe simplest equation (covariance zero, centered on the origin) is:\n\\[\\left( \\frac{x}{\\sigma_k} \\right)^2 + \\left( \\frac{y}{\\sigma_l} \\right)^2 = s\\] The semi-axes are of length \\(\\sigma_k \\sqrt{s}\\) and \\(\\sigma_l \\sqrt{s}\\). \\(s\\) is the scaling factor allowing the ellipsis to encompass all data with a level of confidence \\(p\\). We have \\(s = -2 \\ln(1-p)\\).\nWe can show that this equation is equivalent to\n\\[\\begin{cases} x = \\sigma_k \\sqrt{s} \\cos(t)\\\\ y = \\sigma_l \\sqrt{s} \\sin(t)  \\end{cases}\\] With \\(t\\) being an angle between 0 and \\(2\\pi\\).\nWe write \\(a\\) the length of the semi-major axis and \\(b\\) the length of the semi-minor axis.\nNow in case the values \\(h_k(i, j)\\) and \\(h_l(i, j)\\) are correlated, the covariance is not zero. Then, the semi-axes lengths are the square root of the eigenvaluesof \\(\\Sigma(i)\\). Geometrically, we have an angle \\(\\theta\\) between axis \\(k\\) and the semi-major axis. \\(\\theta\\) can be computed as the direction of the first eigenvector \\(v_1\\): \\(\\theta = \\arctan(v_1(2)/v_1(1))\\).\nThe equation of the ellipsis is: \\[\\begin{cases} x = m_k(i) +  a  \\cos(\\theta) \\cos(t) - b \\sin(\\theta) \\sin(t) \\\\ y = m_l(i) + a \\sin(\\theta) \\cos(t) + b \\cos(\\theta) \\sin(t) \\end{cases}\\] With \\(a = \\sqrt{\\lambda_1} \\sqrt{s}\\) and \\(b = \\sqrt{\\lambda_2} \\sqrt{s}\\). (Here we assumed the origin could be different from zero and shifted the center with \\(m_k(i)\\) and \\(m_l(i)\\).)\n\n\nCode\ngaussian_ellipses &lt;- function(vars, covars, means, x = 1, y = 2,\n                              t = seq(0, 2*pi, 0.01), s = 1.5, ind = 1:nrow(vars)) {\n  # Length of angles\n  nt &lt;- length(t)\n  \n  # Initialize matrix\n  ellipses_mat &lt;- matrix(nrow = length(t)*nrow(vars), \n                         ncol = 3)\n  \n  for (i in ind) {\n    # Define variance covariance matrix\n    covar &lt;- covars[i]\n    varx &lt;- vars[i, x]\n    vary &lt;- vars[i, y]\n    mat &lt;- matrix(data = c(varx, covar,\n                           covar, vary),\n                  nrow = 2)\n    \n    # Eigenvalues\n    vp &lt;- eigen(mat)$values\n    \n    a &lt;- s*sqrt(max(vp)) # semi major axis\n    b &lt;- s*sqrt(min(vp)) # semi minor axis\n    \n    # angle (inclination of ellipse from axe x)\n    if(covar == 0 & varx &gt;= vary){ # covariance is zero and varx is big\n      theta &lt;- 0\n    }else if(covar == 0 & varx &lt; vary){ # covariance is zero and varx is small\n      theta &lt;- pi/2\n    }else{ # \"normal\" cases\n      # get eigenvector associated to largest eigenvalue\n      v1 &lt;- eigen(mat)$vectors[,1]\n      # theta is the angle of the eigenvector with x -&gt; ie\n      # arctan of the slope given by the first eigenvector\n      theta &lt;- atan(v1[2]/v1[1])\n    }\n    \n    # x and y coordinates of ellipse\n    xellipse &lt;- means[i, x] + a*cos(theta)*cos(t) - b*sin(theta)*sin(t)\n    yellipse &lt;- means[i, y] + a*sin(theta)*cos(t) + b*cos(theta)*sin(t)\n    \n    indmin &lt;- (i-1)*nt + 1\n    indmax &lt;- i*nt\n    ellipses_mat[indmin:indmax, ] &lt;- matrix(c(xellipse, yellipse, rep(i,nt)),\n                                           ncol = 3)\n  }\n  res &lt;- as.data.frame(ellipses_mat)\n  colnames(res) &lt;- c(\"xell\", \"yell\", \"group\")\n  return(res)\n}\n\n\n\n\nCode\nplot_ellipses &lt;- function(var, covar, mean, groupnames, \n                          H, Yfreq0, col = \"black\", ellipses = 1:nrow(var), s = 1.5, x = 1, y = 2) {\n  \n  if (all(groupnames %in% Yfreq0$row)) {\n    indivtype &lt;- \"row\"\n  } else {\n    indivtype &lt;- \"colind\"\n  }\n  \n  rows &lt;- which(Yfreq0[[indivtype]] %in% ellipses)\n  \n  # Get gaussian ellipses for the required groups\n  ell &lt;- gaussian_ellipses(var, covar, mean, s = s, x = k, y = l, ind = ellipses)\n  \n  # Plot ellipses from variance and covariance\n  ggplot() +\n    geom_hline(yintercept = 0) +\n    geom_vline(xintercept = 0) +\n    geom_point(aes(x = H[, x], y = H[, y], alpha = Yfreq0[[indivtype]] %in% ellipses),\n               col = col,\n               show.legend = FALSE) +\n    scale_alpha_manual(values = c(\"TRUE\" = 1, \"FALSE\" = 0.2)) +\n    # Label ellipse points only\n    geom_text_repel(aes(x = H[rows, x], y = H[rows, y], \n                        label = paste(Yfreq0$row[rows], Yfreq0$col[rows])),\n                    col = col) +\n    geom_polygon(data = ell, \n                 aes(x = xell, y = yell, group = group),\n                 fill = col, col = col, alpha = 0.5) +\n    theme_linedraw() +\n    geom_label(aes(x = mean[, x], y = mean[, y], label = groupnames),\n               colour = col) +\n    xlab(paste(\"Axis\", x)) +\n    ylab(paste(\"Axis\", y)) \n}\n\n\n\n\nCode\ngr &lt;- plot_ellipses(varrows, covrows_kl2, mrows, \n                    groupnames = rownames(Y), H = H, Yfreq0 = Yfreq0,\n                    col = params$colsite) + ggtitle(\"Rows (sites)\")\n\ngc &lt;- plot_ellipses(varcols, covcols_kl, mcols, \n                    groupnames = colnames(Y), H = H, Yfreq0 = Yfreq0, \n                    col = params$colspp) + ggtitle(\"Columns (species)\")\n\n\nWarning in sqrt(min(vp)): Production de NaN\n\nWarning in sqrt(min(vp)): Production de NaN\n\n\nCode\ngr + gc\n\n\nWarning: ggrepel: 196 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\nWarning: ggrepel: 196 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\nCode\n# Choose a subset of sites\ni &lt;- c(2, 13, 18)\ngr &lt;- plot_ellipses(varrows, covrows_kl2, mrows, \n                    groupnames = rownames(Y), H = H, Yfreq0 = Yfreq0,\n                    ellipses = i, col = params$colsite) + \n  ggtitle(\"Rows (sites)\")\n\n# Choose a subset of species\nj &lt;- c(16, 12, 20) # sp21 is index 20\ngc &lt;- plot_ellipses(varcols, covcols_kl, mcols, \n                    groupnames = colnames(Y), H = H, Yfreq0 = Yfreq0, \n                    ellipses = j, col = params$colspp) + \n  ggtitle(\"Columns (species)\")\n\ngr + gc\n\n\nWarning: ggrepel: 2 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\nReproduce the same plots with ade4:\n\n\nCode\ns.class(rec_ca[, 1:2],\n        wt = rec_ca$Weight, \n        fac = rec_ca$Row,\n        col = params$colsite,\n        main = \"Rows (sites)\")\n\n\n\n\n\nCode\ns.class(rec_ca[, 1:2], \n        wt = rec_ca$Weight, \n        fac = rec_ca$Col,\n        col = params$colspp,\n        main = \"Columns (species)\")"
  },
  {
    "objectID": "recscal.html#additional-developments",
    "href": "recscal.html#additional-developments",
    "title": "Reciprocal scaling",
    "section": "Additional developments",
    "text": "Additional developments\n\nFormula (3) in Thioulouse and Chessel (1992)\nLet’s test formula (3) in Thioulouse and Chessel (1992):\n\\[L_k(i) = \\sum_{j=1}^c p_{j|i} C_k(j)\\]\nwith \\(p_{j|i} = \\frac{y_{ij}}{y_{i \\cdot}}\\). This formula relates species and samples scores in CA.\n\n# Test formula for a given k\nk &lt;- 2\n\n# compute pj|i\npjcondi &lt;- sweep(Y, 1, yi_, \"/\")\n\n# Compute the formula that should be equal th Lk(i)\nres &lt;- vector(mode=\"numeric\", length=nrow(Y))\nfor (i in 1:nrow(Y)) {\n  res[i] &lt;- sum(pjcondi[i, ]*ca$co[, k])\n}\n\n\nres/ca$li[, k] # not equal\n\n [1] 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288\n [8] 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288\n[15] 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288\n[22] 0.4925288 0.4925288 0.4925288 0.4925288 0.4925288\n\n\nWe find that in fact the correct formula is\n\\[L_k(i) = \\frac{1}{\\sqrt{\\lambda_k}}\\sum_{j=1}^c p_{j|i} C_k(j)\\]\n\nres/sqrt(lambda[k])/ca$li[, k]\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nWith this equality, we can indeed prove numerically the equivalence between mean computation using \\(h_k(i, j)\\) (Equations (12) and (14) in Thioulouse and Chessel (1992)) and using CA coordinates (computation in notebook not shown here).\n\n\nMean of means\nThe reciprocal scaling mean computed with \\(\\frac{\\sqrt{\\mu_k}}{\\sqrt{2 \\lambda_k}} a_k(i)\\) is the same as the weighted mean of the weighted means \\(\\frac{\\sqrt{\\mu_k}}{\\sqrt{2 \\lambda_k}} b_k(j)\\), where \\(j\\) is used to index all species occurring in site \\(i\\). So we can interpret species/site-wise means of the \\(H\\) scores as means of means of the other category.\n\ni &lt;- 1 # site\nk &lt;- 1:2 # axes\n\n# Get the correspondences for site i\nHsub &lt;- H[Yfreq0$row == i, k]\nj &lt;- Yfreq0$col[Yfreq0$row == i]\nrownames(Hsub) &lt;- paste0(\"s\", i, \"-\", j)\n\n# Get the weights of correspondences\nwth &lt;- Yfreq0$Freq[Yfreq0$row == i]\n\n# Weighted mean of correspondences\nh_i &lt;- meanfacwt(Hsub, wt = wth) \nh_i &lt;- data.frame(t(h_i))\nrownames(h_i) &lt;- paste(\"rec\", i)\n\n# Get reciprocal scaling means computed from CA coordinates\n# For site i\nca_i &lt;- ca$li[i, k]*sqrt(mu[k])/sqrt(2*lambda[k]) \nrownames(ca_i) &lt;- paste(\"CA\", i)\n\n# For species j present in site i (transformed coordinates)\nca_j &lt;- sweep(ca$co[j, k], 2, sqrt(mu[k])/sqrt(2*lambda[k]), \"*\")\n\n\n# Compare weighted means\nh_i/ca_i\n\n      X1 X2\nrec 1  1  1\n\n\nOn this plot, we plot the CA coordinates for site \\(i\\) and for all species \\(j\\) in site \\(i\\) (scaled with a factor \\(\\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}}\\). We surimpose the reciprocal scaling correspondences for site \\(i\\) (purple dots).\nNB: Means should be surimposed, I don’t know why they are not.\n\n\nCode\n# Plot correspondences and mean\ns.class(Hsub, \n        fac = factor(rep(paste(\"rec\", i), nrow(Hsub))),\n        wt = wth,\n        ppoints.col = \"darkgrey\",\n        main = \"Correspondences\")\ns.label(Hsub, \n        plabels.optim = TRUE, add = TRUE,\n        ppoints.col = \"darkorchid\",\n        plabels.col = \"darkorchid\")\ns.label(ca_i, \n        plabels.col = params$colsite, add = TRUE)\ns.label(h_i, \n        plabels.col = params$colsite, add = TRUE)\n\n\n\n\n\n\n\nCode\n# Plot CA and mean\n# On a separate plot because else ade4 goes crazy\ns.class(ca_j,\n        ppoints.col = \"grey\",\n        fac = factor(rep(i, nrow(ca_j))),\n        wt = wth,\n        main = \"Means\")\ns.label(ca_j, \n        plabels.optim = TRUE, add = TRUE,\n        plabels.col = params$colspp, \n        ppoints.col = params$colspp, )\ns.label(ca_i, \n        plabels.col = params$colsite, add = TRUE)\ns.label(h_i, \n        plabels.col = params$colsite, add = TRUE)\n\n\n\n\n\n\n\nNon-reciprocal score\nIf we don’t wand to find a new common space to plot correspondences in, we can remain in the 2 biplots showing \\(U\\) and \\(A\\) (co and l1) and \\(V\\) with \\(B\\) (c1 and li).\nTo do that, we define the “CA-correspondences” \\(\\tilde{h}_k(i, j)\\):\n\\[\\tilde{h}_k(i, j) = \\frac{b_k(i) + v_k(j)}{2}\\]\n\n# Create duplicated records of the site (one for each species)\ncali_rep &lt;- c()\nfor (jiter in 1:length(j)) {\n  cali_rep &lt;- rbind(cali_rep, ca$li[i, ])\n}\n\n# Compute Htilde for this site\nHtilde &lt;- (ca$c1[j, ] + cali_rep)/2\n\nhtilde_mean_i &lt;- apply(Htilde, 2, \n                       FUN = meanfacwt, wt = wth)\nres &lt;- htilde_mean_i/ca$li[i, ]\nall(res - 1 &lt; zero) # this corresponds to the li\n\n[1] TRUE\n\n\nBelow is a graphical demonstration showing the ellipses computed with \\(\\tilde{h}_k(i, j)\\). Its mean is surimposed with li (\\(B\\)) (or it should be, theoretically) and it is similar but smaller than the ellipse computed with c1 (\\(V\\)):\n\n\nCode\n# Get the mean of the c1\ns.class(ca$c1[j, ], \n        fac = factor(rep(i, nrow(ca$c1[j, ]))),\n        wt = Yfreq0$Freq[Yfreq0$row == i],\n        ppoints.col = \"darkgrey\",\n        main = \"Non-reciprocal scaling\")\ns.label(ca$c1[j, ], \n        plabels.col = params$colspp, \n        ppoints.col = params$colspp,  \n        plabels.optim = TRUE,\n        add = TRUE)\n# Mean of the Htilde\ns.class(Htilde, \n        fac = factor(rep(i, nrow(Hsub))),\n        wt = Yfreq0$Freq[Yfreq0$row == i],\n        ppoints.col = \"darkorchid\",\n        add = TRUE)\n# li\ns.label(ca$li[i, ], \n        plabels.col = params$colsite, add = TRUE)\n\n\n\n\n\nIf we were to compute these CA correspondences in the other biplot, it would be: \\[\\tilde{h}_k(i, j) = \\frac{u_k(i) + a_k(j)}{2}\\]"
  },
  {
    "objectID": "CCA.html",
    "href": "CCA.html",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nsource(here(\"functions/plot.R\"))\nlibrary(gridExtra)\nCode\n# Define bound for comparison to zero\nzero &lt;- 10e-10\nThe contents of this page relies heavily on Legendre and Legendre (2012)."
  },
  {
    "objectID": "CCA.html#introduction",
    "href": "CCA.html#introduction",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Introduction",
    "text": "Introduction\nCCA is a method of the family of canonical or direct gradient analyses, in which a matrix of predictor variables intervenes in the computation of the ordination vectors.\nCCA is an asymmetric method because the predictor variables and the response variables are not equivalent in the analysis.\nCCA takes two matrices in input:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables \\(E\\) (\\(r \\times l\\))\n\n\n\nCode\ndat &lt;- readRDS(here(\"data/Barbaro2012.rds\"))\nY &lt;- dat$comm\nE &lt;- dat$envir\n\nr &lt;- dim(Y)[1]\nc &lt;- dim(Y)[2]\nl &lt;- dim(E)[2]\n\nplotmat(r = r, c = c, l = l, \n        E = TRUE)\n\n\n\n\n\nHere, \\(Y\\) represents the abundance of different bird species (columns) at different sites (rows):\n\n\nCode\nknitr::kable(head(Y))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n\n\n\n\\(E\\) represents environmental variables (columns) associated to each site (rows).\n\n\nCode\nknitr::kable(head(E))\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- dim(E)[2])\n\n[1] 6"
  },
  {
    "objectID": "CCA.html#computation",
    "href": "CCA.html#computation",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nWe have a data matrix \\(Y\\) (\\(r \\times c\\)) and a matrix \\(E\\) (\\(r \\times l\\)) of predictors variables.\nWe regress \\(P_0\\) (“centered” \\(Y\\)) on \\(E_{stand}\\) (which is the centered and scaled \\(E\\) matrix):\n\\[\n\\hat{P_0} = D_r^{1/2} E_{stand}B\n\\]\nThen, we diagonalize matrix \\(S_{\\hat{P_0}^\\top \\hat{P_0}} = \\hat{P_0}^\\top\\hat{P_0}\\).\n\\[\nS_{\\hat{P_0}^\\top\\hat{P_0}} =  V_0 \\Lambda V_0^{-1}\n\\]\nThe matrix \\(V_0\\) (\\(c \\times \\text{mindim}\\)) contains the loadings of the columns (species) of the contingency table. There are \\(\\text{mindim} = \\min(r-1, c, l)\\) non-null eigenvalues.\nThen, we can find the loadings rows (sites) \\(U_0\\) (\\(r \\times \\text{mindim}\\)) from the columns (species) loadings using the following formula:\n\\[\nU_0 = P_0 V_0 \\Lambda^{-1/2}\n\\]\nHere, it is important to note that \\(U_0\\) contains the loadings of the sites computed from the species ordination, i.e. the latent ordination of the sites not taking into account the sites variables. The position of the sites taking into account the regression will be defined below in the scalings section.\nFinally, we define the following transformations of \\(U_0\\) and \\(V_0\\) (\\(V_0\\) corresponds to c1):\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U &= D_r^{-1/2} U_0\\\\\n  V &= D_c^{-1/2} V_0\\\\\n\\end{array}\n\\right.\n\\] This transformation is similar to the transformation applied to CA eigenvectors.\n\n\n\nTransform matrix\nWe start by “centering” the matrix \\(Y\\) to get \\(P_0\\) (just like with CA).\n\\[\nP = Y/y_{\\cdot \\cdot}\n\\]\n\\[\nP_0 = [p_{0ij}] = \\left[ \\frac{p_{ij} - p_{i\\cdot} p_{\\cdot j}}{\\sqrt{p_{i\\cdot} p_{\\cdot j}}} \\right]\n\\]\nHere, we have:\n\n\nCode\nP &lt;- Y/sum(Y)\n\n# Initialize P0 matrix\nP0 &lt;- matrix(ncol = ncol(Y), nrow = nrow(Y))\ncolnames(P0) &lt;- colnames(Y)\nrownames(P0) &lt;- rownames(Y)\n\nfor(i in 1:nrow(Y)) { # For each row\n  for (j in 1:ncol(Y)) { # For each column\n    # Do the sum\n    pi_ &lt;- sum(P[i, ])\n    p_j &lt;- sum(P[, j])\n    \n    # Compute the transformation\n    P0[i, j] &lt;- (P[i, j] - (pi_*p_j))/sqrt(pi_*p_j)\n  }\n}\n\n\n\n\nCode\nknitr::kable(head(P0))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n-0.0246174\n-0.0235678\n0.1819102\n0.0177849\n-0.0086058\n0.0190444\n-0.0060852\n0.0389306\n-0.0172115\n0.0177849\n0.0142185\n-0.0285421\n-0.0121704\n-0.0086058\n-0.0172115\n-0.0136069\n-0.0172115\n-0.0425963\n0.0259875\n-0.0227687\n-0.0250899\n\n\n-0.0700532\n-0.0430288\n-0.0192431\n-0.0075494\n-0.0157119\n-0.0362309\n-0.0111100\n0.0317935\n-0.0314238\n-0.0075494\n-0.0702658\n0.0257394\n0.3429284\n-0.0157119\n0.1622254\n0.2201063\n-0.0314238\n0.0004761\n-0.0290665\n-0.0415698\n0.0427538\n\n\n0.0325898\n-0.0342433\n-0.0153141\n0.0216502\n-0.0125039\n-0.0148135\n-0.0088416\n-0.0092517\n-0.0250078\n-0.0160655\n0.0166286\n-0.0414707\n-0.0176832\n-0.0125039\n-0.0250078\n-0.0197704\n-0.0250078\n0.0364300\n0.0331807\n-0.0330822\n0.0191867\n\n\n0.0149125\n-0.0283250\n-0.0126673\n-0.0444862\n-0.0103428\n0.0023441\n-0.0073135\n0.0865729\n0.0773724\n-0.0444862\n-0.0024017\n-0.0343033\n-0.0146270\n-0.0103428\n-0.0206857\n-0.0163535\n-0.0206857\n0.0280484\n-0.0407198\n-0.0273646\n0.0371130\n\n\n0.0381182\n-0.0333300\n-0.0149056\n-0.0135976\n-0.0121704\n-0.0123509\n-0.0086058\n-0.0058019\n-0.0243408\n-0.0523468\n0.0573758\n-0.0403646\n-0.0172115\n-0.0121704\n-0.0243408\n0.0861662\n-0.0243408\n0.0407749\n-0.0055815\n-0.0321998\n0.0216837\n\n\n-0.0648859\n-0.0351329\n-0.0157119\n-0.0184176\n-0.0128287\n0.0201080\n-0.0090713\n0.0163368\n0.0533995\n0.0183431\n-0.0220164\n-0.0425480\n-0.0181425\n-0.0128287\n0.0533995\n-0.0202840\n0.0533995\n0.0003888\n0.0298152\n-0.0339416\n0.1252960\n\n\n\n\n\n\n\nWeights on \\(E\\)\nWe standardize \\(E\\) as \\(E_{stand}\\), but we standardize so that the variables associated to the sites which have more observations have more weight. Therefore, we standardize \\(E\\) with the weights \\(y_{i\\cdot}/r\\).\n\nE_wt &lt;- rowSums(Y)/nrow(E)\n\nEstand &lt;- scalewt(E, wt = E_wt)\n\n\n\nCode\nknitr::kable(head(Estand))\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n-0.8940191\n-1.4578384\n-0.5429520\n-1.0404731\n1.0369741\n-1.0351817\n\n\n-0.8940191\n-1.3502706\n-0.5081483\n-0.3311255\n-0.4345644\n1.0954816\n\n\n-0.8940191\n0.8010856\n1.0902771\n0.3301082\n-1.3346326\n1.0954816\n\n\n-0.8940191\n0.7473017\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n-0.8940191\n0.6397339\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n-0.8940191\n1.1775730\n-0.6656140\n-1.0605165\n0.9946790\n-0.6293411\n\n\n\n\n\nConceptually, it is equivalent to using the inflated matrix \\(E_{infl}\\) to compute its mean \\(\\bar{E}_{infl}\\) and standard deviation \\(\\sigma(E_{infl})\\) per column. In \\(E_{infl}\\), the rows corresponding to each site are duplicates as many times as there are observations for this given site (so that \\(E_{infl}\\) is of dimension \\(y_{\\cdot \\cdot} \\times l\\)).\n\\[\nE_{stand} = \\frac{E - \\bar{E}_{infl}}{\\sigma(E_{infl})}\n\\]\nWith our data: first, we compute \\(E_{infl}\\):\n\n\nCode\nEinfl &lt;- matrix(data = 0,\n                ncol = ncol(E), \n                nrow = sum(Y))\ncolnames(Einfl) &lt;- colnames(E)\nrownames(Einfl) &lt;- 1:nrow(Einfl)\n\n# Get the number of times to duplicate each site\nnrep_sites &lt;- rowSums(Y)\n\nnrstart &lt;- 0\nfor (i in 1:nrow(E)) {\n  ri &lt;- as.matrix(E)[i, ]\n  \n  rname &lt;- rownames(E)[i]\n  \n  # Get how many times to duplicate this site\n  nr &lt;- nrep_sites[as.character(rname)]\n  \n  Einfl[(nrstart+1):(nrstart+nr), ] &lt;- matrix(rep(ri, nr), \n                                              nrow = nr, \n                                              byrow = TRUE)\n  \n  rownames(Einfl)[(nrstart+1):(nrstart+nr)] &lt;- paste(rname,\n                                                     1:nr,\n                                                     sep = \"_\")\n  nrstart &lt;- nrstart + nr\n}\n\npaste(\"Dimension of Einfl:\", paste(dim(Einfl), collapse = \" \"))\n\n\n[1] \"Dimension of Einfl: 493 6\"\n\n\nThen, we compute the mean and standard deviation per column and standardize \\(E\\).\n\n\nCode\nEinfl_mean &lt;- apply(Einfl, 2, mean)\n\nn &lt;- nrow(Einfl)\nEinfl_sd &lt;- apply(Einfl, 2, \n                  function(x) sd(x)*sqrt((n-1)/n))\n\n\n\n\nCode\nEstand2 &lt;- scale(E, \n                 center = Einfl_mean,\n                 scale = Einfl_sd)\n\nall(abs(Estand2/Estand - 1) &lt; zero)\n\n\n[1] TRUE\n\n\n\n\nRegression\nAfter that, we perform the weighted multiple linear regression of \\(P_0\\) by \\(E_{stand}\\). \\(P_0\\) is approximated by \\(\\hat{P_0}\\) using multiple linear regression on \\(E_{stand}\\): for each row, we can write \\(\\hat{p_{0i\\cdot}} = b_0 + b_1 e_{1\\cdot} + \\ldots + b_e e_{l\\cdot}\\), where \\(e_i\\) are columns of \\(E_{stand}\\) and \\(b_i\\) are regression coefficients.\nIn a matrix form, it is written:\n\\[\n\\hat{P_0} = D_r^{1/2}E_{stand}B\n\\]\nWhere\n\\[\nB = [E_{stand}^\\top D_r E_{stand}]^{-1}E_{stand}^\\top D_r^{1/2}P_0\n\\]\nWith our example:\n\n# Diagonal matrix weights\ndr &lt;- rowSums(P)\nDr &lt;- diag(dr)\ncolnames(Dr) &lt;- rownames(P)\n\n# Regression coefficient\nB &lt;- solve(t(Estand) %*% Dr %*% Estand) %*% t(Estand) %*% diag(dr^(1/2)) %*% P0\n\n# Compute predicted values\nP0hat &lt;- diag(dr^(1/2)) %*% Estand %*% B\ncolnames(P0hat) &lt;- colnames(P0)\nrownames(P0hat) &lt;- rownames(P0)\n\nNow, we can get the predicted values for \\(P_0\\). For instance, let’s plot predicted vs observed values for site 2:\n\n# Get predicted and observed values for one site\nind &lt;- 2\n\npred &lt;- P0hat[ind, ]\nobs &lt;- P0[ind, ]\n\n\n\nCode\ndf &lt;- data.frame(predicted = pred, \n                 observed = obs, \n                 names = names(pred))\ndf&lt;- df |&gt; \n  tidyr::pivot_longer(cols = c(\"predicted\", \"observed\"),\n                      names_to = \"type\")\n\nggplot(df, aes(x = reorder(names, value, decreasing = TRUE), \n               y = value, col = type, group = type)) +\n  geom_point() +\n  geom_line() +\n  theme_linedraw() +\n  ylab(\"Values of P0\") +\n  xlab(\"Species\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\nDiagonalization of \\(S_{\\hat{P_0}^\\top \\hat{P_0}}\\)\nThen, we diagonalize the covariance matrix of predicted values \\(S_{\\hat{P_0}^\\top \\hat{P_0}}\\).\nFirst, we compute the covariance matrix (note that here we don’t divide by the degrees of freedom).\n\\[\nS_{\\hat{P_0}^\\top \\hat{P_0}} = \\hat{P_0}^\\top \\hat{P_0}\n\\]\n\nSpp &lt;- t(P0hat) %*% P0hat\n\n\n\nCode\n# Covariance matrix of predicted P0 is equal to that\nSpe &lt;- t(P0hat) %*% diag(dr^(1/2)) %*% as.matrix(Estand)\nSee &lt;- t(Estand) %*% Dr %*% as.matrix(Estand)\nSpp2 &lt;- Spe %*% solve(See) %*% t(Spe)\n\nall(abs(Spp/Spp2 - 1) &lt; zero)\n\n\n[1] TRUE\n\n\nWe diagonalize \\(S_{\\hat{P_0}^\\top \\hat{P_0}}\\):\n\\[\nS_{\\hat{P_0}^\\top \\hat{P_0}} = V_0 \\Lambda V_0^{-1}\n\\]\n\\(\\Lambda\\) is the matrix of eigenvalues (there are \\(\\min(r-1, c, l)\\) non-null eigenvalues) and \\(V_0\\) contains the columns (species) loadings.\n\nneig &lt;- min(c(r-1, c, l))\n\nHere, \\(r-1 =\\) 25, \\(c =\\) 21 and \\(l =\\) 6 so the minimum (and the number of eigenvalues) is 6.\n\neig &lt;- eigen(Spp)\n\n(lambda &lt;- eig$values) # There are l = 6 non-null eigenvalues\n\n [1]  1.846574e-01  1.571586e-01  1.009501e-01  8.711508e-02  3.222443e-02\n [6]  1.476469e-02  9.276798e-18  8.416776e-18  2.476628e-18  1.422189e-18\n[11] -1.212603e-18 -1.597223e-18 -1.677170e-18 -2.007096e-18 -3.488219e-18\n[16] -3.614024e-18 -5.174948e-18 -5.675276e-18 -6.196745e-18 -6.258539e-18\n[21] -7.334976e-18\n\nlambda &lt;- lambda[1:neig]\n\nLambda &lt;- diag(lambda)\nV0 &lt;- eig$vectors[, 1:neig] # We keep only the eigenvectors\nrownames(V0) &lt;- colnames(Y)\n\nFinally, we can get the ordination of rows (sites) by using the link between rows and columns ordination:\n\\[\nU_0 = P_0 V_0 \\Lambda^{-1/2}\n\\]\n\nU0 &lt;- P0 %*% V0 %*% diag(lambda^(-1/2))\nrownames(U0) &lt;- rownames(U0)\n\ndim(U0)\n\n[1] 26  6\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe rows loadings \\(U_0\\) are different from the loadings obtained by diagonalizing \\(S_{hat{P_0} \\hat{P_0}^\\top}\\) or performing the SVD of \\(\\hat{P_0}\\), because \\(U_0\\) does not contain the loadings of \\(\\hat{P_0}\\) but the loadings of \\(P_0\\).\n\n# This is not the same as diagonalizing S_ppt\nSppt &lt;- P0hat %*% t(P0hat)\neig2 &lt;- eigen(Sppt)\n\nall(abs(eig2$vectors[,1:neig]/U0 - 1) &lt; zero) # Eigenvectors are different\n\n[1] FALSE\n\n\n\n# We perform the SVD\nsv &lt;- svd(P0hat)\n\nall(abs(abs(sv$u[, 1:neig]/U0) - 1) &lt; zero) # Eigenvectors are different for U0\n\n[1] FALSE\n\nall(abs(abs(sv$v[, 1:neig]/V0) - 1) &lt; zero) # But they are the same for V0\n\n[1] TRUE\n\n\n\n# If U was computed as below (using the matrix of predicted values), it would give the same results as the diagonalization/SVD above (but it is not the case).\n\n# Compute rows loadings differently\nUhat &lt;- P0hat %*% V0 %*% diag(lambda^(-1/2))\n\nall(abs(abs(Uhat/eig2$vectors[,1:neig]) - 1) &lt; zero) # Eigenvectors are the same\n\n[1] TRUE\n\nall(abs(abs(sv$u[, 1:l]/eig2$vectors[,1:l]) - 1) &lt; zero) # Eigenvectors are the same\n\n[1] TRUE\n\n\n\n\n\n\nCompute \\(U\\) and \\(V\\)\nWe compute \\(U\\) and \\(V\\) as:\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U &= D_r^{-1/2} U_0\\\\\n  V &= D_c^{-1/2} V_0\\\\\n\\end{array}\n\\right.\n\\]\nFirst, we define the diagonal matrices with rows and columns weights (respectively \\(D_r\\) and \\(D_c\\)).\n\n# Define weights matrices\nDr &lt;- diag(rowSums(P))\nDc &lt;- diag(colSums(P))\n\n# Also define a variable for just the sums for easier manipulation\ndr &lt;- rowSums(P)\ndc &lt;- colSums(P)\n\n\n# Sites\nU &lt;- diag(dr^(-1/2)) %*% U0\n  \n# Species\nV &lt;- diag(dc^(-1/2)) %*% V0\n\n\napply(U, 2, varfacwt, wt = dr) # variance?\n\n[1] 1.337729 1.455514 1.495549 1.736722 3.103141 2.666784\n\napply(V, 2, varfacwt, wt = dc) # variance is one\n\n[1] 1 1 1 1 1 1"
  },
  {
    "objectID": "CCA.html#scaling",
    "href": "CCA.html#scaling",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Scaling",
    "text": "Scaling\n\n\n\n\n\n\nTL;DR\n\n\n\nAs with CA, we have scalings type 1, 2 and 3. There are 2 differences with CA:\n\nFor the sites, we have 2 types of scores: the predicted sites scores (LC scores), computed from the regression, and the weighted averages (WA scores), computed from the species scores.\nThere are also scalings for the correlations of the explanatory variables with the axes.\n\nScaling type 1 (\\(\\alpha = 1\\))\n\nWA scores for rows (sites): \\(B = U \\Lambda^{-1/2}\\) (ls)\nLC scores for rows (sites): \\(Z_1 = D_r^{-1/2} \\hat{P_0} V\\) (li)\nColumns (species) scores: \\(V = D_c^{-1/2} V_0\\) (c1)\nVariables scores: \\(BS_1 = E_{stand}^\\top D_r Z_{stand} \\Lambda^{1/2}\\)\n\nScaling type 2 (\\(\\alpha = 0\\))\n\nWA scores for rows (sites): \\(U = D_r^{-1/2} U_0\\) (not computed by ade4: sort of ls1, but variance not normed to one)\nLC scores for rows (sites): \\(Z_2 = D_r^{-1/2}\\hat{P_0} V \\Lambda^{-1/2}\\) (l1)\nColumns (species) scores: \\(A = V \\Lambda^{1/2}\\) (co)\nVariables scores: \\(BS_2 = E_{stand}^\\top D_r Z_{stand}\\)\n\nScaling type 3 (\\(\\alpha = 1/2\\))\n\nWA scores for rows (sites): \\(\\hat{S}_3 = U \\Lambda^{1/4}\\)\nLC scores for rows (sites): \\(Z_3 = D_r^{-1/2}\\hat{P_0}U_0 \\Lambda^{-1/4}\\)\nColumns (species) scores: \\(S_3 = V \\Lambda^{1/4}\\)\nVariables scores: \\(BS_3 = E_{stand}' D_r Z_{stand}\\Lambda^{1/4}\\)\n\n\\(A\\) (columns/species) and \\(B\\) (rows/sites) correspond to weighted averagings, and cab be computed from \\(U\\) (rows/sites) (resp. \\(V\\) (columns/species)). See Equation 1 and Equation 2 below.\nHow to find the fa (i.e. correlation coefficients for each environmental variable in the multivariate space)??\n\n\nLet’s compute CCA with ade4 to compare results.\n\nca &lt;- dudi.coa(Y, \n               nf = c-1, \n               scannf = FALSE)\ncca &lt;- pcaiv(dudi = ca, \n             df = E,\n             scannf = FALSE,\n             nf = neig)\n\nlambda[1:neig]/cca$eig # Eigenvalues are the same as computed manually\n\n[1] 1 1 1 1 1 1\n\n\n\nPre-computations\nThe scores for the explanatory variables are computed from matrix \\(Z_{stand}\\): so we first need to standardize \\(Z\\) into \\(Z_{stand}\\) (the computation can involve \\(Z_1\\), \\(Z_2\\) or \\(Z_3\\) (defined below) and give the same result).\n\\(Z_1\\), \\(Z_2\\) or \\(Z_3\\) are defined as some variation of:\n\\[Z_i = D_r^{-1/2} \\hat{P}_0 V_0 \\Lambda^\\alpha\\] where \\(\\alpha\\) is an exponent equal to 0, -1/2 or -1/4.\n\n# Compute Z1\nZ1 &lt;- diag(dr^(-1/2)) %*% P0hat %*% V0\n\nZ_wt &lt;- E_wt\nZstand &lt;- scalewt(Z1, wt = Z_wt)\n\nIt is the same as computing with the inflated matrix (below):\n\n\nCode\n# Compute inflated matrix ------\nZinfl &lt;- matrix(data = 0,\n                ncol = ncol(Z1), \n                nrow = sum(Y))\nrownames(Zinfl) &lt;- 1:nrow(Zinfl)\n# Give names to Z1\nrownames(Z1) &lt;- rownames(Y)\n\n# Get the number of times to duplicate each site\nnrep_sites &lt;- rowSums(Y)\n\nnrstart &lt;- 0\nfor (i in 1:nrow(Z1)) {\n  ri &lt;- Z1[i, ]\n  \n  rname &lt;- rownames(Z1)[i]\n  \n  # Get how many times to duplicate this site\n  nr &lt;- nrep_sites[as.character(rname)]\n  \n  Zinfl[(nrstart+1):(nrstart+nr), ] &lt;- matrix(rep(ri, nr), \n                                              nrow = nr, \n                                              byrow = TRUE)\n  \n  rownames(Zinfl)[(nrstart+1):(nrstart+nr)] &lt;- paste(rname, \n                                                     1:nr, \n                                                     sep = \"_\")\n  nrstart &lt;- nrstart + nr\n}\n\n# Compute mean/sd ------\nZinfl_mean &lt;- apply(Zinfl, 2, mean)\n\nn &lt;- nrow(Zinfl)\nZinfl_sd &lt;- apply(Zinfl, 2, \n                  function(x) sd(x)*sqrt((n-1)/n))\n\n# Compute Zstand ------\nZstand2 &lt;- scale(Z1, \n                 center = Zinfl_mean,\n                 scale = Zinfl_sd)\n\nall(abs(Zstand2/Zstand - 1) &lt; zero)\n\n\n[1] TRUE\n\n\n\n\nScaling type 1\nHere, \\(\\chi^2\\) distances between rows (sites) are preserved they are positioned at the centroid of species.\n\nthe rows (sites) scores can be positioned by averaging: \\(B = U \\Lambda^{-1/2}\\) (ls) or by predicted positions \\(Z_1 = D_r^{-1/2} \\hat{P_0} V\\) (li)\nthe columns (species) scores are positioned at variance 1 \\(V = D_c^{-1/2} V_0\\) (c1)\nthe explanatory variable score are \\(BS_1 = E_{stand}^\\top D_r Z_{stand}\\Lambda^{1/2}\\)\n\n\n# Rows WA scores\nB &lt;- U %*% diag(lambda^(1/2))\n\n# Variables correlation\nBS1 &lt;- t(Estand) %*% Dr %*% Zstand %*% sqrt(Lambda)\n\nIf we compare to the results obtained with ade4, we can see what each score corresponds to.\n\nall(abs(abs(Z1/cca$li) - 1) &lt; zero) # Predicted sites scores\n\n[1] TRUE\n\nall(abs(abs(B/cca$ls) - 1) &lt; zero) # Averaging sites scores\n\n[1] TRUE\n\nall(abs(abs(V/cca$c1) - 1) &lt; zero) # Variance 1 species scores\n\n[1] TRUE\n\n# What does the BS1 correspond to?\nres &lt;- as.matrix(cca$cor)/(BS1 %*% diag(lambda^(-1/2)) )\nall(abs(abs(res) - 1) &lt; zero)\n\n[1] TRUE\n\n\nWe know that \\(V\\)/c1 is of variance 1 (computed above). Below we show that \\(Z_1\\)/li is of variance \\(\\lambda\\) and try to get the variance of \\(B\\)/ls.\n\n# The CCA weights can be recovered from data (modulo a constant)\ncca$lw/E_wt\n\n         1          2          3          4          5          6          7 \n0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 \n         8          9         10         11         12         13         14 \n0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 \n        15         16         17         18         19         20         21 \n0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 \n        22         23         24         25         26 \n0.05273834 0.05273834 0.05273834 0.05273834 0.05273834 \n\ncca$cw/(colSums(Y)/ncol(Y))\n\n       sp1        sp2        sp3        sp4        sp5        sp6        sp7 \n0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 \n       sp8        sp9       sp10       sp11       sp12       sp13       sp14 \n0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 \n      sp15       sp16       sp17       sp18       sp19       sp21       sp22 \n0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 0.04259635 \n\n\n\napply(Z1, 2, varwt, wt = cca$lw)/cca$eig # Z1 variance = eigenvalues\n\n[1] 1 1 1 1 1 1\n\napply(B, 2, varwt, wt = cca$lw)\n\n[1] 0.24702157 0.22874662 0.15097579 0.15129471 0.09999697 0.03937424\n\n\n\nWeighted averaging\nSimilarly to the CA case, \\(B\\) (sites coordinates) can be obtained from species coordinates, weighted by the observed data matrix:\n\\[\nB = \\left\\{\n\\begin{array}{ll}\n  D_r^{-1/2} P_0 V_0 \\qquad &\\text{(from } V_0 \\text{)}\\\\\n  D_r^{-1/2} P_0 D_c^{1/2} V \\qquad &\\text{(from } V \\text{)}\\\\\n   D_r^{-1} P V \\qquad &\\text{(from } V \\text{ and } P \\text{)}\\\\\n\\end{array}\n\\right.\n\\tag{1}\\]\n\n# With V0\nB_wa &lt;- diag(dr^(-1/2)) %*% P0 %*% V0\nres &lt;- B_wa/B\nall(res[, 1:neig] - 1 &lt; zero)\n\n[1] TRUE\n\n# With V\nB_wa_V &lt;- diag(dr^(-1/2)) %*% P0 %*% diag(dc^(1/2)) %*% V\nres &lt;- B_wa_V/B\nall(res[, 1:neig] - 1 &lt; zero)\n\n[1] TRUE\n\n# With V and P\nB_wa_legendre &lt;- diag(dr^(-1)) %*% P %*% V\nres &lt;- B_wa_legendre/B\nall(res[, 1:neig] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nPlots\nWe can plot the predicted scores for sites (LC scores):\n\n\nCode\nmult &lt;- 10\n\n# LC scores\nmultiplot(indiv_row = Z1, indiv_col = V, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS1, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\n\n\n\n\n\n\nCode\ns.label(cca$c1, # Species constrained at variance 1\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        main = \"LC scores for sites\")\ns.label(cca$li, # Predicted sites scores\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        add = TRUE)\n\n\n\n\n\nWe can also plot the weighted averaging sites scores:\n\n\nCode\n# WA scores\nmultiplot(indiv_row = B, indiv_col = V, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS1, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"WA scores for sites\")\n\n\n\n\n\n\n\nCode\ns.label(cca$c1, # Species constrained at variance 1\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        main = \"WA scores for sites\")\ns.label(cca$ls, # WA sites scores\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        add = TRUE)\n\n\n\n\n\n\n\n\nScaling type 2\nHere, \\(\\chi^2\\) distances between columns (species) are preserved they are positioned at the centroid of sites.\n\nthe rows (sites) scores can be \\(U = D_r^{-1/2} U_0\\) (variance 1) or \\(Z_2 = D_r^{-1/2} \\hat{P_0} V_0 \\Lambda^{-1/2}\\) (l1) (predicted sites scores)\nthe columns (species) scores are \\(A = V \\Lambda^{1/2}\\) (co) (WA scores from sites latent ordination)\nthe explanatory variable score are \\(BS_2 = E_{stand}^\\top D_r Z_{stand}\\)\n\n\n# Row predicted scores\nZ2 &lt;- diag(dr^(-1/2)) %*% P0hat %*% V0 %*% diag(lambda^(-1/2))\n\n# Columns WA scores\nA &lt;- V %*% Lambda^(1/2)\n\n# Variables correlation\nBS2 &lt;- t(Estand) %*% Dr %*% Zstand\n\nIf we compare to the results obtained with ade4, we can see what each score corresponds to.\n\nall(abs(abs(Z2/cca$l1) - 1) &lt; zero) # Predicted sites scores of variance 1\n\n[1] TRUE\n\n# U is not computed by ade4 so we compute it from ls (corresponding to B)\nls1_ade4 &lt;- as.matrix(cca$ls) %*% diag(lambda^(-1/2))\nall(abs(abs(ls1_ade4/U) - 1) &lt; zero)\n\n[1] TRUE\n\nall(abs(abs(A/cca$co) - 1) &lt; zero) # Averaging column scores\n\n[1] TRUE\n\nall(abs(abs(cca$cor/BS2) - 1) &lt; zero) # Variables correlations\n\n[1] TRUE\n\n\nBelow we show that \\(A\\)/co is of variance \\(\\lambda\\), \\(Z_2\\)/l1 is of variance 1 and try to get the variance of \\(U\\)/ls1.\n\napply(A, 2, varwt, wt = cca$cw)/cca$eig # A variance = eigenvalues\n\n[1] 1 1 1 1 1 1\n\napply(Z2, 2, varwt, wt = cca$lw) # Z variance = 1\n\n[1] 1 1 1 1 1 1\n\napply(ls1_ade4, 2, varwt, wt = cca$lw) # ?\n\n[1] 1.337729 1.455514 1.495549 1.736722 3.103141 2.666784\n\n\n\nWeighted averaging\n\\(A\\) (species coordinates) can be obtained from sites coordinates, weighted by the predicted data matrix. Contrary to the CA case, sites coordinates are not weighted by \\(P_0\\) (observed) but by \\(\\hat{P}_0\\) (predicted):\n\\[\nA = \\left\\{\n\\begin{array}{ll}\n  D_c^{-1/2} \\hat{P}_0^\\top U_0 \\qquad &\\text{(from } U_0 \\text{)}\\\\\n  D_c^{-1/2} \\hat{P}_0^\\top D_r^{1/2} U \\qquad &\\text{(from } U \\text{)}\n\\end{array}\n\\right.\n\\tag{2}\\]\n\n# U0\nA_wa &lt;- diag(dc^(-1/2)) %*% t(P0hat) %*% U0\nres &lt;- A_wa/A\nall(res[, 1:neig] - 1 &lt; zero)\n\n[1] TRUE\n\nA_wa_U &lt;- diag(dc^(-1/2)) %*% t(P0hat) %*% diag(dr^(1/2)) %*% U\nres &lt;- A_wa_U/A\nall(res[, 1:neig] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nPlots\nWe can plot the predicted scores for sites (LC scores):\n\n\nCode\nmult &lt;- 1\n\n# LC scores\nmultiplot(indiv_row = Z2, indiv_col = A, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS2, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"LC scores for sites (variance 1)\")\n\n\n\n\n\n\n\nCode\ns.label(cca$l1, # Predicted sites scores of variance 1\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        main = \"LC scores for sites (variance 1)\")\ns.label(cca$co, # Species WA\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        add = TRUE)\n\n\n\n\n\nCode\ns.corcircle(cca$cor)\n\n\n\n\n\nWe can also plot the sites WA scores \\(U\\):\n\n\nCode\n# WA scores\nmultiplot(indiv_row = U, indiv_col = A, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS2, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"Sites WA scores (U)\")\n\n\n\n\n\nade4 does not compute the sites WA scores corresponding to \\(U\\), so we compute them below:\n\n\nCode\ns.label(ls1_ade4, # Sites WA scores U\n        plabels.optim = TRUE,\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite,\n        main = \"Sites WA scores (U)\")\ns.label(cca$co, # Species WA\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        add = TRUE)\n\n\n\n\n\n\n\n\nScaling type 3\nThis type of scaling is a compromise between scalings type 1 and 2.\n\nthe rows (sites) scores can be \\(\\hat{S}_3 = U \\Lambda^{1/4}\\) or \\(Z_3 = D_r^{-1/2} \\hat{P_0} V_0 \\Lambda^{-1/4}\\)\nthe columns (species) scores are \\(S_3 = V \\Lambda^{1/4}\\)\nthe explanatory variable score are \\(BS_3 = E_{stand}^\\top D_r Z_{stand} \\Lambda^{1/4}\\)\n\n\n# Row scores\nShat3 &lt;- U %*% Lambda^(1/4) # Latent scores\nZ3 &lt;- diag(dr^(-1/2)) %*% P0hat %*% V0 %*% diag(lambda^(-1/4)) # Predicted scores\n\n# Columns scores\nS3 &lt;- V %*% Lambda^(1/4)\n\n# Variables correlation\nBS3 &lt;- t(Estand) %*% Dr %*% Zstand %*% Lambda^(1/4)\n\nThe corresponding ade4 values are not computed, but we can compute them:\n\nZ3_ade4 &lt;- as.matrix(cca$l1) %*% diag(cca$eig^(1/4))\nShat3_ade4 &lt;- ls1_ade4 %*% diag(cca$eig^(1/4))\nS3_ade4 &lt;- as.matrix(cca$c1) %*% diag(cca$eig^(1/4))\n\n\nall(abs(abs(Z3_ade4/Z3) - 1) &lt; zero) # LC scores for sites\n\n[1] TRUE\n\nall(abs(abs(Shat3_ade4/Shat3) - 1) &lt; zero) # sites scores\n\n[1] TRUE\n\nall(abs(abs(S3_ade4/S3) - 1) &lt; zero) # species scores\n\n[1] TRUE\n\n\n\n\nPlots\n\n\nCode\n# LC scores\nmultiplot(indiv_row = Z3, indiv_col = S3, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS3, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\n\n\n\n\n\ns.label(Z3_ade4,\n        plabels.optim = TRUE,\n        xlim = c(-3, 2),\n        ylim = c(-2, 3),\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite)\ns.label(S3_ade4,\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        add = TRUE)\n\n\n\n\n\n\nCode\nmult &lt;- 5\n\nmultiplot(indiv_row = Shat3, indiv_col = S3, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          var_row = BS3, var_row_lab = colnames(E),\n          row_color = params$colsite, col_color = params$colspp,\n          mult = mult,\n          eig = lambda) +\n  ggtitle(\"Sites latent scores\")\n\n\n\n\n\n\ns.label(Shat3_ade4,\n        plabels.optim = TRUE,\n        xlim = c(-3, 2),\n        ylim = c(-2, 3),\n        plabels.col  = params$colsite,\n        ppoints.col = params$colsite)\ns.label(S3_ade4,\n        plabels.optim = TRUE,\n        plabels.col  = params$colspp,\n        ppoints.col = params$colspp,\n        add = TRUE)"
  },
  {
    "objectID": "CCA.html#interpretation",
    "href": "CCA.html#interpretation",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Interpretation",
    "text": "Interpretation\nIn CCA, each ordination axis corresponds to a linear combination of the explanatory variables that maximizes the explained variance in the response data.\nThis analysis constrains rows (sites) scores to be linear combinations of the environmental variables (scaling \\(Z_i\\)).\nSpecies can be ordered along environmental variables axes by projecting species coordinates on the vector of this variable. This gives species niche optimum, but there are strong assumptions:\n\nunimodal distribution of niches preferences along the variable of interest\nspecies distributions are indeed controlled by the environment\nthe study gradient is long enough to capture the range of species abundance variation.\n\nThe part of variation explained by the environmental variables can be computed as\n\\[\n\\frac{\\sum_k \\lambda_k(CCA)}{\\sum_l \\lambda_l(CA)}\n\\]\n\nsum(lambda)/sum(ca$eig)\n\n[1] 0.3795835\n\n\nHere, the environmental variables explain 38 % of the total variation.\nWarning: in CCA, using noisy or not relevant explanatory variables leads to spurious relationships.\n\nResidual analysis\nIn order to examinate residuals, a CA can be performed on the table of residuals \\(P_0_{res}\\):\n\\[\nP_{0res} = P_0 - \\hat{P}_0\n\\]\n\nPres &lt;- P0 - P0hat\n\nres_pca &lt;- dudi.pca(Pres, scannf = FALSE, nf = 27)\n\nscatter(res_pca)\n\n\n\n\n\n\nTests of significance\nIt is possible to test the significance of the the relationship between \\(E\\) and \\(Y\\) with a permutation test.\n\nrandtest(cca, nrepet = 999)\n\nMonte-Carlo test\nCall: randtest.pcaiv(xtest = cca, nrepet = 999)\n\nObservation: 0.3795835 \n\nBased on 999 replicates\nSimulated p-value: 0.001 \nAlternative hypothesis: greater \n\n     Std.Obs  Expectation     Variance \n3.6710027797 0.2672397317 0.0009365447"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "This website aims at summarizing the theory behind different methods to analyze count data:\nIt also describes reciprocal scaling (Thioulouse and Chessel 1992) (and its extensions with CCA and dc-CA). Reciprocal scaling is a method to compute and visualize the dispersion among count tables analyzed with multivariate methods."
  },
  {
    "objectID": "index.html#dataset",
    "href": "index.html#dataset",
    "title": "Introduction",
    "section": "Dataset",
    "text": "Dataset\nThroughout this document, we will use the data from Barbaro et al. (2012) on bird species distribution in New Zealand extracted from the CESTES database (Jeliazkov et al. 2020).\nThroughout this document, we will analyze a matrix \\(Y\\) (\\(r \\times c\\)) and two associated matrices \\(E\\) (\\(r \\times e\\)) and \\(T\\) (\\(t \\times c\\)). In our example:\n\n\\(Y\\) (\\(r =\\) 26 \\(\\times\\) \\(c =\\) 21) represents bird species counts in different sites\n\\(E\\) (\\(r =\\) 26 \\(\\times\\) \\(l =\\) 6) represents environmental variables in different sites\n\\(T\\) (\\(c =\\) 21 \\(\\times\\) \\(k =\\) 7) represents bird species traits"
  },
  {
    "objectID": "CA.html",
    "href": "CA.html",
    "title": "Correspondence analysis (CA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(gridExtra)\nsource(here(\"functions/plot.R\"))\nCode\n# Define bound for comparison to zero\nzero &lt;- 10e-10\nThe contents of this page relies heavily on Legendre and Legendre (2012)."
  },
  {
    "objectID": "CA.html#introduction",
    "href": "CA.html#introduction",
    "title": "Correspondence analysis (CA)",
    "section": "Introduction",
    "text": "Introduction\nCorrespondence analysis (CA) was developed independently by several authors between the 1930s and 1960s. It has been mainly applied to analysis of ecological data tables (species \\(\\times\\) environment) such as the data we will analyze here.\nNotably, Hill discovered it in 1973 with an iterative method that he called reciprocal averaging. It involves ordering species with sites initially positioned randomly, reciprocally order sites with species, etc. This iterative procedure converges to reach the same results as what is achieved with CA’s first axis.\nCA is designed to analyze contingency tables (count tables) such \\(Y\\):\n\n\n\n\n\nHere, \\(Y\\) represents the abundance of different bird species (columns) at different sites (rows) in New Zealand.\nHere is a preview of \\(Y\\) with our example dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n4\n0\n0\n0\n0\n2\n0\n4\n0\n2\n0\n4\n0\n0\n0\n0\n1\n5\n0\n0\n2\n\n\n2\n0\n0\n1\n0\n2\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n5\n1\n5\n1\n\n\n4\n0\n0\n0\n0\n0\n0\n2\n0\n0\n3\n0\n0\n0\n0\n0\n1\n1\n0\n0\n1\n\n\n2\n0\n1\n5\n0\n0\n0\n5\n0\n1\n1\n4\n0\n0\n0\n1\n2\n2\n0\n0\n2\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n2\n0\n0\n0\n4\n0\n1\n10\n3\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n4\n0\n2\n2\n4\n0\n0\n0\n0\n2\n1\n2\n0\n1\n\n\n5\n5\n0\n0\n1\n1\n0\n1\n0\n3\n0\n5\n0\n0\n0\n0\n0\n0\n1\n5\n1\n\n\n4\n0\n0\n1\n0\n2\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n3\n0\n0\n0\n1\n0\n0\n0\n0\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n5\n0\n4\n0\n1\n2\n0\n0\n0\n0\n0\n0\n1\n2\n0\n0\n\n\n4\n0\n1\n1\n0\n1\n0\n3\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n1\n0\n3\n2\n1\n2\n0\n0\n0\n0\n0\n0\n1\n3\n0\n0\n\n\n4\n2\n0\n1\n0\n0\n0\n2\n0\n2\n2\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n4\n0\n0\n1\n0\n2\n0\n2\n2\n2\n1\n1\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n4\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n5\n1\n0\n3\n0\n2\n0\n2\n1\n0\n2\n0\n0\n0\n0\n0\n0\n3\n1\n0\n0\n\n\n3\n5\n0\n4\n0\n2\n0\n5\n0\n4\n2\n0\n0\n1\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n2\n0\n7\n0\n1\n1\n0\n0\n4\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n6\n0\n0\n2\n0\n1\n0\n0\n0\n1\n3\n0\n0\n0\n0\n0\n0\n0\n3\n3\n0\n\n\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n\nMore generally, CA can be used to analyze tables which are dimensionally homogeneous and contain no negative values.\nCA preserves \\(\\chi^2\\) distances \\(D\\) between rows and columns of the contingency table:\n\\[\nD(x_1, x_2) = \\sqrt{\\sum_{j = 1}^p \\frac{1}{y_{\\cdot j}/y_{\\cdot \\cdot}}\\left(\\frac{y_{1j}}{y_{1\\cdot}} -  \\frac{y_{2j}}{y_{2\\cdot}}\\right)^2}\n\\]\nWhere \\(x_1\\) and \\(x_2\\) represent two items of the rows/columns. \\(p\\) is the number of rows (if \\(x_1\\) and \\(x_2\\) are items of columns) or columns else.\n\\(y_{\\cdot j}\\) represent either:\n\nif \\(x_1\\) and \\(x_2\\) are items of the columns: the sum of the \\(j\\)-th row. For a species x environment table, it is the total number of individuals in the \\(j\\)-th site.\nif \\(x_1\\) and \\(x_2\\) are items of the rows: the sum of the \\(j\\)-th column. For a species x environment table, it is the total number of individuals of the \\(j\\)-th species.\n\n\\(y_{\\cdot \\cdot}\\) is the sum of all individuals of the table.\n\\(\\frac{y_{1j}}{y_{1\\cdot}}\\) are relative frequencies of individuals per rows (if \\(x_1\\) and \\(x_2\\) are items of the rows) or columns.\nFor example, we compute the \\(\\chi^2\\) distance between sp1 and sp2:\n\n# Get total number of individuals in all sites\nytot &lt;- sum(Y)\n\n# Get how much each site contributed to the total count of species\ny_j &lt;- apply(Y, 2, FUN = function(x) x/sum(x))\n\nsqrt( sum(1/(rowSums(Y)/ytot)*(y_j[, \"sp1\"] - y_j[, \"sp2\"])^2 ) )\n\n[1] 2.090546\n\n\nAnd between sites 1 and 2:\n\n# Get the relative composition of species for each site\nyi_ &lt;- t(apply(Y, 1, FUN = function(x) x/sum(x)))\n\nsqrt( sum(1/(colSums(Y)/ytot)*(yi_[\"1\",] - yi_[\"2\", ])^2 ) )\n\n[1] 2.563363"
  },
  {
    "objectID": "CA.html#computation",
    "href": "CA.html#computation",
    "title": "Correspondence analysis (CA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nGiven a data matrix \\(Y\\), we “center-scale” this matrix (\\(P_0\\)).\nWe can perform the SVD of \\(P_0\\):\n\\[\nP_0 = U_0 \\Delta V_0^\\top\n\\]\n\\(V_0\\) (\\(c \\times c\\)) contains the loadings of the columns (species) of the contingency table.\n\\(U_0\\) (\\(r \\times c\\)) contains the loadings of the rows (sites) of the contingency table.\nThere are \\(k = \\min(c-1, r-1)\\) non-null eigenvalues. The CA eigenvalues are the squares of the SVD eigenvalues: \\(\\Lambda = \\Delta^2\\).\nAlso, there is a link between \\(U_0\\) and \\(V_0\\) given by the following transition formulae:\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U_0 &= P_0 V_0 \\Lambda^{-1/2}\\\\\n  V_0 &= P_0^\\top U_0 \\Lambda^{-1/2}\\\\\n\\end{array}\n\\right.\n\\]\nFinally, we define the following transformations of \\(U_0\\) and \\(V_0\\) (that have variance 1 and correspond to l1 and c1):\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U &= D_r^{-1/2} U_0\\\\\n  V &= D_c^{-1/2} V_0\\\\\n\\end{array}\n\\right.\n\\]\n\n\nLet’s perform a CA with ade4 to check results later.\n\nca &lt;- dudi.coa(Y, \n               scannf = FALSE, \n               nf = min(r, c))\n\n\nTransform the table\nWe transform values of the contingency table \\(Y\\) with counts \\(y_{ij}\\) into proportions \\(p_{ij}\\):\n\\[\nP = Y/y_{\\cdot \\cdot}\n\\]\nWith our example data:\n\nP &lt;- Y/sum(Y)\n\nThen we transform values of this table into a quantity related to \\(\\chi^2\\) values \\(P_0\\):\n\\[\nP_0 = [p_{0ij}] = \\left[ \\frac{p_{ij} - p_{i\\cdot} p_{\\cdot j}}{\\sqrt{p_{i\\cdot} p_{\\cdot j}}} \\right]\n\\]\n\n# Initialize P0 matrix\nP0 &lt;- matrix(ncol = ncol(Y), nrow = nrow(Y))\ncolnames(P0) &lt;- colnames(Y)\nrownames(P0) &lt;- rownames(Y)\n\nfor(i in 1:nrow(Y)) { # For each row\n  for (j in 1:ncol(Y)) { # For each column\n    # Do the sum\n    pi_ &lt;- sum(P[i, ])\n    p_j &lt;- sum(P[, j])\n    \n    # Compute the transformation\n    P0[i, j] &lt;- (P[i, j] - (pi_*p_j))/sqrt(pi_*p_j)\n  }\n}\n\nWe could also do this by matrix multiplication:\n\\[\nP_0 = D_r^{-1/2} (P - p_{i\\cdot} p_{\\cdot j}^\\top) D_c^{-1/2}\n\\]\nwhere \\(p_{i\\cdot}\\) and \\(p_{\\cdot j}\\) are the rows and columns sums vectors (respectively) and \\(D_r\\) and \\(D_c\\) are the associated diagonal matrices (respectively).\n\n# Define weights matrices\nDr &lt;- diag(rowSums(P))\nDc &lt;- diag(colSums(P))\n\n# Also define a variable for just the sums for easier manipulation\ndr &lt;- rowSums(P)\ndc &lt;- colSums(P)\n\n# Compute P0 with this computation\nP0_mat &lt;- diag(dr^(-1/2)) %*% (P - (dr %*% t(dc))) %*% diag(dc^(-1/2)) \n\nall((P0_mat/P0 - 1) &lt; zero) # It works\n\n[1] TRUE\n\n\nThe \\(p_{0ij}\\) values are equal to the \\(\\chi\\) values, a constant apart: \\(p_{0ij} = \\chi_{ij}/\\sqrt{y_{\\cdot \\cdot}}\\).\n\n\nSingular value decomposition of \\(P_0\\)\nWe perform the SVD of \\(P_0\\):\n\\[\nP_0 = U \\Delta V_0^\\top\n\\]\nWhere \\(P_0\\) is \\(r \\times c\\), \\(U_0\\) is \\(r \\times c\\), \\(\\Delta\\) is a \\(c \\times c\\) diagonal matrix (assuming \\(r \\geq c\\); the table can be transposed to meet this condition) and \\(V_0\\) is \\(c \\times c\\).\nNote that the last eigenvalue of this SVD will always be null (due to the centering).\n\nsv &lt;- svd(P0)\n\n# Eigenvalues\ndelta &lt;- sv$d # Last eigenvalue is zero\nlambda &lt;- delta^2\nLambda &lt;- diag(lambda)\n\n# Define the number of non-null eigenvalues\nk &lt;- min(c-1, r-1)\n\n# Eigenvectors\nU0 &lt;- sv$u\nV0 &lt;- sv$v\n\n\nSVD as a diagonalization\nThis SVD is equivalent to a diagonalization: with the SVD, we can rewrite \\(P_0^\\top P_0\\):\n\\[\nP_0^\\top P_0 = V_0 \\Delta^\\top U_0^\\top U_0 \\Delta V_0^\\top\n\\]\nWe have \\(U_0^\\top U_0 = I\\) (because \\(U_0\\) is orthonormal), so:\n\\[\nP_0^\\top P_0 =  V_0 \\Delta^\\top \\Delta V_0^\\top\n\\]\nIf we rewrite \\(\\Delta^\\top \\Delta\\) as \\(\\Lambda\\) (so \\(\\Delta = \\Lambda^{1/2}\\)), and since \\(V_0^\\top = V_0^{-1}\\) (\\(V_0\\) is orthonormal), then we can write this as a diagonalization:\n\\[\nP_0^\\top P_0 =  V_0 \\Lambda V_0^{-1}\n\\]\n\n# Diagonalize P0^t P0 ---\ndg1 &lt;- eigen(t(P0) %*% P0)\n\n# Eigenvalues are equal to the square roots of SVD eigenvalues\nall((dg1$values - lambda) &lt; zero)\n\n[1] TRUE\n\n# Eigenvectors are equal to V0\nall(abs(dg1$vectors/V0) - 1 &lt; zero)\n\n[1] TRUE\n\n\nSimilarly, we can rewrite \\(P_0 P_0^\\top\\):\n\\[\nP_0 P_0^\\top =  U_0 \\Lambda U_0^{-1}\n\\]\n\n# Diagonalize P0 P0^t ---\ndg2 &lt;- eigen(P0 %*% t(P0))\n\n# Eigenvalues are equal to the square roots of SVD eigenvalues\nall((dg1$values - lambda) &lt; zero)\n\n[1] TRUE\n\n# Eigenvectors corresponding to non-null eigenvalues are equal to U0\nall(abs(dg2$vectors[, 1:k]/U0[, 1:k]) - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\nComparison with Carroll, Green, and Schaffer (1986)\nIn Carroll, Green, and Schaffer (1986), CA is defined as the SVD of matrix \\(H\\) defined as:\n\\[\nH = D(y_{i\\cdot})^{-1/2} Y D(y_{\\cdot j})^{-1/2}\n\\]\nWhere \\(D(y_{i \\cdot})\\) and \\(D(y_{\\cdot j})\\) are the equivalent of \\(D_r\\) and \\(D_c\\) for matrix \\(Y\\).\nWe compute this matrix and compare the results with the SVD of \\(P_0\\).\n\n# Define weights matrices\nDyi_ &lt;- diag(rowSums(Y))\nDy_j &lt;- diag(colSums(Y))\n\n# Also define a variable for just the sums for easier manipulation\ndyi_ &lt;- rowSums(Y)\ndy_j &lt;- colSums(Y)\n\n\n# Compute H with the formula from Caroll\nH &lt;- diag(dyi_^(-1/2)) %*% Y %*% diag(dy_j^(-1/2))\n\nres &lt;- H/P0 \nall((res - 1) &lt; zero) # It is not equal to P0\n\n[1] FALSE\n\n# We try to center it:\nH_centered &lt;- diag(dyi_^(-1/2)) %*% (Y - (dyi_ %*% t(dy_j))) %*% diag(dy_j^(-1/2))\n\nres &lt;- H_centered/P0\nall((res - 1) &lt; zero) # Not equal\n\n[1] FALSE\n\n\nWe compare the SVDs of \\(H\\) and \\(P_0\\): they give the same value.\n\n# SVD of H\nsvH &lt;- svd(H)\n\n# Eigenvalues are the same, except for the first eigenvalue equal to one\nres &lt;- svH$d[2:(k+1)]/delta[1:k]\nall((res - 1) &lt; zero)\n\n[1] TRUE\n\n# Eigenvectors are the same (but for the first one)\nres &lt;- svH$u[, 2:(k+1)]/U0[, 1:k]\nall((res - 1) &lt; zero)\n\n[1] TRUE\n\nres &lt;- svH$v[, 2:(k+1)]/V0[, 1:k]\nall((res - 1) &lt; zero)\n\n[1] TRUE\n\n\nNB: \\(P_0\\) is not equal to \\(H\\) defined in Carroll, Green, and Schaffer (1987). But they do not center the matrix, so the first eigenvalue is one and the rest are the same.\n\n\n\nRelationship between \\(U_0\\) and \\(V_0\\)\nWe have the following transition formulae between \\(U_0\\) and \\(V_0\\):\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U_0 &= P_0 V_0 \\Lambda^{-1/2}\\\\\n  V_0 &= P_0^\\top U_0 \\Lambda^{-1/2}\\\\\n\\end{array}\n\\right.\n\\]\n\n# Sites weighted averaging\nU0_wa &lt;- P0 %*% V0 %*% diag(lambda^(-1/2))\nres &lt;- U0_wa/U0\nall((abs(res[, 1:k]) - 1) &lt; zero)\n\n[1] TRUE\n\n# Species weighted averaging\nV0_wa &lt;- t(P0) %*% U0 %*% diag(lambda^(-1/2))\nres &lt;- V0_wa/V0\nall((abs(res[, 1:k]) - 1) &lt; zero)\n\n[1] TRUE\n\n\n\n\nDefine \\(U\\) and \\(V\\)\nWe define weighted versions of \\(U_0\\) and \\(V_0\\):\n\\[\n\\left\\{\n\\begin{array}{ll}\n  U &= D_r^{-1/2} U_0\\\\\n  V &= D_c^{-1/2} V_0\\\\\n\\end{array}\n\\right.\n\\tag{1}\\]\n\n# Sites\nU &lt;- diag(dr^(-1/2)) %*% U0\n  \n# Species\nV &lt;- diag(dc^(-1/2)) %*% V0\n\nThese vectors have the property to be of variance 1 (when weighted by \\(D_r\\) and \\(D_c\\)): it is easier to interpret than vectors of norm 1 like \\(U_0\\) and \\(V_0\\).\n\n# Variance of columns vectors for columns\nvarV &lt;- apply(V, 2, varwt, wt = dc)\nres &lt;- varV[1:k]/1\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n# Variance of columns vectors for rows\nvarU &lt;- apply(U, 2, varwt, wt = dr)\nres &lt;- varU[1:k]/1\nall(res - 1 &lt; zero)\n\n[1] TRUE\n\n\nWe check that these are equal to the l1 and c1 of CA:\n\nres &lt;- U/ca$l1\nall((abs(res) - 1) &lt; zero)\n\n[1] TRUE\n\nres &lt;- V/ca$c1\nall((abs(res) - 1) &lt; zero)\n\n[1] TRUE"
  },
  {
    "objectID": "CA.html#scalings",
    "href": "CA.html#scalings",
    "title": "Correspondence analysis (CA)",
    "section": "Scalings",
    "text": "Scalings\n\n\n\n\n\n\nTL;DR\n\n\n\nTo plot rows and columns on separate plots, one can plot the eigenvectors \\(U_0\\) (rows = sites) and \\(V_0\\) (columns = species). But in data analyses, the weighted vectors \\(U\\) and \\(V\\) are more commonly used Equation 1.\nTo plot columns and rows individuals on the same biplot, different scalings have been proposed. For sites (rows), these scalings are equal to \\(S_\\alpha = U \\Lambda^{\\alpha/2}\\) and for species (columns), \\(S_\\alpha = V \\Lambda^{(1-\\alpha)/2}\\). (with \\(\\alpha =\\) 1, 0 or 1/2).\n\nScaling type 1 (\\(\\alpha = 1\\)): this scaling preserves the distances between rows. Rows (sites) are represented with \\(B = U \\Lambda^{1/2}\\) and species (columns) with \\(V\\).\nScaling type 2 (\\(\\alpha = 0\\)): this scaling preserves distances between columns. Rows (sites) are represented with \\(U\\) and species (columns) with \\(A = V \\Lambda^{1/2}\\).\nScaling type 3 (\\(\\alpha = 1/2\\)): this scaling is a compromise between scalings type 1 and 2. Rows (sites) are represented with \\(\\hat{S}_3 = U \\Lambda^{1/4}\\) and species (columns) with \\(S_3 = V \\Lambda^{1/4}\\).\n\nAs noted in Carroll, Green, and Schaffer (1987), if we plot distances of different scalings on the same biplot, we cannot interpret between-sets distances, but within-sets distances are still be interpretable. But this type of interpretation is often attempted with scaling type 4 (described below), and this scaling is what Carroll, Green, and Schaffer (1987) criticize.\n\n\n\nNo scaling\nOne can represent the eigenvectors \\(U_0\\) and \\(V_0\\) (or \\(U\\) and \\(V\\)) on separate plots.\n\\(U_0\\) and \\(V_0\\):\n\n\nCode\n# Plot sites ---\ng1 &lt;- multiplot(indiv_row = U0, \n          indiv_row_lab = rownames(Y), \n          row_color = params$colsite,\n          eig = lambda)\n\n# Plot species ---\ng2 &lt;- multiplot(indiv_row = V0, \n          indiv_row_lab = colnames(Y), \n          row_color = params$colspp,\n          eig = lambda)\n\ngrid.arrange(grobs = list(g1, g2), nrow = 1)\n\n\n\n\n\n\\(U\\) and \\(V\\):\n\n\nCode\n# Plot sites ---\ng1 &lt;- multiplot(indiv_row = U, \n          indiv_row_lab = rownames(Y), \n          row_color = params$colsite,\n          eig = lambda)\n\n# Plot species ---\ng2 &lt;- multiplot(indiv_row = V, \n          indiv_row_lab = colnames(Y), \n          row_color = params$colspp,\n          eig = lambda)\n\ngrid.arrange(grobs = list(g1, g2), nrow = 1)\n\n\n\n\n\n\n\nScaling type 1\nThis scaling preserves the row \\(\\chi^2\\) distances and is useful to interpret distances between row individuals (sites). In this scaling, the rows individuals (sites) are positioned at the barycentre of the corresponding column (species) individuals.\nFor that, we use:\n\n\\(B = U \\Lambda^{1/2}\\) (rows = sites): corresponds to the li\n\\(V = D_c^{-1/2} V_0\\) (columns = species): corresponds to the c1\n\n\n# Sites\nB &lt;- U %*% Lambda^(1/2)\n\nWe check that \\(B\\) corresponds to the li of CA:\n\nres &lt;- B/ca$li\nall((abs(res) - 1) &lt; zero)\n\n[1] TRUE\n\n\nThese scalings correspond to fixed variances for rows and columns. With scaling type 1, variance of the columns is fixed at one (corresponds to c1) and variance of the rows correspond to the eigenvalues (corresponds to li).\n\n# Variance of columns vectors for rows\nvarB &lt;- apply(B, 2, varwt, wt = ca$lw)\nres &lt;- varB[1:k]/ca$eig\nall(res -1 &lt; zero)\n\n[1] TRUE\n\n\n\nPlots\nPlot with our coordinates:\n\n\nCode\nmultiplot(indiv_row = B, # variance lambda (averaging)\n          indiv_col = V, # variance 1\n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\nPlot with ade4:\n\n\nCode\ns.label(ca$c1,\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp,\n        plabels.optim = TRUE) # variance 1\ns.label(ca$li, \n        ppoints.col = params$colsite,\n        plabels.col = params$colsite,\n        plabels.optim = TRUE,\n        add = TRUE) # variance lambda (averaging)\n\n\n\n\n\nOther plotting method with ade4:\n\n\nCode\n# Check the agreement between li/c1 and scaling type\n# From the doc: when method = 2, rows variance 1 and columns by averaging\nscatter(ca, method = 2,\n        plabels.optim = TRUE,\n        posieig = 'none')\n\n\n\n\n\n\n\nWeighted averaging\n\\(B\\) (sites scores) can also be computed from the species scores using weighted averaging, since there is a correspondence between \\(V_0\\) and \\(U_0\\). This shows better the relationship between sites and species scores (sites are at the barycentre of their species with this scaling).\n\\(B\\) can be expressed by weighted averaging using the following formulas:\n\\[\nB = \\left\\{\n\\begin{array}{ll}\n  D_r^{-1/2} P_0 V_0 \\qquad &\\text{(from } V_0 \\text{)}\\\\\n  D_r^{-1/2} P_0 D_c^{1/2} V \\qquad &\\text{(from } V \\text{)}\\\\\n   D_r^{-1} P V \\qquad &\\text{(from } V \\text{ and } P \\text{)}\\\\\n\\end{array}\n\\right.\n\\tag{2}\\]\n\n# Compute sites coordinates using weighted averaging\n\n# With V0\nB_wa &lt;- diag(dr^(-1/2)) %*% P0 %*% V0\nres &lt;- B_wa/B\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# With V\nB_wa_V &lt;- diag(dr^(-1/2)) %*% P0 %*% diag(dc^(1/2)) %*% V\nres &lt;- B_wa_V/B\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n# With V and P\nB_wa_legendre &lt;- diag(dr^(-1)) %*% P %*% V\nres &lt;- B_wa_legendre/B\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\n\nScaling type 2\nThis preserves \\(\\chi^2\\) distances between species on the plot. Here, species are positioned at the centroid of sites.\nWe use:\n\n\\(U = D_r^{-1/2} U_0\\) (rows = sites)\n\\(A = V \\Lambda^{1/2}\\) (columns = species)\n\n\n# Species\nA &lt;- V %*% diag(lambda^(1/2))\n\nWe check that \\(A\\) corresponds to the co of CA:\n\nres &lt;- A/ca$co\nall((abs(res) - 1) &lt; zero)\n\n[1] TRUE\n\n\nThese scalings correspond to fixed variances for rows and columns. With scaling type 2, variance of the rows is fixed at one (corresponds to l1) and variance of the columns correspond to the eigenvalues (corresponds to co).\n\n# Variance of columns vectors for rows\nvarA &lt;- apply(A, 2, varwt, wt = ca$cw)\nres &lt;- varA[1:k]/ca$eig\nall(res -1 &lt; zero)\n\n[1] TRUE\n\n\n\nPlots\nPlot with our coordinates:\n\n\nCode\nmultiplot(indiv_row = U, # variance 1 \n          indiv_col = A, # variance lambda (weighted averaging)\n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\nPlot with ade4:\n\n\nCode\ns.label(ca$l1, # variance 1 (rows/sites)\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite,\n        plabels.optim = TRUE)\ns.label(ca$co, #  variance lambda (weighted averaging) (cols/spp)\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp,\n        plabels.optim = TRUE,\n        add = TRUE)\n\n\n\n\n\nOther plotting method with ade4:\n\n\nCode\n# ade4 doc: method = 3 -&gt; 3 columns variance 1 and rows by averaging \n# Error? here we have columns by WA and rows variance 1\n\nscatter(ca, method = 3, \n        plabels.optim = TRUE,\n        posieig = 'none')\n\n\n\n\n\n\n\nWeighted averaging\nLike \\(B\\), \\(A\\) (species scores) can also be computed from the sites scores. This shows better the relationship between species and sites scores (species are at the barycentre of their sites with this scaling).\n\\[\nA = \\left\\{\n\\begin{array}{ll}\n  D_c^{-1/2} P_0^\\top U_0 \\qquad &\\text{(from } U_0 \\text{)}\\\\\n  D_c^{-1/2} P_0^\\top D_r^{1/2} U \\qquad &\\text{(from } U \\text{)}\\\\\n   D_c^{-1} P U^\\top \\qquad &\\text{(from } U \\text{ and } P \\text{)}\\\\\n\\end{array}\n\\right.\n\\tag{3}\\]\n\n# U0\nA_wa &lt;- diag(dc^(-1/2)) %*% t(P0) %*% U0\nres &lt;- A_wa/A\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n# U\nA_wa_U &lt;- diag(dc^(-1/2)) %*% t(P0) %*% diag(dr^(1/2)) %*% U\nres &lt;- A_wa_U/A\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n# U and P\nA_wa &lt;- diag(dc^(-1)) %*% t(P) %*% U\nres &lt;- A_wa/A\nall(res[, 1:k] - 1 &lt; zero)\n\n[1] TRUE\n\n\n\n\n\nScaling type 3\nIt is a compromise between scalings 1 and 2. It preserves none of the \\(\\chi^2\\) distances.\nWe use:\n\n\\(S_r = U \\Lambda^{1/4}\\) (for sites)\n\\(S_c = V \\Lambda^{1/4}\\) (for species).\n\n\nSr &lt;- U %*% Lambda^(1/4)\nSc &lt;- V %*% Lambda^(1/4)\n\n\nPlots\nPlot with our values:\n\n\nCode\nmultiplot(indiv_row = Sr, indiv_col = Sc, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\nPlot with ade4 values:\n\n\nCode\nSr_ade4 &lt;- as.matrix(ca$l1) %*% diag(ca$eig^(1/4))\nSc_ade4 &lt;- as.matrix(ca$c1) %*% diag(ca$eig^(1/4))\n\ns.label(Sr_ade4, \n        ylim = c(-5, 5),\n        xlim = c(-5, 5),\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite,\n        plabels.optim = TRUE)\ns.label(Sc_ade4,\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp,\n        plabels.optim = TRUE,\n        add = TRUE)\n\n\n\n\n\n\n\n\nScaling type 4\nUse \\(B\\) (sites) and \\(A\\) (species). Then, both \\(\\chi^2\\) distances are preserved. It is useful for a table crossing two factors.\nPlot with our values:\n\n\nCode\nmultiplot(indiv_row = B, \n          indiv_col = A, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\nPlot with ade4 values:\n\n\nCode\ns.label(ca$li, \n        ylim = c(-2, 3),\n        xlim = c(-3, 2),\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite,\n        plabels.optim = TRUE)\ns.label(ca$co,\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp,\n        plabels.optim = TRUE,\n        add = TRUE)\n\n\n\n\n\nOther ade4 method:\n\n\nCode\n# 1 rows and columns with the coordinates of lambda variance\nscatter(ca, method = 1,\n        plabels.optim = TRUE,\n        posieig = 'none')"
  },
  {
    "objectID": "CA.html#interpretation",
    "href": "CA.html#interpretation",
    "title": "Correspondence analysis (CA)",
    "section": "Interpretation",
    "text": "Interpretation\nUsing the “transition formula” defined in Equation 2 and Equation 3, we can relate the ordination of rows (sites) (\\(U\\)) to the ordination of columns (species) (\\(V\\)) by expressing it as a weighted average of the other dimensions’ individuals.\nFor instance, the sites coordinates \\(B\\) (weighted average) represent the mean of the coordinates of species present in this site. The species coordinates \\(A\\) (weighted average) represent the mean of the coordinates of sites that this species is present in.\nThe eigenvalue \\(\\lambda_h\\) is a measure of the correlation of the rows and columns ordinations along axis \\(h\\).\nIf species have a unimodal (bell-shaped) response along the gradient defined by the sites ordination along a given axis, then their position should be close to their niche optimum.\nDepending on he position of, say, species, in the multivariate space, there are several interpretations:\n\nspecies that are absent from most sites: often at the edge, close to a site where they happen to be present. They have little influence on the analysis.\nspecies that are in the center: either have their optimum there, they have a multimodal niche or their niche is not influenced by the latent variables of the ordination axes.\nspecies found away from the center but not at the edges: more likely to display clear relationships with the axis\n\n\n\n\n\n\n\nNote\n\n\n\nRare species are generally not very interesting because they are exceptions, not a general tendency. So some authors propose strategies to remove them, notably an iterative procedure. First do the complete CA, then remove the species seen one, twice… etc. Note the total inertia and the eigenvalues. When there is a jump, stop.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen there is a succession of species, along an hypothetical gradient, the CA may lead to an arch shape. There are techniques to detrend it, but knowing how to interpret this effect is probably more important."
  },
  {
    "objectID": "dcCA.html",
    "href": "dcCA.html",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# dc-CA\nsource(here(\"functions/dpcaiv2-ade4.R\"))\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(gridExtra)\nsource(here(\"functions/plot.R\"))\nThe contents of this page relies heavily on (Braak, Šmilauer, and Dray 2018)."
  },
  {
    "objectID": "dcCA.html#introduction",
    "href": "dcCA.html#introduction",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Introduction",
    "text": "Introduction\ndc-CA was developed as a natural extension of CCA and has been used to study the relationship between species traits and environmental variables.\nIn dc-CA, we have 3 matrices:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables \\(E\\) (\\(r \\times l\\))\nA matrix of predictor variables \\(T\\) (\\(c \\times k\\))\n\n\n\n\n\n\nThe aim of dc-CA is to find a linear combination of the predictor variables in \\(E\\) and \\(T\\) (environmental variables and traits) that maximizes the correlation.\nBelow are these matrices for our data:\n\\(Y =\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n4\n0\n0\n0\n0\n2\n0\n4\n0\n2\n0\n4\n0\n0\n0\n0\n1\n5\n0\n0\n2\n\n\n2\n0\n0\n1\n0\n2\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n5\n1\n5\n1\n\n\n4\n0\n0\n0\n0\n0\n0\n2\n0\n0\n3\n0\n0\n0\n0\n0\n1\n1\n0\n0\n1\n\n\n2\n0\n1\n5\n0\n0\n0\n5\n0\n1\n1\n4\n0\n0\n0\n1\n2\n2\n0\n0\n2\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n2\n0\n0\n0\n4\n0\n1\n10\n3\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n4\n0\n2\n2\n4\n0\n0\n0\n0\n2\n1\n2\n0\n1\n\n\n5\n5\n0\n0\n1\n1\n0\n1\n0\n3\n0\n5\n0\n0\n0\n0\n0\n0\n1\n5\n1\n\n\n4\n0\n0\n1\n0\n2\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n3\n0\n0\n0\n1\n0\n0\n0\n0\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n5\n0\n4\n0\n1\n2\n0\n0\n0\n0\n0\n0\n1\n2\n0\n0\n\n\n4\n0\n1\n1\n0\n1\n0\n3\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n1\n0\n3\n2\n1\n2\n0\n0\n0\n0\n0\n0\n1\n3\n0\n0\n\n\n4\n2\n0\n1\n0\n0\n0\n2\n0\n2\n2\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n4\n0\n0\n1\n0\n2\n0\n2\n2\n2\n1\n1\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n4\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n5\n1\n0\n3\n0\n2\n0\n2\n1\n0\n2\n0\n0\n0\n0\n0\n0\n3\n1\n0\n0\n\n\n3\n5\n0\n4\n0\n2\n0\n5\n0\n4\n2\n0\n0\n1\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n2\n0\n7\n0\n1\n1\n0\n0\n4\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n6\n0\n0\n2\n0\n1\n0\n0\n0\n1\n3\n0\n0\n0\n0\n0\n0\n0\n3\n3\n0\n\n\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n\n\n\n\n\n\\(E =\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n0\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n0\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n0\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n0\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n0\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n0\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n1\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n1\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n1\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n1\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n1\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n1\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n\n\n\n\\(T =\\)\n\n\n\n\n\n\nbiog\nforag\nmass\ndiet\nmove\nnest\neggs\n\n\n\n\nsp1\n1\n2\n2\n3\n1\n2\n2\n\n\nsp2\n1\n1\n1\n2\n1\n2\n2\n\n\nsp3\n1\n1\n2\n2\n2\n2\n1\n\n\nsp4\n1\n1\n1\n2\n1\n2\n2\n\n\nsp5\n1\n3\n3\n1\n2\n3\n4\n\n\nsp6\n1\n1\n4\n3\n2\n2\n1\n\n\nsp7\n1\n1\n1\n2\n1\n3\n3\n\n\nsp8\n1\n1\n1\n2\n2\n2\n2\n\n\nsp9\n1\n2\n1\n2\n1\n3\n3\n\n\nsp10\n1\n1\n1\n2\n1\n2\n2\n\n\nsp11\n2\n4\n3\n2\n1\n2\n2\n\n\nsp12\n2\n1\n2\n3\n2\n2\n3\n\n\nsp13\n2\n1\n4\n3\n2\n3\n1\n\n\nsp14\n2\n3\n2\n2\n1\n1\n3\n\n\nsp15\n2\n2\n2\n3\n2\n2\n3\n\n\nsp16\n2\n2\n2\n3\n2\n2\n4\n\n\nsp17\n2\n3\n4\n1\n1\n2\n2\n\n\nsp18\n2\n2\n1\n3\n2\n2\n3\n\n\nsp19\n2\n4\n3\n2\n1\n2\n2\n\n\nsp21\n2\n4\n3\n1\n2\n3\n3\n\n\nsp22\n2\n3\n2\n3\n2\n1\n3\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- dim(E)[2])\n\n[1] 6\n\n(k &lt;- dim(T_)[2])\n\n[1] 7\n\n\ndc-CA must not have to many traits compared to species: that is a disadvantage compared to RLQ, but on the other hand dc-CA allows to see relationships that RLQ would miss (Braak, Šmilauer, and Dray 2018).\nThere are several ways to perform dc-CA (Braak, Šmilauer, and Dray 2018), notably:\n\nsingular value decomposition (the method used here)\nan iterative method à la reciprocal averaging\ncanonical correlation analysis between \\(T\\) et \\(E\\), weighted by \\(Y\\)"
  },
  {
    "objectID": "dcCA.html#computation",
    "href": "dcCA.html#computation",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nWe perform the SVD of \\(D = [E_{center}' D(y_{i \\cdot}) E_{center}]^{-1/2} E_{center}' Y T_{center} [T_{center}' D(y_{\\cdot j}) T_{center}]^{-1/2}\\)\n\\[\nD = P \\Delta Q'\n\\] This allows us to find the eigenvectors \\(P\\) (rows or environment eigenvectors) and \\(Q\\) (columns or traits eigenvectors).\nThe eigenvalues of the dc-CA are the squared eigenvalues of the SVD: \\(\\Lambda = \\Delta^2\\).\nThere are \\(\\min(k, l)\\) non-null eigenvalues???\nRegression coefficients\nThen, the regression coefficients for explanatory variables can be found with:\n\n\\(B = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\Delta^\\alpha\\) (row explanatory variables = environmental variables)\n\\(C = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q\\Delta^\\alpha\\) (columns explanatory variables = species traits)\n\nwhere \\(\\alpha\\) is a scaling factor equal to 1, 0 or 1/2. The different scalings are detailed in the next part.\nIndividuals coordinates\nThe individuals coordinates (species or sites) can be computed in two ways:\nLinear combinations (LC scores) are computed from those coefficients :\n\n\\(Z_i = E_{center}B_i\\) for the rows (sites)\n\\(\\hat{Z}_i = T_{center}C_i\\) for columns (species)\n\nWeighted averages (WA scores) are computed from the scores of the other individuals:\n\n\\(\\hat{U}_i = D(y_{\\cdot i})^{-1} Y Z_i\\) for row (sites) scores\n\\(U_i = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_i\\) for column (species) scores\n\nCorrelations\nFinally, we can compute correlations scores for different scalings for the explanatory variables:\n\n\\(BS_B^i = \\left[ E_{center}'D(y_{i\\cdot})E_{center} \\right]^{1/2} P \\Delta^{\\alpha}\\) for the row (environmental variables)\n\\(BS_C^i = \\left[ T_{center}'D(y_{i\\cdot})T_{center} \\right]^{1/2} Q \\Delta^{1-\\alpha}\\) for the columns (species traits)\n\n\n\nFirst, we need to center the traits and environment matrices (resp. \\(T_{cent}\\) and \\(E_{cent}\\)). To do that, we have to compute “inflated” versions of these matrices matching the occurrence counts in \\(Y\\).\n\\[\nE_{stand} = E - \\bar{E}_{infl} =\\left[e_i \\sum_i y_{i\\cdot}e_i/y_{\\cdot\\cdot} \\right]\n\\]\n\\[\nT_{stand} = T - \\bar{T}_{infl} = \\left[t_j \\sum_j y_{\\cdot j}t_j/y_{\\cdot\\cdot} \\right]\n\\]\nWith our data:\n\n# Center E -----\nyi_ &lt;- rowSums(Y)\nEcenter &lt;- matrix(nrow = nrow(E), ncol = ncol(E))\n\nfor(i in 1:ncol(Ecenter)) {\n  Ecenter[, i] &lt;- E[, i] - sum(E[, i]*yi_)/sum(Y)\n}\n# This is the same as computing a mean on inflated data matrix Einfl and centering E with these means\n\n# Center T -----\ny_j &lt;- colSums(Y)\nTcenter &lt;- matrix(nrow = nrow(T_), ncol = ncol(T_))\nrownames(Tcenter) &lt;- rownames(T_)\ncolnames(Tcenter) &lt;- colnames(T_)\n\nfor(j in 1:ncol(Tcenter)) {\n  Tcenter[, j] &lt;- T_[, j] - (sum(T_[, j]*y_j)/sum(Y))\n}\n\n\n# Check centering -----\nM1 &lt;- matrix(rep(1, nrow(Y)), nrow = 1)\nall((M1 %*% diag(rowSums(Y)) %*% Ecenter) &lt; 10e-10)\n\n[1] TRUE\n\nM1 &lt;- matrix(rep(1, ncol(Y)), nrow = 1)\nall((M1 %*% diag(colSums(Y)) %*% Tcenter) &lt; 10e-10)\n\n[1] TRUE\n\n\nMaximizing the fourth-corner correlation means finding \\(\\hat{u}\\) and \\(u\\) that maximize \\(\\hat{u}'Yu\\) (where \\(\\hat{u}\\) are the sites (rows) scores and \\(u\\) are the species (columns) scores).\n\\(\\hat{u}\\) and \\(u\\) are linear combinations of traits and environmental variables: \\(\\hat{u} = E_{center}b\\) and \\(u = T_{center}c\\).\nSo in the end, we need to maximize \\(\\hat{u}'Yu\\) with respect to the coefficients vectors \\(b\\) and \\(c\\):\n\\[\n\\max_{b, c}(\\hat{u}'Yu) = \\max_{b, c}\\left(\\left[E_{center}b\\right]'Y  T_{center}c \\right)\n\\]\n\n\n\n\n\n\nNote\n\n\n\nThese equations are written for the first axis, but we can also write them in matrix form:\n\\[\n\\max_{B, C}(\\hat{U}'YU) = \\max_{B, C}\\left(\\left[E_{center}B\\right]'Y T_{center}C \\right)\n\\]\n\n\nIn addition, we introduce the following constraint on the norm of the columns vectors of \\(\\hat{U}\\) and \\(U\\): \\(\\hat{u}' D(y_{i\\cdot}) \\hat{u} = 1\\) and \\(u' D(y_{\\cdot j})u = 1\\). In fact, tjese constraints will be relaxed later depending on the scaling (see below).\nTo find the coefficients \\(B\\) and \\(C\\) defined above, we need to diagonalize the following matrices \\(M\\) and \\(M_2\\):\n\nTo find \\(B\\), we must diagonalize \\(M\\): \\[\nM = \\left[E_{center}' D(y_{i\\cdot}) E_{center} \\right]^{-1} E_{center}'YT_{center} \\left[T_{center}' D(y_{\\cdot j}) T_{center} \\right]^{-1} T_{center}' Y' E_{center}\n\\] Where matrices \\(D(y_{i \\cdot})\\) and \\(D(y_{\\cdot j})\\) are the diagonal matrices with the column and row sums (respectively). They are analogous to matrices \\(D(p_{i \\cdot})\\) and \\(D(p_{\\cdot j})\\) defined for CA and CCA (but we use \\(Y\\) instead of \\(P\\) to define the margins).\n\nWe can view \\(M\\) as: \\[\nM = \\hat{E}_{center} \\hat{T}_{center} = \\beta T_{center} \\gamma E_{center}\n\\] With \\(\\beta = \\left[E_{center}' D(y_{i\\cdot}) E_{center} \\right]^{-1} E_{center}'Y\\) and \\(\\gamma = \\left[T_{center}' D(y_{\\cdot j}) T_{center} \\right]^{-1} T_{center}' Y'\\). Here, we predict the environment with traits so that \\(\\hat{E}_{center} = \\beta T_{center}\\) and the traits with the environment so that \\(\\hat{T}_{center} = \\gamma E_{center}\\). So we maximize the correlation between \\(\\hat{E}_{center}\\) and \\(\\hat{T}_{center}\\).\n\nSimilarly, to find \\(C\\), we must diagonalize \\(M_2\\):\n\n\\[\nM_2 = \\left[T_{center}' D(y_{\\cdot j}) T_{center} \\right]^{-1} T_{center}' Y' E_{center} \\left[E_{center}' D(y_{i\\cdot}) E_{center} \\right]^{-1} E_{center}'YT_{center}\n\\] Here, we can view \\(M_2\\) as: \\[\nM_2 = \\hat{T}_{center} \\hat{E}_{center} = \\gamma E_{center} \\beta T_{center}\n\\]\nThe eigenvectors matrices of these diagonalizations give us \\(B\\) and \\(C\\):\n\\[\nM = B \\Lambda_b B^{-1} ~~ \\text{and} ~~ M_2 = C \\Lambda_c C^{-1}\n\\]\nWe can either diagonalize \\(M\\) and \\(M_2\\) of perform a single SVD of a matrix \\(D\\) defined below and get a similar result. Both methods are presented below.\n\nDiagonalizations\nWe diagonalize \\(M\\) and \\(M_2\\):\n\n# Define weights\nDyi_ &lt;- diag(rowSums(Y))\nDy_j &lt;- diag(colSums(Y))\n\n# Compute M\nM &lt;- solve(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% t(Ecenter) %*% Y %*% Tcenter %*% solve(t(Tcenter) %*% Dy_j %*% Tcenter) %*% t(Tcenter) %*% t(Y) %*% Ecenter\n\n# Compute M2\nM2 &lt;- solve(t(Tcenter) %*% Dy_j %*% Tcenter) %*% t(Tcenter) %*% t(Y) %*% Ecenter %*% solve(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% t(Ecenter) %*% Y %*% Tcenter \n\n\n# Diagonalize M\neigB &lt;- eigen(M)\nlambdaB &lt;- eigB$values\nlambdaB # All non-null eigenvectors\n\n[1] 0.139487442 0.088736680 0.049183623 0.013797529 0.008736645 0.002485683\n\nvB &lt;- eigB$vectors\n\n# Diagonalize M2\neigC &lt;- eigen(M2)\nlambdaC &lt;- eigC$values\nlambdaC # six non-null eigenvalues\n\n[1]  1.394874e-01  8.873668e-02  4.918362e-02  1.379753e-02  8.736645e-03\n[6]  2.485683e-03 -9.364154e-18\n\nvC &lt;- eigC$vectors\n\nall(lambdaB - lambdaC[1:l] &lt; 10e-10)\n\n[1] TRUE\n\n\n\n\nSVD\nAlternatively, we can compute the SVD of a matrix \\(D\\) computed from \\(M\\) and get a similar result. \\(D\\) is defined as:\n\\[\nD = M^{1/2} = [E_{center}' D(y_{i \\cdot}) E_{center}]^{-1/2} E_{center}' Y T_{center} [T_{center}' D(y_{\\cdot j}) T_{center}]^{-1/2}\n\\]\nWith our dataset:\n\nD &lt;- solve(sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter)) %*%\n  t(Ecenter) %*% Y %*% Tcenter %*%\n  solve(sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter))\n\nWe perform the SVD of \\(D\\): \\(D = P \\Lambda_{SVD} Q'\\).\n\nsv &lt;- svd(D)\n\ndelta &lt;- sv$d\nDelta &lt;- diag(delta)\n\nP_svd &lt;- sv$u\nQ_svd &lt;- sv$v\n\ndim(P_svd)\n\n[1] 6 6\n\ndim(Q_svd)\n\n[1] 7 6\n\n\nThe eigenvalues of the SVD are the square roots of the final eigenvalues obtained by diagonalization: \\(\\Lambda = \\Delta^2\\)\n\nlambda &lt;- delta^2\nLambda &lt;- diag(lambda)"
  },
  {
    "objectID": "dcCA.html#scalings",
    "href": "dcCA.html#scalings",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Scalings",
    "text": "Scalings\n\n\n\n\n\n\nTL;DR\n\n\n\nThere are two types of coordinates: linear combination scores (LC scores) and weighted averages scores (WA scores).\nThe general formulas are:\n\nthe regression coefficients for the rows (environmental variables) are \\(B = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\Delta^\\alpha\\)\nthe regression coefficients for the columns (species traits) are \\(C = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q\\Delta^{1 - \\alpha}\\)\nthe LC scores for rows (sites) are \\(Z_i = E_{center}B_i\\)\nthe LC scores for columns (species) are \\(\\hat{Z}_i = T_{center}C_i\\)\nthe WA scores for rows (sites) are \\(\\hat{U}_i = D(y_{\\cdot i})^{-1} Y Z_i\\)\nthe WA scores for columns (species) are \\(U_i = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_i\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_B^i = \\left[ E_{center}'D(y_{i\\cdot})E_{center} \\right]^{1/2} P \\Delta^{\\alpha}\\)\nthe correlations with axes for the columns (species traits) are \\(BS_C^i = \\left[ T_{center}'D(y_{i\\cdot})T_{center} \\right]^{1/2} Q \\Delta^{1-\\alpha}\\)\n\nNote: the formula for the regression coefficients \\(C_i\\) are in disagreement with the article of (Braak, Šmilauer, and Dray 2018). Here, we find that the scaling should include \\(\\Delta^{1-\\alpha}\\) in the formula (17) instead of \\(\\Delta^{\\alpha-1}\\). However, when we try to prove transition formula (6), we find that it should be \\(\\Delta^{\\alpha}\\).\nIn these formulas, note that the WA scores for one dimension are computed from the predicted scores of the other dimension.\nScaling type 1 (\\(\\alpha = 1\\))\n\nthe regression coefficients for the rows (environmental variables) are \\(B_1 = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\Delta\\)\nthe regression coefficients for the columns (species traits) are \\(C_1 = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q\\)\nthe LC scores for rows (sites) are \\(Z_1 = E_{center}B_1\\)\nthe LC scores for columns (species) are \\(\\hat{Z}_1 = T_{center}C_1\\)\nthe WA scores for rows (sites) are \\(\\hat{U}_1 = D(y_{\\cdot i})^{-1} Y Z_1\\)\nthe WA scores for columns (species) are \\(U_1 = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_1\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_B^1 = \\left[ E_{center}'D(y_{i\\cdot})E_{center} \\right]^{1/2} P \\Delta\\)\nthe correlations with axes for the columns (species traits) are \\(BS_C^1 = \\left[ T_{center}'D(y_{i\\cdot})T_{center} \\right]^{1/2} Q \\Delta\\)\n\nScaling type 2 (\\(\\alpha = 0\\))\n\nthe regression coefficients for the rows (environmental variables) are \\(B_2 = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\)\nthe regression coefficients for the columns (species traits) are \\(C_2 = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q \\Delta\\)\nthe LC scores for rows (sites) are \\(Z_2 = E_{center}B_2\\)\nthe LC scores for columns (species) are \\(\\hat{Z}_2 = T_{center}C_2\\)\nthe WA scores for rows (sites) are \\(\\hat{U}_2 = D(y_{\\cdot i})^{-1} Y Z_2\\)\nthe WA scores for columns (species) are \\(U_2 = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_2\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_B^2 = \\left[ E_{center}'D(y_{i\\cdot})E_{center} \\right]^{1/2} P\\)\nthe correlations with axes for the columns (species traits) are \\(BS_C^2 = \\left[ T_{center}'D(y_{i\\cdot})T_{center} \\right]^{1/2} Q\\)\n\nScaling type 3 (\\(\\alpha = 1/2\\))\n\nthe regression coefficients for the rows (environmental variables) are \\(B_3 = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\Delta^{1/2}\\)\nthe regression coefficients for the columns (species traits) are \\(C_3 = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q\\Delta^{1/2}\\)\nthe LC scores for rows (sites) are \\(Z_3 = E_{center}B_3\\)\nthe LC scores for columns (species) are \\(\\hat{Z}_3 = T_{center}C_3\\)\nthe WA scores for rows (sites) are \\(\\hat{U}_3 = D(y_{\\cdot i})^{-1} Y Z_3\\)\nthe WA scores for columns (species) are \\(U_3 = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_3\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_B^3 = \\left[ E_{center}'D(y_{i\\cdot})E_{center} \\right]^{1/2} P \\Delta^{1/2}\\)\nthe correlations with axes for the columns (species traits) are \\(BS_C^3 = \\left[ T_{center}'D(y_{i\\cdot})T_{center} \\right]^{1/2} Q \\Delta^{1/2}\\)\n\n\\(\\alpha\\) changes the interpretation of the correlations vectors:\n\nintra-set correlations: \\(BS_B^2\\) (\\(\\alpha = 0\\)) approximates the correlations between the environmental variables (rows variables) and \\(BS_C^1\\) (\\(\\alpha = 1\\)) approximates the correlations between the traits (columns variables)\ninter-set correlations (fourth-corner): \\(BS_B^1\\) (\\(\\alpha = 1\\)) approximates the correlation between environmental variables (row variables) and species (columns) and \\(BS_C^2\\) (\\(\\alpha = 0\\)) approximates the correlation between traits (columns variables) and sites (rows)\n\\(BS_B^3\\) and \\(BS_C^3\\) (\\(\\alpha = 1/2\\)) is the geometric mean of scalings 1 and 2.\n\nWhen plotting the correlation circle, to look at the correlations between variables of the same set (traits or environmental variables), we should use \\(BS_B^2\\) and \\(BS_C^1\\). There are the scores returned by ade4.\n\n\n\nca &lt;- dudi.coa(Y, \n               nf = c-1, \n               scannf = FALSE)\n\ndcca &lt;- dpcaiv2(dudi = ca, \n                dfR = E,\n                dfQ = T_,\n                scannf = FALSE, \n                nf = min(k, l))\n\n\nPre-computations\nCoefficients etc computed with our method are equal to those computed by ade4, but we need to multiply them by a scaling factor \\(\\sqrt{y_{\\cdot \\cdot}}\\).\n\n(scaling &lt;- sqrt(sum(Y)))\n\n[1] 22.2036\n\n\nWe will need this function to normalize correlations vectors to compare results to those of ade4.\n\n#' Normalize row or columns vectors of a matrix\n#'\n#' @param M the matrix to normalize\n#' @param margin the margin (1 = rows, 2 = columns)\n#'\n#' @return The normalized matrix M\nnormalize &lt;- function(M, margin) {\n  \n  m_norm &lt;- apply(M,\n                  margin, \n                  function(x) sqrt(sum(x^2)))\n  M_norm &lt;- sweep(M, margin, m_norm, \"/\")\n  return(M_norm)\n}\n\n\n\nScaling type 1\nThis type of scaling preserves the distances between rows.\n\nthe rows (sites) scores can be \\(\\hat{U}_1\\) (WA scores) or \\(\\hat{Z}_1\\) (LC scores)\n\nthe columns (species) scores can be \\(U_1\\) (WA scores) or \\(Z_1\\) (LC scores)\nrows variables (environmental variables) correlations are \\(BS_{B1}\\).\ncolumns variables (species traits) correlations are \\(BS_{C1}\\)\n\nWith the scaling type 1, \\(BS_{B1}\\) represents the correlation between environmental variables and species and \\(BS_{C1}\\) represents the correlation between species traits and species.\n\n# Coefficients\nB_1 &lt;- solve(sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter)) %*%  P_svd %*% Delta\nC_1 &lt;- solve(sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter)) %*% Q_svd\n\n# LC scores\nZhat1 &lt;- Ecenter %*% B_1 # rows\nZ1 &lt;- Tcenter %*% C_1 # columns\n\n# WA scores\nUhat1 &lt;- solve(Dyi_) %*% Y %*% Z1 # rows\nU1 &lt;- solve(Dy_j) %*% t(Y) %*% Zhat1  # columns\n\n# Variables scores\nBS_B1 &lt;- sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% P_svd %*% Delta\nBS_C1 &lt;- sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter) %*% Q_svd\n\n# Normalize\nBS_B1norm &lt;- normalize(BS_B1, 1)\nBS_C1norm &lt;- normalize(BS_C1, 1)\n\n\n\nCode\n# WA scores\ngwa &lt;- multiplot(indiv_row = Uhat1*scaling, indiv_col = U1*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B1norm, var_row_lab = colnames(E),\n                 var_col = BS_C1norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"WA scores for sites\")\n\n# LC scores\nglc &lt;- multiplot(indiv_row = Zhat1*scaling, indiv_col = Z1*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B1norm, var_row_lab = colnames(E),\n                 var_col = BS_C1norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\ngrid.arrange(grobs = list(gwa, glc),\n             nrow = 2)\n\n\n\n\n\nOn this plot:\n\nrow and columns variables (\\(BS_B^1\\) - \\(BS_C^1\\)): angles between arrows of rows and environmental variables represent their fourth-corner correlation. For instance, the correlation between mass and perc_forests is large (arrows size + direction).\nspecies traits (\\(BS_C^1\\)): arrows indicate intra-set correlations.\nspecies and environmental variables (\\(U\\) - \\(BS_B^1\\)): species points on the right are located in sites with a high location variable.\nsites and species traits (\\(\\hat{U}\\) - \\(BS_C^1\\)): we can understand sites using their community weighted mean (eg site 26 has birds with high mass).\nspecies and species traits (\\(U\\) - \\(BS_C^1\\)): for instance, species 12 has large eggs.\n\nThere is no interpretation for sites - environmental variables (\\(\\hat{U}\\) - \\(BS_B^1\\)).\n\n\nScaling type 2\nThis type of scaling preserves the distances between columns.\n\nthe rows (sites) scores can be \\(\\hat{U}_2\\) (WA scores) or \\(\\hat{Z}_2\\) (LC scores)\n\nthe columns (species) scores can be \\(U_2\\) (WA scores) or \\(Z_2\\) (LC scores)\nrows variables (environmental variables) correlations are \\(BS_{B2}\\).\ncolumns variables (species traits) correlations are \\(BS_{C2}\\)\n\nWith the scaling type 2, \\(BS_{B2}\\) represents the correlation between environmental variables and sites and \\(BS_{C2}\\) represents the correlation between species traits and sites.\n\n# Regression coefficients\nB_2 &lt;- solve(sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter)) %*%  P_svd\nC_2 &lt;- solve(sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter)) %*% Q_svd %*% Delta\n\n# LC scores\nZhat2 &lt;- Ecenter %*% B_2 # rows\nZ2 &lt;- Tcenter %*% C_2 # columns\n\n# WA scores\nUhat2 &lt;- solve(Dyi_) %*% Y %*% Z2 # rows\nU2 &lt;- solve(Dy_j) %*% t(Y) %*% Zhat2 # columns\n\n# Variables scores\nBS_B2 &lt;- sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% P_svd\nBS_C2 &lt;- sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter) %*% Q_svd %*% Delta\n\n# Normalize\nBS_B2norm &lt;- normalize(BS_B2, 1)\nBS_C2norm &lt;- normalize(BS_C2, 1)\n\n\n\nCode\n# WA scores\ngwa &lt;- multiplot(indiv_row = Uhat2*scaling, indiv_col = U2*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B2norm, var_row_lab = colnames(E),\n                 var_col = BS_C2norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"WA scores for sites\")\n\n# LC scores\nglc &lt;- multiplot(indiv_row = Zhat2*scaling, indiv_col = Z2*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B2norm, var_row_lab = colnames(E),\n                 var_col = BS_C2norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\ngrid.arrange(grobs = list(gwa, glc),\n             nrow = 2)\n\n\n\n\n\nOn this plot:\n\nrow and columns variables (\\(BS_B^2\\) - \\(BS_C^2\\)): angles between arrows of rows and environmental variables represent their fourth-corner correlation. For instance, the correlation between mass and patch_forests is large (arrows size + direction).\nenvironmental variables (\\(BS_B^2\\)): arrows indicate intra-set correlations.\nspecies and environmental variables (\\(U\\) - \\(BS_B^1\\))\nsites and species traits (\\(\\hat{U}\\) - \\(BS_C^1\\))\nsites and environmental variables (\\(U\\) - \\(BS_C^1\\))\n\nThere is no interpretation for species - species traits (\\(U\\) - \\(BS_C^2\\)).\n\n\nScaling type 3\nThis type of scaling is an intermediate between scalings 1 and 2.\n\nthe rows (sites) scores can be \\(\\hat{U}_3\\) (WA scores) or \\(\\hat{Z}_3\\) (LC scores)\n\nthe columns (species) scores can be \\(U_3\\) (WA scores) or \\(Z_3\\) (LC scores)\nrows variables (environmental variables) correlations are \\(BS_{B3}\\).\ncolumns variables (species traits) correlations are \\(BS_{C3}\\)\n\nWith the scaling type 3, \\(BS_{B3}\\) and \\(BS_{C3}\\) represent the geometric mean of their correlation with species and sites.\n\n# Variables coefficients\nB_3 &lt;- solve(sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter)) %*%  P_svd %*% Delta^(1/2)\nC_3 &lt;- solve(sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter)) %*% Q_svd %*% Delta^(1/2)\n\n# LC scores\nZhat3 &lt;- Ecenter %*% B_3 # rows\nZ3 &lt;- Tcenter %*% C_3 # columns\n\n# WA scores\nUhat3 &lt;- solve(Dyi_) %*% Y %*% Tcenter %*% C_3 # rows\nU3 &lt;- solve(Dy_j) %*% t(Y) %*% Zhat3 # columns\n\n# Variables scores\nBS_B3 &lt;- sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% P_svd %*% Delta^(1/2)\nBS_C3 &lt;- sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter) %*% Q_svd %*% Delta^(1/2)\n\n# Normalize\nBS_B3norm &lt;- normalize(BS_B3, 1)\nBS_C3norm &lt;- normalize(BS_C3, 1)\n\n\n\nCode\n# WA scores\ngwa &lt;- multiplot(indiv_row = Uhat3*scaling, indiv_col = U3*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B3norm, var_row_lab = colnames(E),\n                 var_col = BS_C3norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"WA scores for sites\")\n\n# LC scores\nglc &lt;- multiplot(indiv_row = Zhat3*scaling, indiv_col = Z3*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B3norm, var_row_lab = colnames(E),\n                 var_col = BS_C3norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\ngrid.arrange(grobs = list(gwa, glc),\n             nrow = 2)"
  },
  {
    "objectID": "dcCA.html#more-tests",
    "href": "dcCA.html#more-tests",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "More tests",
    "text": "More tests\nBelow, we test the variances of various scores.\n\n# Since ter Braak and ade4 disagree, check the variance of co and Z2 or Z2 (it should be the eigenvalues of each axis)\n\n#' Get the variance of vector x\n#'\n#' @param x The vector\n#' @param w The weights\n#'\n#' @return The variance\nvarvec &lt;- function(x, w) {\n  sum(w*(x-mean(x))^2)\n}\n\nres_ade4 &lt;- apply(as.matrix(dcca$co), \n                  2, \n                  function(x) varvec(x, dcca$cw))\nres_ade4/dcca$eig\n\n   Comp1    Comp2    Comp3    Comp4    Comp5    Comp6 \n1.106286 1.151797 1.466209 1.038659 1.005454 1.000003 \n\nres_tB &lt;- apply(Z2*scaling, \n                2, \n                function(x) varvec(x, dcca$cw))\nres_tB/dcca$eig \n\n[1] 1.106286 1.151797 1.466209 1.038659 1.005454 1.000003\n\nres_agree &lt;- apply(Z2*scaling, \n                   2, \n                   function(x) varvec(x, dcca$cw))\nres_agree/dcca$eig\n\n[1] 1.106286 1.151797 1.466209 1.038659 1.005454 1.000003\n\n\n\nLC scores for rows:\n\n\n# l1 variances should be 1\napply(as.matrix(dcca$l1), \n      2, \n      function(x) varvec(x, dcca$lw))\n\n     RS1      RS2      RS3      RS4      RS5      RS6 \n1.014490 1.005249 1.002007 1.000012 1.000331 1.000000 \n\n# li variances should be eigenvalues\napply(as.matrix(dcca$li), \n      2, \n      function(x) varvec(x, dcca$lw))/dcca$eig\n\n   Axis1    Axis2    Axis3    Axis4    Axis5    Axis6 \n1.014490 1.005249 1.002007 1.000012 1.000331 1.000000 \n\n\n\nLC scores for columns\n\n\n# c1 variances should be 1\napply(as.matrix(dcca$c1), \n      2, \n      function(x) varvec(x, dcca$cw))\n\n     CS1      CS2      CS3      CS4      CS5      CS6 \n1.106286 1.151797 1.466209 1.038659 1.005454 1.000003 \n\n# co variances should be eigenvalues\napply(as.matrix(dcca$co), \n      2, \n      function(x) varvec(x, dcca$cw))/dcca$eig \n\n   Comp1    Comp2    Comp3    Comp4    Comp5    Comp6 \n1.106286 1.151797 1.466209 1.038659 1.005454 1.000003 \n\n\n\n# Z2 variances should be the eigenvalues\napply(Z2*scaling, \n      2, \n      function(x) varvec(x, dcca$cw))/dcca$eig\n\n[1] 1.106286 1.151797 1.466209 1.038659 1.005454 1.000003\n\n\n\nWA scores:\n\n\n# Hypothesis: these scires shound be the eigenvalues\napply(as.matrix(dcca$lsR), \n      2, \n      function(x) varvec(x, dcca$lw))/dcca$eig\n\n    Axis1     Axis2     Axis3     Axis4     Axis5     Axis6 \n 1.397739  1.490618  1.894509  3.367612  7.569186 16.600310 \n\n# co variances should be eigenvalues\napply(as.matrix(dcca$lsQ), \n      2, \n      function(x) varvec(x, dcca$cw))/dcca$eig\n\n    Comp1     Comp2     Comp3     Comp4     Comp5     Comp6 \n 1.356947  1.416201  2.521861  7.980247  5.161038 13.632366"
  },
  {
    "objectID": "dcCA.html#interpretation",
    "href": "dcCA.html#interpretation",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Interpretation",
    "text": "Interpretation\nThis method finds the linear correlation of row explanatory variables (environmental variables) and the linear correlation of columns explanatory variables (species traits) that maximizes the fourth-corner correlation, i.e. the correlation between these linear combinations of row and columns-variables.\nThere are other related methods, that have been better described and also more used in ecology: RLQ, community weighted means RDA (CMW-RDA).\nContrary to RLQ, dc-CA takes into account the correlation between the row and column variables. Thus, while RLQ can analyze any number of row and column variables, it is not the case with dc-CA the number of row and column variables must not be large compared to the number of rows/columns in the tables. Also, CCA maximizes correlation and RLQ maximizes covariance (Braak, Šmilauer, and Dray 2018).\nThe eigenvalues of dc-CA are the squares of the fourth-corner correlations."
  },
  {
    "objectID": "recscal_cca.html",
    "href": "recscal_cca.html",
    "title": "Reciprocal scaling with CCA",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# dc-CA\nsource(here(\"functions/dpcaiv2-ade4.R\"))\n\n# Reciprocal scaling\nsource(here(\"functions/reciprocal.R\"))\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nsource(here(\"functions/plot.R\"))\nlibrary(gridExtra)"
  },
  {
    "objectID": "recscal_cca.html#introduction",
    "href": "recscal_cca.html#introduction",
    "title": "Reciprocal scaling with CCA",
    "section": "Introduction",
    "text": "Introduction\nThis is an extension of reciprocal scaling defined for correspondence analysis by Thioulouse and Chessel (1992) to canonical correspondence analysis.\nHere, we start from two matrices:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables (environmental variabnes) \\(E\\) (\\(r \\times l\\))\n\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- ncol(E))\n\n[1] 6"
  },
  {
    "objectID": "recscal_cca.html#computation",
    "href": "recscal_cca.html#computation",
    "title": "Reciprocal scaling with CCA",
    "section": "Computation",
    "text": "Computation\n\nFrom CCA scores\nWe compute the \\(H_k(i, j)\\) from the LC (for rows = sites) and WA (for columns = species) scores computed with CCA (noted \\(LC\\) and \\(C\\)). This formula is a direct extension of formula (11) in Thioulouse and Chessel (1992) but we replace the CA ordination scores with the CCA ordination scores.\nIn CCA, we have several scores for the sites. The notation \\(LC_k(i)\\) represents the LC scores (or the li of ade4). The \\(C_k(j)\\) are the species scores co.\n\\[\nH_k(i, j) = \\frac{LC_k(i) + C_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\n\nYdf &lt;- as.data.frame(Y)\nca &lt;- dudi.coa(Ydf, \n               scannf = FALSE,\n               nf = min(r - 1, c - 1))\n\nneig &lt;- min(c(r-1, c, l))\ncca &lt;- pcaiv(dudi = ca, \n             df = E,\n             scannf = FALSE,\n             nf = neig)\n\nL_CCA &lt;- cca$li\nC_CCA &lt;- cca$co\n\nlambda_CCA &lt;- cca$eig\nmu_CCA &lt;- 1 + sqrt(lambda_CCA)\n\nWe also compute reciprocal scaling for comparison (to check results, not shown):\n\nrec_cca &lt;- reciprocal.caiv(cca)\n\n\n# Transform matrix to count table\nYfreq &lt;- as.data.frame(as.table(Y))\ncolnames(Yfreq) &lt;- c(\"row\", \"col\", \"Freq\")\n\n# Remove the cells with no observation\nYfreq0 &lt;- Yfreq[-which(Yfreq$Freq == 0),]\nYfreq0$colind &lt;- match(Yfreq0$col, colnames(Y)) # match index and species names\n\n\n# Initialize results matrix\nH &lt;- matrix(nrow = nrow(Yfreq0), \n            ncol = length(lambda_CCA))\n\nfor (k in 1:length(lambda_CCA)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H[ind, k] &lt;- (L_CCA[i, k] + C_CCA[j, k])/sqrt(2*lambda_CCA[k]*mu_CCA[k])\n    ind &lt;- ind + 1\n  }\n}\n\n\n\nFrom canonical correlation analysis\nTo perform the canonical correlation analysis, we compute the inflated tables \\(R\\) (\\(\\omega \\times l\\)) and \\(C\\) (\\(\\omega \\times c\\)) from \\(Y\\) (\\(r \\times c\\)) and \\(E\\) (\\(r \\times l\\)). The difference with CA is that we use \\(E\\) instead of \\(Y\\) to compute the inflated table \\(R\\). \\(R\\) is equivalent to \\(E\\) where rows of \\(E\\) are duplicated as many times as there are correspondences in \\(Y\\).\nWe take the frequency table defined before and use it to compute the inflated tables (with weights):\n\n# Create indicator tables\ntabR &lt;- acm.disjonctif(as.data.frame(Yfreq0$row))\ntabR &lt;- as.matrix(tabR) %*% as.matrix(E) # duplicate rows of E according th the correspondences of Y\ntabC &lt;- acm.disjonctif(as.data.frame(Yfreq0$col))\ncolnames(tabC) &lt;- colnames(Y)\n\n# Get weights\nwt &lt;- Yfreq0$Freq\n\nBelow are the first lines of tables \\(R\\) and \\(C\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n0\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n0\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n0\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n0\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n0\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n0\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n1\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n1\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n1\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n1\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n1\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n1\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\nThen, we perform a canonical correlation on the scaled tables \\(R_{scaled}\\) and \\(C_{scaled}\\). We find the coefficients \\(\\rho\\) and \\(\\gamma\\) maximizing the correlation between the scores \\(S_R = R_{scaled} \\rho\\) and \\(S_C = C_{scaled} \\gamma\\).\n\n# Center tables\ntabR_scaled &lt;- scalewt(tabR, wt, \n                       scale = FALSE)\ntabC_scaled &lt;- scalewt(tabC, wt, \n                       scale = FALSE)\n\nres &lt;- cancor(diag(sqrt(wt)) %*% tabR_scaled, \n              diag(sqrt(wt)) %*% tabC_scaled, \n              xcenter = FALSE, ycenter = FALSE)\n# res gives the coefficients of the linear combinations that maximizes the correlation between the 2 dimensions\ndim(res$xcoef) # l columns -&gt; R_scaled is of full rank\n\n[1] 6 6\n\ndim(res$ycoef) # c-1 columns -&gt; C_scaled is not of full rank\n\n[1] 20 20\n\n# Compute these scores from this coef\nscoreR &lt;- tabR_scaled[, 1:l]  %*% res$xcoef\nscoreC &lt;- tabC_scaled[, 1:(c-1)]  %*% res$ycoef\n\nWe have \\(H = (S_R + S_C)_{scaled}\\).\n\n# Get H\nscoreRC &lt;- scoreR[, 1:l] + scoreC[, 1:l] # here l &lt; c-1 so l axes\nscoreRC_scaled &lt;- scalewt(scoreRC, wt = wt)\n\n\n# Check result\nall(abs(scoreRC_scaled/H) - 1 &lt; 10e-10)\n\n[1] TRUE\n\n\n\n\nPlot RC scores\n\n\nCode\nmultiplot(indiv_row = H, \n          indiv_row_lab = paste0(\"site \", Yfreq0$row, \"/\", Yfreq0$col),\n          row_color = \"black\", eig = lambda_CCA)"
  },
  {
    "objectID": "recscal_cca.html#conditional-means-and-variances-from-rc-scores",
    "href": "recscal_cca.html#conditional-means-and-variances-from-rc-scores",
    "title": "Reciprocal scaling with CCA",
    "section": "Conditional means and variances from RC scores",
    "text": "Conditional means and variances from RC scores\n\n\n\n\n\n\nTL;DR\n\n\n\nOnce we have the correspondences scores, we can group them by row (site) or column (species) to compute conditional summary statistics:\n\nconditional mean for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional variance for site \\(i\\) or species \\(j\\) (for each axis \\(k\\))\nconditional covariance for site \\(i\\) or species \\(j\\) (between axes \\(k\\) and \\(l\\))\n\nThese conditional statistics can be computed using \\(H_k(i,j)\\) or using the CA scores:\nFormulas using \\(H_k(i,j)\\)\nThe means and variances are simply the weighted means/variances of the \\(H_k(i, j)\\) for a fixed \\(i\\) or \\(j\\).\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[m_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} H_k(i,j)\\]\n\\[m_k(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} H_k(i,j)\\]\n\n\nVariance for axis \\(k\\)\n\\[s_k^2(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} \\left(H_k(i,j) - m_k(i)\\right)^2\\]\n\\[s_k^2(j) = \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r y_{ij} \\left(H_k(i,j) - m_k(j)\\right)^2\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\\[c_{kl}(i) = \\frac{1}{y_{i \\cdot}}\\sum_{j=1}^c y_{ij}H_k(i, j)H_l(i, j) - m_k(i)m_l(i)\\]\n\\[c_{kl}(j) = \\frac{1}{y_{\\cdot j}}\\sum_{i=1}^r y_{ij}H_k(i, j)H_l(i, j) - m_k(j)m_l(j)\\]\n\n\n\nFormulas using CCA scores\nNote that the LC score (notation: \\(LC\\)) is used for the species variance and the WA score (notation: \\(L\\)) for the sites variance.\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[m_k(i) =  \\frac{1}{\\sqrt{2 \\mu_k}} \\times (LC1_k(i) + L_k(i))\\]\n\\[m_k(j) = \\frac{\\sqrt{\\mu_k}}{\\sqrt{2\\lambda_k}} C_k(j)\\]\n\n\nVariance for axis \\(k\\)\n\\[s^2_k(i) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} C_k^2(j) \\right) - \\lambda_k L_k^2(i) \\right)\\]\n\\[s^2_k(j) = \\frac{1}{2\\lambda_k\\mu_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} LC_k^2(i) \\right) - \\lambda_k C_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\n\nLet’s start from the means/variances computed from the RC scores (\\(H\\)).\n\nfac &lt;- sqrt(mu_CCA)/sqrt(2*lambda_CCA)\nn &lt;- sum(Y)\n\n\nFor rows = sites\nBelow is a graphical illustration of scoreRC grouped by rows:\n\ns.class(scoreRC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        plabels.col = params$colsite, \n        main = \"With RC score (points = correspondences)\")\n\n\n\n\n\nFormula with RC scores (definition)\nWe compute the groupwise mean and variance.\n\n# With scaled values\nmrowsRC &lt;- meanfacwt(scoreRC_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\nmrowsRC/(as.matrix(cca$l1 + cca$ls) %*% diag(1/sqrt(2*mu_CCA)))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1 -1  1  1\n2   1  1  1 -1  1  1\n3   1  1  1 -1  1  1\n4   1  1  1 -1  1  1\n5   1  1  1 -1  1  1\n6   1  1  1 -1  1  1\n7   1  1  1 -1  1  1\n8   1  1  1 -1  1  1\n9   1  1  1 -1  1  1\n10  1  1  1 -1  1  1\n11  1  1  1 -1  1  1\n12  1  1  1 -1  1  1\n13  1  1  1 -1  1  1\n14  1  1  1 -1  1  1\n15  1  1  1 -1  1  1\n16  1  1  1 -1  1  1\n17  1  1  1 -1  1  1\n18  1  1  1 -1  1  1\n19  1  1  1 -1  1  1\n20  1  1  1 -1  1  1\n21  1  1  1 -1  1  1\n22  1  1  1 -1  1  1\n23  1  1  1 -1  1  1\n24  1  1  1 -1  1  1\n25  1  1  1 -1  1  1\n26  1  1  1 -1  1  1\n\n\n\n# With non-scaled values\nmrowsRC_ns &lt;- meanfacwt(scoreRC, fac = Yfreq0$row, wt = Yfreq0$Freq)\nmrowsRC_ns/((cca$l1 + cca$ls)*1/sqrt(n))\n\n   RS1 RS2 RS3 RS4 RS5 RS6\n1    1   1   1  -1   1   1\n2    1   1   1  -1   1   1\n3    1   1   1  -1   1   1\n4    1   1   1  -1   1   1\n5    1   1   1  -1   1   1\n6    1   1   1  -1   1   1\n7    1   1   1  -1   1   1\n8    1   1   1  -1   1   1\n9    1   1   1  -1   1   1\n10   1   1   1  -1   1   1\n11   1   1   1  -1   1   1\n12   1   1   1  -1   1   1\n13   1   1   1  -1   1   1\n14   1   1   1  -1   1   1\n15   1   1   1  -1   1   1\n16   1   1   1  -1   1   1\n17   1   1   1  -1   1   1\n18   1   1   1  -1   1   1\n19   1   1   1  -1   1   1\n20   1   1   1  -1   1   1\n21   1   1   1  -1   1   1\n22   1   1   1  -1   1   1\n23   1   1   1  -1   1   1\n24   1   1   1  -1   1   1\n25   1   1   1  -1   1   1\n26   1   1   1  -1   1   1\n\n\nVariances\n\n# With scaled values\nvarrowsRC &lt;- varfacwt(scoreRC_scaled, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n# With non-scaled values\nvarrowsRC_ns &lt;- varfacwt(scoreRC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n\n\nVariance formula with CCA scores\n\n# Get marginal counts\nyi_ &lt;- rowSums(Y)\ny_j &lt;- colSums(Y)\n\nvarrowsCCA &lt;- matrix(nrow = r, \n                     ncol = l)\n\nfor (i in 1:r) {\n  # Get CCA scores for site i\n  Li &lt;- cca$ls[i, ]\n  \n  # Compute the part with the sum on Cj\n  # we add all coordinates Cj^2 weighted by the number of observations on site i\n  sumCj &lt;- t(Y[i, ]) %*% as.matrix(cca$co)^2\n\n  # Fill i-th row with site i variance along each axis\n  varrowsCCA[i, ] &lt;- (1/(2*lambda_CCA*mu_CCA)) * (((1/yi_[i])*sumCj) - lambda_CCA*as.numeric(Li)^2)\n}\n\n\nvarrowsRC/varrowsCCA\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\n\n\n\nFor columns = species\nBelow is an illustration of the RC scores grouped by species.\n\ns.class(scoreRC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        plabels.col = params$colspp, \n        main = \"With RC score (points = correspondences)\")\n\n\n\n\n\nFormula with RC scores (definition)\n\nmcolsRC &lt;- meanfacwt(scoreRC_scaled, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsRC/(as.matrix(cca$co) %*% diag(fac))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1 -1  1  1\n2   1  1  1 -1  1  1\n3   1  1  1 -1  1  1\n4   1  1  1 -1  1  1\n5   1  1  1 -1  1  1\n6   1  1  1 -1  1  1\n7   1  1  1 -1  1  1\n8   1  1  1 -1  1  1\n9   1  1  1 -1  1  1\n10  1  1  1 -1  1  1\n11  1  1  1 -1  1  1\n12  1  1  1 -1  1  1\n13  1  1  1 -1  1  1\n14  1  1  1 -1  1  1\n15  1  1  1 -1  1  1\n16  1  1  1 -1  1  1\n17  1  1  1 -1  1  1\n18  1  1  1 -1  1  1\n19  1  1  1 -1  1  1\n20  1  1  1 -1  1  1\n21  1  1  1 -1  1  1\n\n\n\nmcolsRC_ns &lt;- meanfacwt(scoreRC, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsRC_ns/cca$co\n\n         Comp1     Comp2     Comp3      Comp4     Comp5    Comp6\nsp1  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp2  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp3  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp4  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp5  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp6  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp7  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp8  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp9  0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp10 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp11 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp12 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp13 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp14 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp15 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp16 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp17 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp18 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp19 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp21 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\nsp22 0.1498454 0.1586454 0.1867878 -0.1976291 0.2959281 0.415688\n\n\n\n# With scaled values\nvarcolsRC &lt;- varfacwt(scoreRC_scaled, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\n# With non-scaled values\nvarcolsRC_ns &lt;- varfacwt(scoreRC, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\n\n\nVariance formula with CCA scores\n\nvarcolsCCA &lt;- matrix(nrow = c, \n                     ncol = l)\n\nfor (j in 1:c) {\n  # Get CCA scores for species j\n  Cj &lt;- cca$co[j, ]\n  \n  # Compute the part with the sum on Li\n  # we add all coordinates Li^2 weighted by the number of observations on species j\n  sumLi &lt;- t(Y[, j]) %*% as.matrix(cca$li)^2\n\n  # Fill i-th row with site i variance along each axis\n  varcolsCCA[j, ] &lt;- (1/(2*lambda_CCA*mu_CCA)) * (((1/y_j[j])*sumLi) - lambda_CCA*as.numeric(Cj)^2)\n}\n\n\nvarcolsRC/varcolsCCA\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   0  0  0  0  0  0\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  0  0  0  0  0  0\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n\nvarcolsRC_ns/(varcolsCCA %*% diag(2*mu_CCA/n))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   0  0  0  0  0  0\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  0  0  0  0  0  0\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1"
  },
  {
    "objectID": "recscal_cca.html#conditional-means-and-variances-from-r-scores-and-c-scores",
    "href": "recscal_cca.html#conditional-means-and-variances-from-r-scores-and-c-scores",
    "title": "Reciprocal scaling with CCA",
    "section": "Conditional means and variances from R scores and C scores",
    "text": "Conditional means and variances from R scores and C scores\n\n\n\n\n\n\nTL;DR\n\n\n\nFor the scores computed with R scores and C scores, we have 3 types of formulas:\n\ndefinition (weighted mean/variance/covariance)\nformulas using the CCA scores\nrelation with the RC scores\n\nHere, we don’t show the definition.\nFormulas using CCA scores\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{1}{\\sqrt{n}} LC1_k(i)\\] (\\(LC1 =\\) normed LC score ($l1))\n\\[mR_k(j) =   \\frac{1}{\\sqrt{n}} C_k(j)\\]\n\n\nVariance for axis \\(k\\)\nNone\n\\[sR_k^2(j) = \\frac{1}{n\\lambda_k} \\left( \\frac{1}{y_{\\cdot j}} \\sum_{i = 1}^r \\left(y_{ij} LC_k^2(i) \\right) - \\lambda_k C_k^2(j) \\right)\\]\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[\\frac{1}{\\sqrt{n}} L_k(i)\\] (\\(L_k(i) =\\) WA score ($ls))\n\\[\\frac{1}{\\sqrt{n}} C1_k(j)\\] (\\(C1_k(j) =\\) normed species score ($c1))\n\n\nVariance for axis \\(k\\)\n\\[sC_k^2(i) = \\frac{1}{n\\lambda_k} \\left( \\frac{1}{y_{i \\cdot}} \\sum_{j = 1}^c \\left(y_{ij} C_k^2(j) \\right) - \\lambda_k L_k^2(i) \\right)\\]\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\nRelation between RC scores and R score / C score\n\nusing R score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mR_k(i) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(i) - \\frac{1}{\\sqrt{n}} L_k(i)\\]\n\\[mR_k(j) = \\frac{\\sqrt{2 \\lambda_k}}{\\sqrt{n \\mu_k}} m_k(j)\\]\n\n\nVariance for axis \\(k\\)\nNone\n\\(sR^2_k(j) = \\frac{2\\mu_k}{n} s^2_k(j)\\)\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\nusing C score\n\n\n\n\n\n\n\n\n\n\nRows (sites)\nColumns (species)\n\n\n\n\nMean for axis \\(k\\)\n\\[mC_k(i) = \\frac{\\sqrt{2 \\mu_k}}{\\sqrt{n}} m_k(i) - \\frac{1}{\\sqrt{n}} LC1_k(i)\\]\n\\[mC_k(j) = \\frac{\\sqrt{2}}{\\sqrt{n \\mu_k}} m_k(j)\\]\n\n\nVariance for axis \\(k\\)\n\\(sC^2_k(i) = \\frac{2\\mu_k}{n} s^2_k(i)\\)\nNone\n\n\nCovariance between axes \\(k\\), \\(l\\)\n\n\n\n\n\n\n\n\nFor rows = sites (group per row)\nIn this section, we compute means and variances per row (for sites).\n\nscoreC\nBelow is a graphical illustration of scoreC grouped by rows:\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colspp,\n        plabels.col = params$colsite, \n        main = \"With C score (points = species scores)\")\n\n\n\n\nWe compute the following mean: \\(mC_k(i) = \\frac{1}{y_{i\\cdot}} \\sum_{j = 1}^c y_{ij} \\text{scoreC}_k(i,j)\\). To compute these conditional means, we use the meanfacwt function from the ade4 package.\n\nmrowsC &lt;- meanfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nThen we compare this to a score obtained from CCA.\n\nmrowsC/(cca$ls * 1/sqrt(n))\n\n   Axis1 Axis2 Axis3 Axis4 Axis5 Axis6\n1      1     1     1    -1     1     1\n2      1     1     1    -1     1     1\n3      1     1     1    -1     1     1\n4      1     1     1    -1     1     1\n5      1     1     1    -1     1     1\n6      1     1     1    -1     1     1\n7      1     1     1    -1     1     1\n8      1     1     1    -1     1     1\n9      1     1     1    -1     1     1\n10     1     1     1    -1     1     1\n11     1     1     1    -1     1     1\n12     1     1     1    -1     1     1\n13     1     1     1    -1     1     1\n14     1     1     1    -1     1     1\n15     1     1     1    -1     1     1\n16     1     1     1    -1     1     1\n17     1     1     1    -1     1     1\n18     1     1     1    -1     1     1\n19     1     1     1    -1     1     1\n20     1     1     1    -1     1     1\n21     1     1     1    -1     1     1\n22     1     1     1    -1     1     1\n23     1     1     1    -1     1     1\n24     1     1     1    -1     1     1\n25     1     1     1    -1     1     1\n26     1     1     1    -1     1     1\n\n\n??????? axis 4 ?????\n\nmrowsC[, 1:k]/(mrowsRC %*% diag(sqrt(2*mu_CCA/n)) - 1/sqrt(n)*cca$l1)\n\n   RS1 RS2 RS3          RS4 RS5 RS6\n1    1   1   1   0.09963914   1   1\n2    1   1   1   0.14907635   1   1\n3    1   1   1   1.25974578   1   1\n4    1   1   1   0.14027240   1   1\n5    1   1   1   0.09215390   1   1\n6    1   1   1  -0.12717730   1   1\n7    1   1   1  -0.02156703   1   1\n8    1   1   1   0.16043829   1   1\n9    1   1   1 -27.85047682   1   1\n10   1   1   1   0.11861683   1   1\n11   1   1   1  -0.05434566   1   1\n12   1   1   1   0.29479392   1   1\n13   1   1   1   0.42847770   1   1\n14   1   1   1  -0.15449359   1   1\n15   1   1   1  -0.04815589   1   1\n16   1   1   1   0.69954078   1   1\n17   1   1   1   0.05783956   1   1\n18   1   1   1   0.13425888   1   1\n19   1   1   1   0.49606870   1   1\n20   1   1   1   0.29537502   1   1\n21   1   1   1   0.15333987   1   1\n22   1   1   1   0.88218079   1   1\n23   1   1   1   0.16678695   1   1\n24   1   1   1   0.45600697   1   1\n25   1   1   1  -4.87670247   1   1\n26   1   1   1   5.94689846   1   1\n\n\nNow let’s compute the variance of scoreC per row:\n\nvarrowsC &lt;- varfacwt(scoreC, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nCompare it to the variance of the RC score:\n\nvarrowsC[, 1:ncol(varrowsRC)]/(varrowsRC %*% diag(2*mu_CCA/n))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\nWe can use this relationship to find the formula using CCA scores:\n\nvarrowsC_CCA &lt;- matrix(nrow = r, \n                       ncol = k)\n\nfor (i in 1:r) {\n  # Get CA scores for site i\n  Li &lt;- cca$ls[i, ]\n  \n  # Compute the part with the sum on Cj\n  # we add all coordinates Cj^2 weighted by the number of observations on site i\n  sumCj &lt;- t(Y[i, ]) %*% as.matrix(cca$co)^2\n\n  # Fill i-th row with site i variance along each axis\n  varrowsC_CCA[i, ] &lt;- 1/(n*lambda_CCA)*((1/yi_[i])*sumCj - lambda_CCA*as.numeric(Li)^2)\n}\n\n\nvarrowsC[, 1:ncol(varrowsRC)]/varrowsC_CCA\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\n\n\nscoreR\nNow, we compute the mean per row (site) from the row (sites) scores.\nBelow is a graphical illustration of scoreR grouped by rows:\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = params$colsite,\n        plabels.col = params$colsite, \n        main = \"With R score (points = sites scores)\")\n\n\n\n\nAll points of the same site ares superimposed.\n\nmrowsR &lt;- meanfacwt(scoreR, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nmrowsR/(cca$l1*1/sqrt(n))\n\n   RS1 RS2 RS3 RS4 RS5 RS6\n1    1   1   1  -1   1   1\n2    1   1   1  -1   1   1\n3    1   1   1  -1   1   1\n4    1   1   1  -1   1   1\n5    1   1   1  -1   1   1\n6    1   1   1  -1   1   1\n7    1   1   1  -1   1   1\n8    1   1   1  -1   1   1\n9    1   1   1  -1   1   1\n10   1   1   1  -1   1   1\n11   1   1   1  -1   1   1\n12   1   1   1  -1   1   1\n13   1   1   1  -1   1   1\n14   1   1   1  -1   1   1\n15   1   1   1  -1   1   1\n16   1   1   1  -1   1   1\n17   1   1   1  -1   1   1\n18   1   1   1  -1   1   1\n19   1   1   1  -1   1   1\n20   1   1   1  -1   1   1\n21   1   1   1  -1   1   1\n22   1   1   1  -1   1   1\n23   1   1   1  -1   1   1\n24   1   1   1  -1   1   1\n25   1   1   1  -1   1   1\n26   1   1   1  -1   1   1\n\n\nThe variance is null.\n\n\n\nFor columns = species (group per column)\n\nscoreC\nWe group the scoreC per species. Below is an illustration:\n\ns.class(scoreC,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colspp,\n        plabels.col = params$colspp, \n        main = \"With C score (points = species scores)\")\n\n\n\n\n\nmcolsC &lt;- meanfacwt(scoreC, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsC/(cca$c1*1/sqrt(n))\n\n     CS1 CS2 CS3 CS4 CS5 CS6\nsp1    1   1   1  -1   1   1\nsp2    1   1   1  -1   1   1\nsp3    1   1   1  -1   1   1\nsp4    1   1   1  -1   1   1\nsp5    1   1   1  -1   1   1\nsp6    1   1   1  -1   1   1\nsp7    1   1   1  -1   1   1\nsp8    1   1   1  -1   1   1\nsp9    1   1   1  -1   1   1\nsp10   1   1   1  -1   1   1\nsp11   1   1   1  -1   1   1\nsp12   1   1   1  -1   1   1\nsp13   1   1   1  -1   1   1\nsp14   1   1   1  -1   1   1\nsp15   1   1   1  -1   1   1\nsp16   1   1   1  -1   1   1\nsp17   1   1   1  -1   1   1\nsp18   1   1   1  -1   1   1\nsp19   1   1   1  -1   1   1\nsp21   1   1   1  -1   1   1\nsp22   1   1   1  -1   1   1\n\n\nThe variance is null.\n\n\nscoreR\nBelow are the scoreR grouped by column:\n\ns.class(scoreR,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$colind),\n        lab = colnames(Y),\n        ppoints.col = params$colsite,\n        plabels.col = params$colspp, \n        main = \"With R score (points = sites scores)\")\n\n\n\n\n\nmcolsR &lt;- meanfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsR/(cca$co*1/sqrt(n))\n\n     Comp1 Comp2 Comp3 Comp4 Comp5 Comp6\nsp1      1     1     1    -1     1     1\nsp2      1     1     1    -1     1     1\nsp3      1     1     1    -1     1     1\nsp4      1     1     1    -1     1     1\nsp5      1     1     1    -1     1     1\nsp6      1     1     1    -1     1     1\nsp7      1     1     1    -1     1     1\nsp8      1     1     1    -1     1     1\nsp9      1     1     1    -1     1     1\nsp10     1     1     1    -1     1     1\nsp11     1     1     1    -1     1     1\nsp12     1     1     1    -1     1     1\nsp13     1     1     1    -1     1     1\nsp14     1     1     1    -1     1     1\nsp15     1     1     1    -1     1     1\nsp16     1     1     1    -1     1     1\nsp17     1     1     1    -1     1     1\nsp18     1     1     1    -1     1     1\nsp19     1     1     1    -1     1     1\nsp21     1     1     1    -1     1     1\nsp22     1     1     1    -1     1     1\n\n\n\nvarcolsR &lt;- varfacwt(scoreR, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\n\nvarcolsR/(varcolsRC %*% diag(2*mu_CCA/n))\n\n    X1  X2  X3  X4  X5  X6\n1    1   1   1   1   1   1\n2    1   1   1   1   1   1\n3    1   1   1   1   1   1\n4    1   1   1   1   1   1\n5    1   1   1   1   1   1\n6    1   1   1   1   1   1\n7  NaN NaN NaN NaN NaN NaN\n8    1   1   1   1   1   1\n9    1   1   1   1   1   1\n10   1   1   1   1   1   1\n11   1   1   1   1   1   1\n12   1   1   1   1   1   1\n13 NaN NaN NaN NaN NaN NaN\n14   1   1   1   1   1   1\n15   1   1   1   1   1   1\n16   1   1   1   1   1   1\n17   1   1   1   1   1   1\n18   1   1   1   1   1   1\n19   1   1   1   1   1   1\n20   1   1   1   1   1   1\n21   1   1   1   1   1   1\n\n\nSimilarly we can use this relationship to compute the variance directly from the CCA scores (see in table)."
  },
  {
    "objectID": "recscal_cca.html#tests",
    "href": "recscal_cca.html#tests",
    "title": "Reciprocal scaling with CCA",
    "section": "Tests",
    "text": "Tests\n\nFor rows = sites\nWe define the “new” RC score \\(H2\\) in which we replace \\(LC_k(i)\\) with \\(L_k(i)\\). Then, this should help to get the mean for the rows (which are at the mean of the \\(CC1_k(j)\\)).\n\\[\nH2_k(i, j) = \\frac{L_k(i) + CC_k(j)}{\\sqrt{2 \\lambda_k \\mu_k}}\n\\]\n\n# Initialize results matrix\nH2 &lt;- matrix(nrow = nrow(Yfreq0), \n             ncol = length(lambda_CCA))\n\nfor (kl in 1:length(lambda_CCA)) { # For each axis\n  ind &lt;- 1 # initialize row index\n  for (obs in 1:nrow(Yfreq0)) { # For each observation\n    i &lt;- Yfreq0$row[obs]\n    j &lt;- Yfreq0$col[obs]\n    H2[ind, kl] &lt;- (cca$ls[i, kl] + cca$co[j, kl])/sqrt(2*lambda_CCA[kl]*mu_CCA[kl])\n    ind &lt;- ind + 1\n  }\n}\n\n\nmultiplot(indiv_row = H2, \n          indiv_row_lab = paste0(\"site \", Yfreq0$row, \"/\", Yfreq0$col),\n          row_color = \"black\", eig = lambda_CCA)\n\nWarning: ggrepel: 188 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\ns.class(H2,\n        wt = Yfreq0$Freq,\n        fac = as.factor(Yfreq0$row),\n        ppoints.col = \"black\",\n        plabels.col = params$colsite, \n        main = \"With H2 score (points = correspondences)\")\n\n\n\n\nWe compute the mean and variance per site and compare them to the scores of CCA:\n\nmrowsH2 &lt;- meanfacwt(H2, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\nvarrowsH2 &lt;- varfacwt(H2, fac = Yfreq0$row, wt = Yfreq0$Freq)\n\n\nmrowsH2/(as.matrix(cca$ls) %*% diag(sqrt(mu_CCA/(2*lambda_CCA))))\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\nvarrowsH2/varrowsRC\n\n   X1 X2 X3 X4 X5 X6\n1   1  1  1  1  1  1\n2   1  1  1  1  1  1\n3   1  1  1  1  1  1\n4   1  1  1  1  1  1\n5   1  1  1  1  1  1\n6   1  1  1  1  1  1\n7   1  1  1  1  1  1\n8   1  1  1  1  1  1\n9   1  1  1  1  1  1\n10  1  1  1  1  1  1\n11  1  1  1  1  1  1\n12  1  1  1  1  1  1\n13  1  1  1  1  1  1\n14  1  1  1  1  1  1\n15  1  1  1  1  1  1\n16  1  1  1  1  1  1\n17  1  1  1  1  1  1\n18  1  1  1  1  1  1\n19  1  1  1  1  1  1\n20  1  1  1  1  1  1\n21  1  1  1  1  1  1\n22  1  1  1  1  1  1\n23  1  1  1  1  1  1\n24  1  1  1  1  1  1\n25  1  1  1  1  1  1\n26  1  1  1  1  1  1\n\n\nHowever, the mean/variance per species is meaningless here.\n\nmcolsH2 &lt;- meanfacwt(H2, fac = Yfreq0$colind, wt = Yfreq0$Freq)\nvarcolsH2 &lt;- varfacwt(H2, fac = Yfreq0$colind, wt = Yfreq0$Freq)\n\nmcolsH2/cca$co\n\n        Comp1    Comp2    Comp3       Comp4      Comp5      Comp6\nsp1  2.204927 2.214188 3.033045  2.84939410   9.599730  57.187463\nsp2  2.292703 2.759724 2.732078  3.50121666   6.790996   7.094938\nsp3  2.038055 2.218691 7.394548  2.98424261   5.120691   9.019759\nsp4  2.043008 2.028701 2.922493  2.98096628   5.569064   7.903319\nsp5  1.854812 2.515655 1.892381 -2.41233483   6.596884   6.916464\nsp6  2.099441 1.691536 1.579981  3.88945766   3.281467  -8.867692\nsp7  2.417125 1.099654 2.531431  5.63440402   5.526149   9.326447\nsp8  2.688827 2.452282 2.331410  2.23407070   8.627137   7.315956\nsp9  1.878870 2.357545 2.590693  2.93413118   5.070225   6.221136\nsp10 1.968900 2.679521 2.402911  3.85373483   6.925532   5.598789\nsp11 2.443190 2.749714 3.074070  4.66511345   6.134031   8.085768\nsp12 2.122282 2.265638 2.870196  3.65703158  24.337013   5.473179\nsp13 2.579059 1.167765 3.330972  2.84273353   6.972203 -49.776718\nsp14 2.055910 1.616859 2.196444  3.33736859   5.602885   5.266113\nsp15 2.289341 3.455500 2.921559 -0.05911166  -0.541863   5.415114\nsp16 2.503668 3.493476 3.887590  2.68787715 -33.273799   8.738308\nsp17 2.053918 2.606138 2.696418  2.63123598   4.974831   7.132595\nsp18 2.136156 2.184527 2.913183  3.21802069   4.316072   9.149164\nsp19 2.345203 1.846607 2.512503  4.61801260   6.012300   3.312290\nsp21 1.835712 2.512696 3.777919  2.73235559   5.961087  14.924682\nsp22 1.999947 2.082287 2.353229 -1.64401094   4.074915  -7.733470\n\nvarcolsH2/varcolsRC\n\n            X1           X2        X3        X4         X5          X6\n1   1.06510099   1.28338143 0.9968892 1.8783638  3.0281093   1.8926897\n2   0.76319303   1.58662753 1.2072889 0.9761483  5.3943004   2.4378017\n3   0.94075445   0.22277106 0.3740693 0.4458427  5.2134738 206.3467611\n4   1.82796063   1.26736570 1.1172710 1.8223508  5.0252265   4.1099058\n5   0.26141856   0.59946940 0.7285742 2.6626261 66.8787701   0.8151891\n6   1.08129630   1.27404278 1.0479188 1.6857533  2.2842158   2.3137396\n7          NaN          NaN       NaN       NaN        NaN         NaN\n8   1.22909000   0.79894351 2.1249995 1.3039092  2.3466962   3.0797365\n9   0.45585849   0.40004426 4.0809608 0.5725448  0.9045940   2.0419116\n10  1.29801206   1.85864705 1.2502562 2.0021665  3.5598796   3.9077261\n11  0.99192984   0.87027258 0.7178052 1.7455824  2.3503642   2.0851215\n12  1.79936920   1.76448991 2.1663448 1.2382071  2.7083390   2.2500473\n13         NaN          NaN       NaN       NaN        NaN         NaN\n14  0.07474319 103.04431697 0.2264867 0.2873537  0.2298883   1.4471310\n15 23.41075227   0.60430791 3.7474804 0.1828772  2.5384605  38.9563104\n16  6.92953611   0.07789058 3.0039412 0.7543632  9.8005577   1.2840238\n17  2.67129153   0.35939661 1.2802335 1.0029803  1.0071618   1.8968154\n18  1.25065759   2.70457580 1.7160757 1.1141613  2.2687371   1.8856903\n19  1.18649678   1.17954097 0.9611250 2.0050774  1.7043000   2.5101147\n20  0.72585943   0.45927710 0.4740258 5.4316998  6.9768796   2.2908477\n21  6.81766645   1.45963901 2.6966869 1.0689390  2.1683218   1.9424546"
  }
]