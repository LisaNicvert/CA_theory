[
  {
    "objectID": "CA.html",
    "href": "CA.html",
    "title": "Correspondence analysis (CA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(gridExtra)\nsource(here(\"functions/plot.R\"))\nThe contents of this page relies heavily on (Legendre and Legendre 2012)."
  },
  {
    "objectID": "CA.html#introduction",
    "href": "CA.html#introduction",
    "title": "Correspondence analysis (CA)",
    "section": "Introduction",
    "text": "Introduction\nCorrespondence analysis (CA) was developed independently by several authors between the 1930s and 1960s. It has been mainly applied to analysis of ecological data tables (species \\(\\times\\) environment) such as the bat data we will analyze here.\nNotably, Hill discovered it in 1973 with an iterative method that he called reciprocal averaging. It involves ordering species with sites initially positioned randomly, reciprocally order sites with species, etc. This iterative procedure converges to reach the same results as what is achieved with CA’s first axis.\nCA is designed to analyze contingency tables (count tables) such \\(Y\\):\n\n\n\n\n\nHere is a preview of \\(Y\\) with our example dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n4\n0\n0\n0\n0\n2\n0\n4\n0\n2\n0\n4\n0\n0\n0\n0\n1\n5\n0\n0\n2\n\n\n2\n0\n0\n1\n0\n2\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n5\n1\n5\n1\n\n\n4\n0\n0\n0\n0\n0\n0\n2\n0\n0\n3\n0\n0\n0\n0\n0\n1\n1\n0\n0\n1\n\n\n2\n0\n1\n5\n0\n0\n0\n5\n0\n1\n1\n4\n0\n0\n0\n1\n2\n2\n0\n0\n2\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n2\n0\n0\n0\n4\n0\n1\n10\n3\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n4\n0\n2\n2\n4\n0\n0\n0\n0\n2\n1\n2\n0\n1\n\n\n5\n5\n0\n0\n1\n1\n0\n1\n0\n3\n0\n5\n0\n0\n0\n0\n0\n0\n1\n5\n1\n\n\n4\n0\n0\n1\n0\n2\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n3\n0\n0\n0\n1\n0\n0\n0\n0\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n5\n0\n4\n0\n1\n2\n0\n0\n0\n0\n0\n0\n1\n2\n0\n0\n\n\n4\n0\n1\n1\n0\n1\n0\n3\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n1\n0\n3\n2\n1\n2\n0\n0\n0\n0\n0\n0\n1\n3\n0\n0\n\n\n4\n2\n0\n1\n0\n0\n0\n2\n0\n2\n2\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n4\n0\n0\n1\n0\n2\n0\n2\n2\n2\n1\n1\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n4\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n5\n1\n0\n3\n0\n2\n0\n2\n1\n0\n2\n0\n0\n0\n0\n0\n0\n3\n1\n0\n0\n\n\n3\n5\n0\n4\n0\n2\n0\n5\n0\n4\n2\n0\n0\n1\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n2\n0\n7\n0\n1\n1\n0\n0\n4\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n6\n0\n0\n2\n0\n1\n0\n0\n0\n1\n3\n0\n0\n0\n0\n0\n0\n0\n3\n3\n0\n\n\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n\nThis table represents the abundance of different bird species (columns) at different sites (rows) in New Zealand.\nMore generally CA, can be used to analyze tables which are dimensionnally homogeneous and contain no negative values.\nCA preserves \\(\\chi^2\\) distances \\(D\\) between rows and columns of the contingency table:\n\\[\nD(x_1, x_2) = \\sqrt{\\sum_{j = 1}^p \\frac{1}{y_{\\cdot j}/y_{\\cdot \\cdot}}\\left(\\frac{y_{1j}}{y_{1\\cdot}} -  \\frac{y_{2j}}{y_{2\\cdot}}\\right)^2}\n\\]\nWhere \\(x_1\\) and \\(x_2\\) represent two items of the rows/columns. \\(p\\) is the number of rows (if \\(x_1\\) and \\(x_2\\) are items of columns) or columns else.\n\\(y_{\\cdot j}\\) represent either:\n\nif \\(x_1\\) and \\(x_2\\) are items of the columns: the sum of the \\(j\\)-th row. For a species x environment table, it is the total number of individuals in the \\(j\\)-th site.\nif \\(x_1\\) and \\(x_2\\) are items of the rows: the sum of the \\(j\\)-th column. For a species x environment table, it is the total number of individuals of the \\(j\\)-th species.\n\n\\(y_{\\cdot \\cdot}\\) is the sum of all individuals of the table.\n\\(\\frac{y_{1j}}{y_{1\\cdot}}\\) are relative frequencies of individuals per rows (if \\(x_1\\) and \\(x_2\\) are items of the rows) or columns.\nFor example, we compute the \\(\\chi^2\\) distance between sp1 and sp2:\n\n# Get how much each site contributed to the total count of species\nfreq &lt;- apply(Y, 2, FUN = function(x) x/sum(x))\n\n# Get total number of individuals of bats in all sites\n(ytot &lt;- sum(Y))\n\n[1] 493\n\nsqrt( sum(1/(rowSums(Y)/ytot)*(freq[, \"sp1\"] - freq[, \"sp2\"])^2 ) )\n\n[1] 2.090546\n\n\nAnd between sites 1 and 2:\n\n# Get the relative composition of species for each site\nfreq &lt;- t(apply(Y, 1, FUN = function(x) x/sum(x)))\n\nsqrt( sum(1/(colSums(Y)/ytot)*(freq[\"1\",] - freq[\"2\", ])^2 ) )\n\n[1] 2.563363"
  },
  {
    "objectID": "CA.html#computation",
    "href": "CA.html#computation",
    "title": "Correspondence analysis (CA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nGiven a data matrix \\(Y\\), we “center-scale” this matrix (\\(\\bar{Q}\\)).\nWe can perform the SVD of \\(\\bar{Q}\\):\n\\[\n\\hat{Q} = \\hat{U} \\Delta U'\n\\]\n\\(U\\) (\\(c \\times c\\)) contains the loadings of the columns (species) of the contingency table.\n\\(\\hat{U}\\) (\\(r \\times c\\)) contains the loadings of the rows (sites) of the contingency table.\nThere are \\(\\min(c-1, r-1)\\) non-null eigenvalues. The CA eigenvalues are the squares of the SVD eigenvalues: \\(\\Lambda = \\Delta^2\\).\nAlso, there is a link between \\(\\hat{U}\\) and \\(U\\): \\[\n\\hat{U} = \\bar{Q}U\\Lambda^{-1/2}\n\\]\nand\n\\[\nU = \\bar{Q}'\\hat{U}\\Lambda^{-1/2}\n\\]\n\n\n\nTransform the table\nWe transform values of the contingency table \\(Y\\) with counts \\(f_{ij}\\) into proportions \\(p_{ij}\\):\n\\[\nP = Y/f_{\\cdot \\cdot}\n\\]\nWith our example data:\n\nP &lt;- Y/sum(Y)\n\nThen we transform values of this table into a quantity related to \\(\\chi^2\\) values \\(\\bar{Q}\\):\n\\[\n\\bar{Q} = [\\bar{q}_{ij}] = \\left[ \\frac{p_{ij} - p_{i\\cdot} p_{\\cdot j}}{\\sqrt{p_{i\\cdot} p_{\\cdot j}}} \\right]\n\\]\nThe \\(\\bar{q}_{ij}\\) values are equal to the \\(\\chi\\) values, a constant apart: \\(\\bar{q}_{ij} = \\chi_{ij}/\\sqrt{f_{\\cdot \\cdot}}\\).\nWith our data:\n\n# Initialize Qbar matrix\nQbar &lt;- matrix(ncol = ncol(Y), nrow = nrow(Y))\ncolnames(Qbar) &lt;- colnames(Y)\nrownames(Qbar) &lt;- rownames(Y)\n\nfor(i in 1:nrow(Y)) { # For each row\n  for (j in 1:ncol(Y)) { # For each column\n    # Do the sum\n    pi_ &lt;- sum(P[i, ])\n    p_j &lt;- sum(P[, j])\n    \n    # Compute the transformation\n    Qbar[i, j] &lt;- (P[i, j] - (pi_*p_j))/sqrt(pi_*p_j)\n  }\n}\n\nWe could also do this by matrix multiplication:\n\\[\n\\bar{Q} = D(p_{i\\cdot})^{-1/2} P D(p_{\\cdot j})^{-1/2}\n\\]\nIn (Carroll, Green, and Schaffer 1986), the formula is:\n\\[\n\\bar{Q} = D(y_{i\\cdot})^{-1/2} Y D(y_{\\cdot j})^{-1/2}\n\\]\nwhere matrices \\(D(p_{i \\cdot})\\) and \\(D(p_{\\cdot j})\\) are the diagonal matrices with the row and columns sums of \\(P\\) (respectively) and \\(D(y_{i \\cdot})\\) and \\(D(y_{\\cdot j})\\) are he equivalent for matrix \\(Y\\).\nNB: I could not verify this result numerically, since here \\(\\bar{Q}\\) is not equal to \\(D(p_{i \\cdot})^{-1/2} Q D(p_{\\cdot j})^{-1/2}\\), as in (Carroll, Green, and Schaffer 1987).\n\n# Define weights matrices\nDpi_ &lt;- diag(rowSums(P))\nDp_j &lt;- diag(colSums(P))\n\n# Also define a variable for just the sums for easier manipulation\ndpi_ &lt;- rowSums(P)\ndp_j &lt;- colSums(P)\n\n# Define weights matrices\nDyi_ &lt;- diag(rowSums(Y))\nDy_j &lt;- diag(colSums(Y))\n\n# Also define a variable for just the sums for easier manipulation\ndyi_ &lt;- rowSums(Y)\ndy_j &lt;- colSums(Y)\n\n\n\nSingular value decomposition of \\(\\bar{Q}\\)\n\\[\n\\bar{Q} = \\hat{U}WU'\n\\]\nWhere \\(\\bar{Q}\\) is \\(r \\times c\\), \\(\\hat{U}\\) is \\(r \\times c\\), \\(W\\) is a \\(c \\times c\\) diagonal matrix (assuming \\(r \\geq c\\); the table can be transposed to meet this condition) and \\(U'\\) is \\(c \\times c\\).\nNote that the last eigenvalue of this SVD will always be null (due to the centering).\n\nsv &lt;- svd(Qbar)\n\n# Eigenvalues\n(delta &lt;- sv$d) # Last eigenvalue is zero\n\n [1] 5.498025e-01 4.925288e-01 4.329553e-01 4.040318e-01 3.433964e-01\n [6] 3.150413e-01 2.883515e-01 2.863913e-01 2.408812e-01 2.195224e-01\n[11] 1.962294e-01 1.587138e-01 1.429179e-01 1.242514e-01 1.095957e-01\n[16] 9.878630e-02 7.702202e-02 6.088389e-02 5.470965e-02 4.087652e-02\n[21] 6.653482e-17\n\nlambda &lt;- delta^2\nLambda &lt;- diag(lambda)\n \n# Eigenvectors\nUhat &lt;- sv$u\nU &lt;- sv$v\n\nThis SVD is equivalent to a diagonalization: with the SVD, we can rewrite \\(\\bar{Q}' \\bar{Q}\\):\n\\[\n\\bar{Q}' \\bar{Q} = U W' \\hat{U'} \\hat{U} W U'\n\\]\nWe have \\(\\hat{U}' \\hat{U} = I\\) (because \\(\\hat{U}\\) is orthonormal), so:\n\\[\n\\bar{Q}' \\bar{Q} =  U W' W U'\n\\]\nIf we rewrite \\(W' W\\) as \\(\\Lambda\\) (so \\(W = \\Lambda^{1/2}\\)), and since \\(U' = U^{-1}\\) (\\(U\\) is orthonormal), then we can write this as a diagonalization:\n\\[\n\\bar{Q}' \\bar{Q} =  U \\Lambda U^{-1}\n\\]\nSimilarly, we can rewrite \\(\\bar{Q} \\bar{Q}'\\):\n\\[\n\\bar{Q} \\bar{Q}' =  \\hat{U} \\Lambda \\hat{U}^{-1}\n\\]\n\n# Diagonalize Q'Q ---\ndg1 &lt;- eigen(t(Qbar) %*% Qbar)\n\n# Eigenvalues are equal to the square roots of SVD eigenvalues\nall((dg1$values - lambda) &lt; 10e-10)\n\n[1] TRUE\n\n# Eigenvectors are equal to U\nall(abs(dg1$vectors/U) - 1 &lt; 10e-10)\n\n[1] TRUE\n\n\n\n# Diagonalize QQ' ---\ndg2 &lt;- eigen(Qbar %*% t(Qbar))\n\n# Eigenvalues are equal to the square roots of SVD eigenvalues\nall((dg1$values - lambda) &lt; 10e-10)\n\n[1] TRUE\n\n# Eigenvectors are equal to Uhat\nall(abs(dg2$vectors[, 1:(c-1)]/Uhat[, 1:(c-1)]) - 1 &lt; 10e-10)\n\n[1] TRUE"
  },
  {
    "objectID": "CA.html#scalings",
    "href": "CA.html#scalings",
    "title": "Correspondence analysis (CA)",
    "section": "Scalings",
    "text": "Scalings\n\n\n\n\n\n\nTL;DR\n\n\n\nTo plot rows and columns on separate plots, one can plot the eigenvectors \\(\\hat{U}\\) (rows = sites) and \\(U\\) (columns = species).\nTo plot columns and rows individuals on the same biplot, different scalings have been proposed. For sites (rows), these scalings are equal to \\(\\hat{S}_i = D(p_{i \\cdot})^{-1/2} \\hat{U} \\Delta^\\alpha\\) (with \\(\\alpha =\\) 1, 0 or 1/2).\nFor species (columns), these scalings are equal to \\(\\hat{S}_i = D(p_{\\cdot j})^{-1/2} U \\Delta^{1-\\alpha}\\).\n\nScaling type 1 (\\(\\alpha = 1\\)): this scaling preserves the distances between rows. Rows (sites) are represented with \\(F = D(p_{i \\cdot})^{-1/2} \\hat{U} \\Lambda^{1/2}\\) and species (columns) with \\(V = D(p_{\\cdot j})^{-1/2} U\\).\nScaling type 2 (\\(\\alpha = 0\\)): this scaling preserves distances between columns. Rows (sites) are represented with \\(\\hat{V} = D(p_{i \\cdot})^{-1/2} \\hat{U}\\) and species (columns) with \\(\\hat{F} = D(p_{\\cdot j})^{-1/2} U \\Lambda^{1/2}\\).\nScaling type 3 (\\(\\alpha = 1/2\\)): this scaling is a compromise between scalings type 1 and 2. Rows (sites) are represented with \\(\\hat{S}_3 = D(p_{i \\cdot})^{-1/2} \\hat{U} \\Lambda^{1/4}\\) and species (columns) with \\(S_3 = D(p_{\\cdot j})^{-1/2} U \\Lambda^{1/4}\\).\n\nAs noted in (Carroll, Green, and Schaffer 1987), if we plot distances of different scalings on the same biplot, we cannot interpret between-sets distances, but within-sets distances are still be interpretable. This is what the scaling type 4 described below does and this scaling is what (Carroll, Green, and Schaffer 1987) refers to.\n\n\nLet’s perform a CA with ade4 to check results later.\n\nca &lt;- dudi.coa(Y, \n               scannf = FALSE, \n               nf = min(r, c))\n\n\nNo scaling\nOne can represent the eigenvectors directly without scaling to display them on separate plots.\n\n\nCode\n# Plot sites ---\ng1 &lt;- multiplot(indiv_row = Uhat, \n          indiv_row_lab = rownames(Y), \n          row_color = params$colsite,\n          eig = lambda)\n\n# Plot species ---\ng2 &lt;- multiplot(indiv_row = U, \n          indiv_row_lab = colnames(Y), \n          row_color = params$colspp,\n          eig = lambda)\n\ngrid.arrange(grobs = list(g1, g2), nrow = 1)\n\n\n\n\n\n\n\nScaling type 1\nThis scaling preserves the row \\(\\chi^2\\) distances and is useful to interpret distances between row individuals (sites). In this scaling, the rows individuals are positioned at the barycentre of the corresponding column (species) individuals.\nFor that, we use:\n\n\\(F = D(p_{\\cdot j})^{-1/2} \\hat{U} \\Lambda^{1/2}\\) (rows = sites)\n\\(V = D(p_{\\cdot j})^{-1/2} U\\) (columns = species)\n\n\n# Sites\nF_ &lt;- diag(dpi_^(-1/2)) %*% Uhat %*% Lambda^(1/2)\n\n# Species\nV &lt;- diag(dp_j^(-1/2)) %*% U\n\nNB: \\(F\\) (sites scores) can also be computed from the species scores, since there is a correspondence between \\(U\\) and \\(\\hat{U}\\). This shows better the relationship between sites and species scores (sites are at the barycentre of their species with this scaling).\nNB2: I could not find back the formula in (Legendre and Legendre 2012) for \\(F = D(p_{i\\cdot})^{-1} Q V\\) and \\(\\hat{F} = D(p_{\\cdot j})^{-1} Q' \\hat{V}\\) (p 479). Indeed, for these formulas to be valid, we need \\(\\bar{Q} = D(p_{i \\cdot})^{-1/2} Q D(p_{\\cdot j})^{-1/2}\\), as in (Carroll, Green, and Schaffer 1987), but it is not the case here.\n\n# Compute sites coordinates using species coordinates\nF2 &lt;- diag(dpi_^(-1/2)) %*% Qbar %*% U\n\n# Check that this corresponds to F_ cmputed above\nall(F_[, 1:(c-1)]/F2[, 1:(c-1)] - 1 &lt; 10e-10)\n\n[1] TRUE\n\n\n\n\nCode\nmultiplot(indiv_row = F_, indiv_col = V, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\n\n\nScaling type 2\nThis preserves \\(\\chi^2\\) distances between species on the plot. Here, species are positioned at the centroid of sites.\nWe use:\n\n\\(\\hat{V} = D(p_{i\\cdot})^{-1/2} \\hat{U}\\) (rows = sites)\n\\(\\hat{F} = D(p_{\\cdot j})^{-1/2} U \\Lambda^{1/2}\\) (columns = species)\n\n\n# Sites\nVhat &lt;- diag(dpi_^(-1/2)) %*% Uhat\n\n# Species\nFhat &lt;- diag(dp_j^(-1/2)) %*% U %*% Lambda^(1/2)\n\nNB: like \\(F\\), \\(\\hat{F}\\) (species scores) can also be computed from the sites scores. This shows better the relationship between species and sites scores (species are at the barycentre of their sites with this scaling).\n\n# Compute sites coordinates using species coordinates\nFhat2 &lt;- diag(dp_j^(-1/2)) %*% t(Qbar) %*% Uhat\n\n# Check that this corresponds to Fhat cmputed above\nall(Fhat[, 1:(c-1)]/Fhat2[, 1:(c-1)] - 1 &lt; 10e-10)\n\n[1] TRUE\n\n\n\n\nCode\nmultiplot(indiv_row = Vhat, indiv_col = Fhat, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\n\n\nScaling type 3\nIt is a compromise between scalings 1 and 2. It preserves none of the \\(\\chi^2\\) distances.\nWe use:\n\n\\(\\hat{S}_3 = D(p_{i\\cdot})^{-1/2} \\hat{U} \\Lambda^{1/4}\\) (for sites)\n\\(S_3 = D(p_{\\cdot j})^{-1/2} U \\Lambda^{1/4}\\) (for species).\n\n\ns3_r &lt;- diag(dpi_^(-1/2)) %*% Uhat %*% Lambda^(1/4)\ns3_c &lt;- diag(dp_j^(-1/2)) %*% U %*% Lambda^(1/4)\n\n\n\nCode\nmultiplot(indiv_row = s3_r, indiv_col = s3_c, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)\n\n\n\n\n\n\n\nScaling type 4\nUse \\(F\\) (sites) and \\(\\hat{F}\\) (species). Then, both \\(\\chi^2\\) distances are preserved. It is useful for a table crossing two factors.\n\n\nCode\nmultiplot(indiv_row = F_, indiv_col = Fhat, \n          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n          row_color = params$colsite, col_color = params$colspp,\n          eig = lambda)"
  },
  {
    "objectID": "CA.html#interpretation",
    "href": "CA.html#interpretation",
    "title": "Correspondence analysis (CA)",
    "section": "Interpretation",
    "text": "Interpretation\nUsing the “transition formula” defined above (\\(\\hat{U} = \\bar{Q}U\\Lambda^{-1/2}\\)), we can relate \\(V\\) and \\(\\hat{V}\\) with the following equation:\n\\[\n\\hat{V} \\Lambda^{1/2} = D(p_{i\\cdot})^{-1/2}\\bar{Q}D(p_{\\cdot j})^{1/2}V\n\\]\nThis equation relates the ordination of rows (sites) (\\(\\hat{V}\\)) to the ordination of columns (species) (\\(V\\)). The “conversion factor” is \\(\\Lambda^{1/2}\\), which translates to \\(\\sqrt{\\lambda_h}\\) along principal axis \\(h\\).\nIndeed, the eigenvalue \\(\\lambda_h\\) is a measure of the correlation of the rows and columns ordinations along axis \\(h\\).\nIf species have a unimodal (bell-shaped) response along the gradient defined by the sites ordination along a given axis, then their position should be close to their niche optimum.\nDepending on he position of, say, species, in the multivariate space, there are several interpretations:\n\nspecies that are absent from most sites: often at the edge, close to a site where they happen to be present. They have little influence on the analysis.\nspecies that are in the center: either have their optimum there, they have a multimodal niche or their niche is not influenced by the latent variables of the ordination axes.\nspecies found away from the center but not at the edges: more likely to display clear relationships with the axis\n\n\n\n\n\n\n\nNote\n\n\n\nRare species are generally not very interesting because they are exceptions, not a general tendency. So some authors propose strategies to remove them, notably an iterative procedure. First do the complete CA, then remove the species seen one, twice… etc. Note the total inertia and the eigenvalues. When there is a jump, stop.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen there is a succession of species, along an hypothetical gradient, the CA may lead to an arch shape. There are techniques to detrend it, but knowing how to interpret this effect is probably more important."
  },
  {
    "objectID": "CCA.html",
    "href": "CCA.html",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nsource(here(\"functions/plot.R\"))\nlibrary(gridExtra)\nThe contents of this page relies heavily on (Legendre and Legendre 2012)."
  },
  {
    "objectID": "CCA.html#introduction",
    "href": "CCA.html#introduction",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Introduction",
    "text": "Introduction\nCCA is a method of the family of canonical or direct gradient analyses, in which a matrix of predictor variables intervenes in the computation of the ordination vectors.\nCCA is an asymmetric method because the predictor variables and the response variables are not equivalent in the analysis.\nCCA takes two matrices in input:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables \\(E\\) (\\(r \\times l\\))\n\n\n\n\n\n\nHere, \\(Y\\) represents the abundance of different bird species (columns) at different sites (rows):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n4\n0\n0\n0\n0\n2\n0\n4\n0\n2\n0\n4\n0\n0\n0\n0\n1\n5\n0\n0\n2\n\n\n2\n0\n0\n1\n0\n2\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n5\n1\n5\n1\n\n\n4\n0\n0\n0\n0\n0\n0\n2\n0\n0\n3\n0\n0\n0\n0\n0\n1\n1\n0\n0\n1\n\n\n2\n0\n1\n5\n0\n0\n0\n5\n0\n1\n1\n4\n0\n0\n0\n1\n2\n2\n0\n0\n2\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n2\n0\n0\n0\n4\n0\n1\n10\n3\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n4\n0\n2\n2\n4\n0\n0\n0\n0\n2\n1\n2\n0\n1\n\n\n5\n5\n0\n0\n1\n1\n0\n1\n0\n3\n0\n5\n0\n0\n0\n0\n0\n0\n1\n5\n1\n\n\n4\n0\n0\n1\n0\n2\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n3\n0\n0\n0\n1\n0\n0\n0\n0\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n5\n0\n4\n0\n1\n2\n0\n0\n0\n0\n0\n0\n1\n2\n0\n0\n\n\n4\n0\n1\n1\n0\n1\n0\n3\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n1\n0\n3\n2\n1\n2\n0\n0\n0\n0\n0\n0\n1\n3\n0\n0\n\n\n4\n2\n0\n1\n0\n0\n0\n2\n0\n2\n2\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n4\n0\n0\n1\n0\n2\n0\n2\n2\n2\n1\n1\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n4\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n5\n1\n0\n3\n0\n2\n0\n2\n1\n0\n2\n0\n0\n0\n0\n0\n0\n3\n1\n0\n0\n\n\n3\n5\n0\n4\n0\n2\n0\n5\n0\n4\n2\n0\n0\n1\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n2\n0\n7\n0\n1\n1\n0\n0\n4\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n6\n0\n0\n2\n0\n1\n0\n0\n0\n1\n3\n0\n0\n0\n0\n0\n0\n0\n3\n3\n0\n\n\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n\n\n\n\n\n\\(E\\) represents environmental variables (columns) associated to each site (rows).\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n0\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n0\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n0\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n0\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n0\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n0\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n1\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n1\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n1\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n1\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n1\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n1\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- dim(E)[2])\n\n[1] 6"
  },
  {
    "objectID": "CCA.html#computation",
    "href": "CCA.html#computation",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nWe have a data matrix \\(Y\\) (\\(r \\times c\\)) and a matrix \\(E\\) (\\(r \\times l\\)) of predictors variables.\nWe regress \\(\\bar{Q}\\) (“centered” \\(Y\\)) on \\(E_{stand}\\) (which is the centered and scaled \\(E\\) matrix):\n\\[\n\\hat{\\bar{Q}} = D(p_{i\\cdot})^{1/2} E_{stand}B\n\\]\nThen, we diagonalize matrix \\(S_{\\hat{\\bar{Q}}'\\hat{\\bar{Q}}} = \\hat{\\bar{Q}}'\\hat{\\bar{Q}}\\).\n\\[\nS_{\\hat{\\bar{Q}}'\\hat{\\bar{Q}}} =  U \\Lambda U^{-1}\n\\]\nThe matrix \\(U\\) (\\(c \\times \\text{mindim}\\)) contains the loadings of the columns (species) of the contingency table. There are \\(\\text{mindim} = \\min(r-1, c, l)\\) non-null eigenvalues.\nThen, we can find the loadings rows (sites) \\(\\hat{U}\\) (\\(r \\times \\text{mindim}\\)) from the columns (species) loadings using the following formula:\n\\[\n\\hat{U} = \\bar{Q} U \\Lambda^{-1/2}\n\\]\n\n\n\nTransform matrix\nWe start by “centering” the matrix \\(Y\\) to get \\(\\bar{Q}\\) (as with CA).\nHere, we have:\n\n\nCode\nP &lt;- Y/sum(Y)\n\n# Initialize Qbar matrix\nQbar &lt;- matrix(ncol = ncol(Y), nrow = nrow(Y))\ncolnames(Qbar) &lt;- colnames(Y)\nrownames(Qbar) &lt;- rownames(Y)\n\nfor(i in 1:nrow(Y)) { # For each row\n  for (j in 1:ncol(Y)) { # For each column\n    # Do the sum\n    pi_ &lt;- sum(P[i, ])\n    p_j &lt;- sum(P[, j])\n    \n    # Compute the transformation\n    Qbar[i, j] &lt;- (P[i, j] - (pi_*p_j))/sqrt(pi_*p_j)\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n-0.0246174\n-0.0235678\n0.1819102\n0.0177849\n-0.0086058\n0.0190444\n-0.0060852\n0.0389306\n-0.0172115\n0.0177849\n0.0142185\n-0.0285421\n-0.0121704\n-0.0086058\n-0.0172115\n-0.0136069\n-0.0172115\n-0.0425963\n0.0259875\n-0.0227687\n-0.0250899\n\n\n-0.0700532\n-0.0430288\n-0.0192431\n-0.0075494\n-0.0157119\n-0.0362309\n-0.0111100\n0.0317935\n-0.0314238\n-0.0075494\n-0.0702658\n0.0257394\n0.3429284\n-0.0157119\n0.1622254\n0.2201063\n-0.0314238\n0.0004761\n-0.0290665\n-0.0415698\n0.0427538\n\n\n0.0325898\n-0.0342433\n-0.0153141\n0.0216502\n-0.0125039\n-0.0148135\n-0.0088416\n-0.0092517\n-0.0250078\n-0.0160655\n0.0166286\n-0.0414707\n-0.0176832\n-0.0125039\n-0.0250078\n-0.0197704\n-0.0250078\n0.0364300\n0.0331807\n-0.0330822\n0.0191867\n\n\n0.0149125\n-0.0283250\n-0.0126673\n-0.0444862\n-0.0103428\n0.0023441\n-0.0073135\n0.0865729\n0.0773724\n-0.0444862\n-0.0024017\n-0.0343033\n-0.0146270\n-0.0103428\n-0.0206857\n-0.0163535\n-0.0206857\n0.0280484\n-0.0407198\n-0.0273646\n0.0371130\n\n\n0.0381182\n-0.0333300\n-0.0149056\n-0.0135976\n-0.0121704\n-0.0123509\n-0.0086058\n-0.0058019\n-0.0243408\n-0.0523468\n0.0573758\n-0.0403646\n-0.0172115\n-0.0121704\n-0.0243408\n0.0861662\n-0.0243408\n0.0407749\n-0.0055815\n-0.0321998\n0.0216837\n\n\n-0.0648859\n-0.0351329\n-0.0157119\n-0.0184176\n-0.0128287\n0.0201080\n-0.0090713\n0.0163368\n0.0533995\n0.0183431\n-0.0220164\n-0.0425480\n-0.0181425\n-0.0128287\n0.0533995\n-0.0202840\n0.0533995\n0.0003888\n0.0298152\n-0.0339416\n0.1252960\n\n\n-0.0121284\n-0.0384861\n-0.0172115\n-0.0604449\n-0.0140532\n0.0084189\n-0.0099371\n0.0284370\n-0.0281063\n0.0066707\n-0.0628476\n0.1274686\n-0.0198742\n-0.0140532\n-0.0281063\n-0.0222200\n0.0440625\n0.0762434\n-0.0553273\n-0.0371811\n0.0580431\n\n\n-0.0383974\n-0.0342433\n-0.0153141\n-0.0160655\n-0.0125039\n0.0234224\n-0.0088416\n-0.0684866\n-0.0250078\n-0.0537812\n-0.0196452\n0.0074409\n-0.0176832\n-0.0125039\n-0.0250078\n-0.0197704\n-0.0250078\n0.1019773\n-0.0080236\n0.2734875\n0.0191867\n\n\n0.0509731\n-0.0272138\n-0.0121704\n-0.0427410\n-0.0099371\n-0.0421595\n-0.0070266\n0.0201080\n-0.0198742\n-0.0427410\n0.0924907\n-0.0329576\n-0.0140532\n-0.0099371\n-0.0198742\n-0.0157119\n0.0821879\n-0.0079467\n-0.0391223\n-0.0262910\n0.0410427\n\n\n-0.0598219\n-0.0400576\n0.0953134\n0.0982934\n-0.0146270\n-0.0620570\n-0.0103428\n0.0464771\n-0.0292540\n-0.0306717\n-0.0344052\n0.1187362\n-0.0206857\n-0.0146270\n-0.0292540\n0.0645785\n0.1094211\n-0.0163667\n-0.0575865\n-0.0386994\n0.0524857\n\n\n-0.0770633\n-0.0451290\n-0.0201823\n-0.0136415\n-0.0164788\n-0.0409006\n-0.0116523\n0.0221086\n-0.0329576\n-0.0136415\n-0.0186472\n-0.0546539\n-0.0233045\n-0.0164788\n0.2132254\n-0.0260552\n0.0285882\n0.1671166\n0.0289188\n-0.0435988\n-0.0058235\n\n\n-0.0082886\n-0.0376758\n-0.0168491\n-0.0591722\n-0.0137573\n-0.0236147\n-0.0097279\n0.0323248\n-0.0275145\n0.0093869\n0.0044137\n0.1321940\n-0.0194557\n-0.0137573\n-0.0275145\n-0.0217521\n0.1199274\n-0.0383072\n0.0207382\n-0.0363983\n0.0104632\n\n\n-0.0066028\n0.2024052\n-0.0185906\n-0.0652879\n0.1184515\n-0.0329026\n-0.0107333\n-0.0587421\n-0.0303583\n0.0279175\n-0.0678832\n0.1511122\n-0.0214665\n-0.0151791\n-0.0303583\n-0.0240003\n-0.0303583\n-0.0751329\n-0.0258181\n0.2123779\n0.0015805\n\n\n0.0509731\n-0.0272138\n-0.0121704\n0.0047169\n-0.0099371\n0.0540656\n-0.0070266\n-0.0544276\n-0.0198742\n0.0047169\n0.0468471\n-0.0329576\n-0.0140532\n-0.0099371\n-0.0198742\n-0.0157119\n-0.0198742\n-0.0491860\n0.0645729\n-0.0262910\n-0.0289713\n\n\n0.0537748\n-0.0222200\n-0.0099371\n-0.0348979\n0.2418864\n-0.0344230\n-0.0057372\n-0.0444400\n-0.0162272\n0.1394736\n-0.0362851\n0.0484681\n-0.0114743\n-0.0081136\n-0.0162272\n-0.0128287\n-0.0162272\n-0.0401602\n-0.0319432\n-0.0214665\n-0.0236550\n\n\n-0.0105035\n-0.0333300\n-0.0149056\n-0.0523468\n-0.0121704\n0.1447840\n-0.0086058\n0.0550562\n-0.0243408\n-0.0135976\n0.0201080\n-0.0403646\n-0.0172115\n-0.0121704\n-0.0243408\n-0.0192431\n-0.0243408\n-0.0265686\n0.0367519\n-0.0321998\n-0.0354825\n\n\n0.0303585\n-0.0304260\n0.1354643\n-0.0053382\n-0.0111100\n-0.0041026\n-0.0078559\n0.0391481\n0.0690671\n0.0371094\n-0.0496854\n-0.0368477\n-0.0157119\n-0.0111100\n-0.0222200\n-0.0175664\n-0.0222200\n0.0187795\n-0.0437401\n-0.0293943\n-0.0323909\n\n\n0.0325898\n-0.0342433\n-0.0153141\n-0.0160655\n-0.0125039\n-0.0148135\n-0.0088416\n0.0203657\n0.1372137\n-0.0160655\n0.0166286\n-0.0414707\n-0.0176832\n-0.0125039\n-0.0250078\n-0.0197704\n-0.0250078\n-0.0291174\n0.0743850\n-0.0330822\n-0.0364548\n\n\n0.0244779\n0.0976756\n-0.0140532\n-0.0082533\n-0.0114743\n-0.0486815\n-0.0081136\n0.0017021\n-0.0229487\n0.0328465\n0.0277421\n-0.0380561\n-0.0162272\n0.1653023\n-0.0229487\n-0.0181425\n-0.0229487\n-0.0210808\n-0.0002732\n-0.0303583\n-0.0334532\n\n\n0.0189774\n-0.0323909\n-0.0144857\n-0.0109993\n-0.0118275\n0.0306654\n-0.0083633\n-0.0021594\n0.1478436\n0.0288733\n-0.0145459\n0.0124814\n-0.0167266\n-0.0118275\n-0.0236550\n-0.0187009\n-0.0236550\n0.0107528\n-0.0465649\n-0.0312926\n-0.0344828\n\n\n0.0502635\n-0.0314238\n-0.0140532\n-0.0082533\n-0.0114743\n0.1179851\n-0.0081136\n-0.0628476\n-0.0229487\n-0.0493530\n0.1067990\n-0.0380561\n-0.0162272\n-0.0114743\n-0.0229487\n-0.0181425\n-0.0229487\n-0.0567951\n0.0446281\n-0.0303583\n-0.0334532\n\n\n0.0273672\n0.0226022\n-0.0157119\n0.0551038\n-0.0128287\n0.0201080\n-0.0090713\n-0.0125307\n0.0533995\n-0.0551784\n0.0133389\n-0.0425480\n-0.0181425\n-0.0128287\n-0.0256574\n-0.0202840\n-0.0256574\n0.0323326\n-0.0103457\n-0.0339416\n-0.0374018\n\n\n-0.0455868\n0.2024052\n-0.0185906\n0.0589860\n-0.0151791\n-0.0014055\n-0.0107333\n0.0388479\n-0.0303583\n0.0589860\n-0.0081217\n-0.0503435\n-0.0214665\n0.1184515\n-0.0303583\n-0.0240003\n-0.0303583\n-0.0211380\n-0.0597603\n-0.0401602\n-0.0442544\n\n\n0.0089254\n0.0669231\n-0.0172115\n0.1744597\n-0.0140532\n-0.0256018\n0.1941871\n-0.0769723\n-0.0281063\n0.0737863\n0.0017021\n-0.0466090\n-0.0198742\n-0.0140532\n-0.0281063\n-0.0222200\n-0.0281063\n-0.0695595\n0.0179962\n-0.0371811\n-0.0409716\n\n\n0.0562523\n-0.0342433\n-0.0153141\n0.0216502\n-0.0125039\n-0.0148135\n-0.0088416\n-0.0684866\n-0.0250078\n-0.0160655\n0.0529024\n-0.0414707\n-0.0176832\n-0.0125039\n-0.0250078\n-0.0197704\n-0.0250078\n-0.0618911\n0.0743850\n0.1508596\n-0.0364548\n\n\n0.0649207\n-0.0207849\n-0.0092953\n-0.0326440\n-0.0075896\n0.0307943\n-0.0053666\n-0.0415698\n-0.0151791\n-0.0326440\n0.0258198\n-0.0251718\n-0.0107333\n-0.0075896\n-0.0151791\n-0.0120002\n-0.0151791\n-0.0375664\n0.0380043\n0.0809351\n-0.0221272\n\n\n\n\n\n\n\nWeights on \\(E\\)\nWe standardize \\(E\\) as \\(E_{stand}\\), but we standardize so that the variables associated to the sites which have more observations have more weight.\nTo do that, we use the inflated matrix \\(E_{infl}\\) to compute its mean \\(\\bar{E}_{infl}\\) and standard deviation \\(\\sigma(E_{infl})\\) per column. In \\(E_{infl}\\), the rows corresponding to each site are duplicates as many times as there are observations for this given site (so that \\(E_{infl}\\) is of dimension \\(y_{\\cdot \\cdot} \\times l\\)).\n\\[\nE_{stand} = \\frac{E - \\bar{E}_{infl}}{\\sigma(E_{infl})}\n\\]\nWith our data: first, we compute \\(E_{infl}\\):\n\n\nCode\nEinfl &lt;- matrix(data = 0,\n                ncol = ncol(E), \n                nrow = sum(Y))\ncolnames(Einfl) &lt;- colnames(E)\nrownames(Einfl) &lt;- 1:nrow(Einfl)\n\n# Get the number of times to duplicate each site\nnrep_sites &lt;- rowSums(Y)\n\nnrstart &lt;- 0\nfor (i in 1:nrow(E)) {\n  ri &lt;- as.matrix(E)[i, ]\n  \n  rname &lt;- rownames(E)[i]\n  \n  # Get how many times to duplicate this site\n  nr &lt;- nrep_sites[as.character(rname)]\n  \n  Einfl[(nrstart+1):(nrstart+nr), ] &lt;- matrix(rep(ri, nr), \n                                              nrow = nr, \n                                              byrow = TRUE)\n  \n  rownames(Einfl)[(nrstart+1):(nrstart+nr)] &lt;- paste(rname,\n                                                     1:nr,\n                                                     sep = \"_\")\n  nrstart &lt;- nrstart + nr\n}\npaste(\"Dimension:\", paste(dim(Einfl), collapse = \" \"))\n\n\n[1] \"Dimension: 493 6\"\n\n\nCode\nknitr::kable(head(Einfl, 10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n1_1\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_2\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_3\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_4\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_5\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_6\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_7\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_8\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_9\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n2_1\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n\n\n\nThen, we compute the mean and standard deviation per column and standardize \\(E\\).\n\nEinfl_mean &lt;- apply(Einfl, 2, mean)\n\nn &lt;- nrow(Einfl)\nEinfl_sd &lt;- apply(Einfl, 2, \n                  function(x) sd(x)*sqrt((n-1)/n))\n\n\nEstand &lt;- scale(E, \n                center = Einfl_mean,\n                scale = Einfl_sd)\nknitr::kable(Estand)\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n-0.8940191\n-1.4578384\n-0.5429520\n-1.0404731\n1.0369741\n-1.0351817\n\n\n-0.8940191\n-1.3502706\n-0.5081483\n-0.3311255\n-0.4345644\n1.0954816\n\n\n-0.8940191\n0.8010856\n1.0902771\n0.3301082\n-1.3346326\n1.0954816\n\n\n-0.8940191\n0.7473017\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n-0.8940191\n0.6397339\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n-0.8940191\n1.1775730\n-0.6656140\n-1.0605165\n0.9946790\n-0.6293411\n\n\n-0.8940191\n1.0162212\n-0.5098460\n-0.0929573\n0.3501447\n0.0301499\n\n\n-0.8940191\n-0.9199993\n-0.2273840\n0.2490300\n-0.0430582\n0.4867206\n\n\n-0.8940191\n0.9624373\n-0.1495000\n0.0784846\n0.3887809\n-0.4771509\n\n\n-0.8940191\n0.9086534\n-0.6102251\n-1.2838968\n1.3976330\n-1.8468630\n\n\n-0.8940191\n-1.2964867\n-0.5348877\n-1.0664053\n0.9299593\n-0.6293411\n\n\n-0.8940191\n-0.6510798\n-0.5567462\n0.9797698\n-0.3354772\n0.0301499\n\n\n-0.8940191\n-0.6510798\n-0.4429974\n0.7628294\n-1.9186435\n1.9578929\n\n\n1.1185444\n-1.4578384\n-0.5429520\n-1.0404731\n1.0369741\n-1.0351817\n\n\n1.1185444\n-1.3502706\n-0.5081483\n-0.3311255\n-0.4345644\n1.0954816\n\n\n1.1185444\n0.8010856\n1.0902771\n0.3301082\n-1.3346326\n1.0954816\n\n\n1.1185444\n0.7473017\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n1.1185444\n0.6397339\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n1.1185444\n1.1775730\n-0.6656140\n-1.0605165\n0.9946790\n-0.6293411\n\n\n1.1185444\n1.0162212\n-0.5098460\n-0.0929573\n0.3501447\n0.0301499\n\n\n1.1185444\n-0.9199993\n-0.2273840\n0.2490300\n-0.0430582\n0.4867206\n\n\n1.1185444\n0.9624373\n-0.1495000\n0.0784846\n0.3887809\n-0.4771509\n\n\n1.1185444\n0.9086534\n-0.6102251\n-1.2838968\n1.3976330\n-1.8468630\n\n\n1.1185444\n-1.2964867\n-0.5348877\n-1.0664053\n0.9299593\n-0.6293411\n\n\n1.1185444\n-0.6510798\n-0.5567462\n0.9797698\n-0.3354772\n0.0301499\n\n\n1.1185444\n-0.6510798\n-0.4429974\n0.7628294\n-1.9186435\n1.9578929\n\n\n\n\n\n\n\nRegression\nAfter that, we perform the weighted multiple linear regression of \\(\\bar{Q}\\) by \\(E_{stand}\\). Each row of \\(\\bar{Q}\\) \\(\\bar{q}\\) is approximated by \\(\\hat{\\bar{q}}\\) using multiple linear regression on \\(E_{stand}\\): \\(\\hat{\\bar{q}} = b_0 + b_1 e_{1} + \\ldots + b_e e_{l}\\), where \\(e_i\\) are columns of \\(E_{stand}\\) and \\(b_i\\) are regression coefficients. In a matrix form, it is written:\n\\[\n\\hat{\\bar{Q}} = D(p_{i\\cdot})^{1/2}E_{stand}B\n\\]\nWhere\n\\[\nB = [E_{stand}' D(p_{i\\cdot}) E_{stand}]^{-1}E_{stand}'D(p_{i\\cdot})^{1/2}\\bar{Q}\n\\]\nWith our example:\n\n# Diagonal matrix weights\nDpi_ &lt;-  diag(rowSums(P))\ncolnames(Dpi_) &lt;- rownames(P)\n\n# Regression coefficient\nB &lt;- solve(t(Estand) %*% Dpi_ %*% Estand) %*% t(Estand) %*% sqrt(Dpi_) %*% Qbar\n\nNow, we can get the predicted values for \\(\\bar{Q}\\). For instance, let’s plot predicted vs observed values for site 2:\n\n# Compute predicted values\nQbarhat &lt;- sqrt(Dpi_) %*% Estand %*% B\ncolnames(Qbarhat) &lt;- colnames(Qbar)\nrownames(Qbarhat) &lt;- rownames(Qbar)\ndim(Qbarhat)\n\n[1] 26 21\n\n# Get predicted and observed values for one site\nind &lt;- 2\n\npred &lt;- Qbarhat[ind, ]\nobs &lt;- Qbar[ind, ]\n\n\n\nCode\ndf &lt;- data.frame(pred, obs, names = names(pred))\ndf&lt;- df |&gt; \n  tidyr::pivot_longer(cols = c(\"pred\", \"obs\"))\n\nggplot(df, aes(x = names, y = value, col = name)) +\n  geom_point() +\n  theme_linedraw() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\nDiagonalization\nThen, we diagonalize the covariance matrix of predicted values \\(S_{\\hat{\\bar{Q}}' \\hat{\\bar{Q}}}\\).\nFirst, we compute the covariance matrix (note that here we don’t divide by the degrees of freedom).\n\\[\nS_{\\hat{\\bar{Q}}' \\hat{\\bar{Q}}} = \\hat{\\bar{Q}}' \\hat{\\bar{Q}}\n\\]\n\nSqq &lt;- t(Qbarhat) %*% Qbarhat\n\nWe diagonalize \\(S_{\\hat{\\bar{Q}}' \\hat{\\bar{Q}}}\\):\n\\[\nS_{\\hat{\\bar{Q}}' \\hat{\\bar{Q}}} = U \\Lambda U^{-1}\n\\]\n\\(\\Lambda\\) is the matrix of eigenvalues (there are \\(\\min(r-1, c, l)\\) non-null eigenvalues) and \\(U\\) contains the columns (species) loadings.\n\nneig &lt;- min(c(r-1, c, l))\n\nHere, \\(r-1 =\\) 25, \\(c =\\) 21 and \\(l =\\) 6 so the minimum (and the number of eigenvalues) is 6.\n\neig &lt;- eigen(Sqq)\n\n(lambda &lt;- eig$values) # There are l = 6 non-null eigenvalues\n\n [1]  1.846574e-01  1.571586e-01  1.009501e-01  8.711508e-02  3.222443e-02\n [6]  1.476469e-02  9.795705e-18  8.252762e-18  7.486518e-18  6.959888e-18\n[11]  5.759585e-18  5.381418e-18  4.061072e-18  1.605351e-18  4.678542e-19\n[16]  3.679331e-19 -4.523252e-20 -7.096450e-19 -4.140284e-18 -7.864342e-18\n[21] -2.116046e-17\n\nlambda &lt;- lambda[1:neig]\n\nLambda &lt;- diag(lambda)\nU &lt;- eig$vectors[, 1:neig] # We keep only the eigenvectors\nrownames(U) &lt;- colnames(Y)\n\nFinally, we can get the ordination of rows (sites) by using the link between rows and columns ordination:\n\\[\n\\hat{U} = \\bar{Q} U \\Lambda^{-1/2}\n\\]\n\nUhat &lt;- Qbar %*% U %*% diag(lambda^(-1/2))\nrownames(Uhat) &lt;- rownames(Qbar)\n\ndim(Uhat)\n\n[1] 26  6\n\n\nNB: this is not the same as diagonalizing S_{ ’} or performing the SVD of \\(\\hat{\\bar{Q}}\\), because $ does not contain the loadings of \\(\\hat{\\bar{Q}}\\) but the loadings of \\(\\bar{Q}\\)."
  },
  {
    "objectID": "CCA.html#scaling",
    "href": "CCA.html#scaling",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Scaling",
    "text": "Scaling\n\n\n\n\n\n\nTL;DR\n\n\n\nAs with CA, we have scalings type 1, 2 and 3. There are 2 differences with CA:\n\nFor the sites, we have 2 types of scores: the predicted sites scores (LC scores), computed from the regression, and the weighted averages (WA scores), computed from the species.\nThere are also scalings for the correlations of the explanatory variables with the axes.\n\nIt seems that the general formulas for scalings are:\n\nWA scores for rows (sites): \\(F = D(p_{\\cdot j})^{-1/2}\\hat{U} \\Lambda^{\\alpha/2}\\)\nLC scores for rows (sites): \\(Z_1 = D(p_{i\\cdot})^{-1/2}\\hat{\\bar{Q}}U \\Lambda^{?}\\)\nColumns (species) scores: \\(V = D(p_{\\cdot j})^{-1/2}U \\Lambda^{(1-\\alpha)/2}\\)\nVariables scores: \\(BS_1 = E_{stand}' D(p_{i\\cdot})Z_{stand} \\Lambda^{\\alpha/2}\\)\n\nwith \\(\\alpha =\\) 1, 0 or 1/2.\nScaling type 1 (\\(\\alpha = 1\\))\n\nWA scores for rows (sites): \\(F = D(p_{\\cdot j})^{-1/2}\\hat{U} \\Lambda^{1/2}\\)\nLC scores for rows (sites): \\(Z_1 = D(p_{i\\cdot})^{-1/2}\\hat{\\bar{Q}}U\\)\nColumns (species) scores: \\(V = D(p_{\\cdot j})^{-1/2}U\\)\nVariables scores: \\(BS_1 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\Lambda^{1/2}\\)\n\nScaling type 2 (\\(\\alpha = 0\\))\n\nWA scores for rows (sites): \\(\\hat{V} = D(p_{\\cdot j})^{-1/2}\\hat{U}\\)\nLC scores for rows (sites): \\(Z_2 = D(p_{i\\cdot})^{-1/2}\\hat{\\bar{Q}} U \\Lambda^{-1/2}\\)\nColumns (species) scores: \\(\\hat{F} = D(p_{\\cdot j})^{-1/2}U \\Lambda^{1/2}\\)\nVariables scores: \\(BS_2 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\)\n\nScaling type 3 (\\(\\alpha = 1/2\\))\n\nWA scores for rows (sites): \\(\\hat{S}_3 = D(p_{\\cdot j})^{-1/2}\\hat{U} \\Lambda^{1/4}\\)\nLC scores for rows (sites): \\(Z_3 = D(p_{i\\cdot})^{-1/2}\\hat{\\bar{Q}}U \\Lambda^{-1/4}\\)\nColumns (species) scores: \\(S_3 = D(p_{\\cdot j})^{-1/2} U \\Lambda^{1/4}\\)\nVariables scores: \\(BS_3 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\Lambda^{1/4}\\)\n\nHow to find the fa (ie correlation coefficients for each environmental variable in the multivariate space)??\n\n\nLet’s compute CCA with ade4 to compare results.\n\nca &lt;- dudi.coa(Y, \n               nf = c-1, \n               scannf = FALSE)\ncca &lt;- pcaiv(dudi = ca, \n             df = E,\n             scannf = FALSE,\n             nf = neig)\n\nlambda[1:neig]/cca$eig # Eigenvalues are the same as computed manually\n\n[1] 1 1 1 1 1 1\n\n\n\nPre-computations\nWe define the diagonal matrices with rows and columns weights (respectively \\(D(p_{i\\cdot}\\) and \\(D(p_{\\cdot j}\\)).\n\n# Define weights matrices\nDpi_ &lt;- diag(rowSums(P))\nDp_j &lt;- diag(colSums(P))\n\n# Also define a variable for just the sums for easier manipulation\ndpi_ &lt;- rowSums(P)\ndp_j &lt;- colSums(P)\n\nThe scores for the explanatory variables are computed from matrix \\(Z_{stand}\\): so we first need to standardize \\(Z\\) into \\(Z_{stand}\\) (the computation can involve \\(Z_1\\), \\(Z_2\\) or \\(Z_3\\) and give the same result).\n\n\nCode\n# Compute Z1\nZ1 &lt;- diag(dpi_^(-1/2)) %*% Qbarhat %*% U\n\n# Compute inflated matrix ------\nZinfl &lt;- matrix(data = 0,\n                ncol = ncol(Z1), \n                nrow = sum(Y))\nrownames(Zinfl) &lt;- 1:nrow(Zinfl)\n# Give names to Z1\nrownames(Z1) &lt;- rownames(Y)\n\n# Get the number of times to duplicate each site\nnrep_sites &lt;- rowSums(Y)\n\nnrstart &lt;- 0\nfor (i in 1:nrow(Z1)) {\n  ri &lt;- Z1[i, ]\n  \n  rname &lt;- rownames(Z1)[i]\n  \n  # Get how many times to duplicate this site\n  nr &lt;- nrep_sites[as.character(rname)]\n  \n  Zinfl[(nrstart+1):(nrstart+nr), ] &lt;- matrix(rep(ri, nr), \n                                              nrow = nr, \n                                              byrow = TRUE)\n  \n  rownames(Zinfl)[(nrstart+1):(nrstart+nr)] &lt;- paste(rname, \n                                                     1:nr, \n                                                     sep = \"_\")\n  nrstart &lt;- nrstart + nr\n}\n\npaste(\"Dimension of Zinfl:\", \n      paste(dim(Zinfl), collapse = \" \"))\n\n\n[1] \"Dimension of Zinfl: 493 6\"\n\n\nCode\n# Compute mean/sd ------\nZinfl_mean &lt;- apply(Zinfl, 2, mean)\n\nn &lt;- nrow(Zinfl)\nZinfl_sd &lt;- apply(Zinfl, 2, \n                  function(x) sd(x)*sqrt((n-1)/n))\n\n# Compute Zstand ------\nZstand &lt;- scale(Z1, \n                center = Zinfl_mean,\n                scale = Zinfl_sd)\n\npaste(\"Dimension of Zstand:\", \n      paste(dim(Zstand), collapse = \" \"))\n\n\n[1] \"Dimension of Zstand: 26 6\"\n\n\n\n\nScaling type 1\nHere, \\(\\chi^2\\) distances between rows (sites) are preserved they are positioned at the centroid of species.\n\nthe rows (sites) scores can be \\(F = D(p_{i \\cdot})^{-1/2} \\hat{U} \\Lambda^{1/2}\\) or \\(Z_1 = D(p_{i\\cdot})^{-1/2} \\hat{\\bar{Q}} U\\)\nthe columns (species) scores are \\(V = D(p_{\\cdot j})^{-1/2} U\\)\nthe explanatory variable score are \\(BS_1 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\Lambda^{1/2}\\)\n\n\n# Row scores\nF_ &lt;- diag(dpi_^(-1/2)) %*% Uhat %*% Lambda^(1/2)\nZ1 &lt;- diag(dpi_^(-1/2)) %*% Qbarhat %*% U\n\n# Columsn scores\nV &lt;- diag(dp_j^(-1/2)) %*% U\n\n# Variables correlation\nBS1 &lt;- t(Estand) %*% Dpi_ %*% Zstand %*% sqrt(Lambda)\n\n\n\nCode\nmult &lt;- 10\n# WA scores\ngwa &lt;- multiplot(indiv_row = F_, indiv_col = V, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS1, var_row_lab = colnames(E),\n                 row_color = params$colsite, col_color = params$colspp,\n                 mult = mult,\n                 eig = lambda) +\n  ggtitle(\"WA scores for sites\")\n\n# LC scores\nglc &lt;- multiplot(indiv_row = Z1, indiv_col = V, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS1, var_row_lab = colnames(E),\n                 row_color = params$colsite, col_color = params$colspp,\n                 mult = mult,\n                 eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\ngrid.arrange(grobs = list(gwa, glc),\n             nrow = 1)\n\n\n\n\n\nThe plot with the predicted sites scores has the same coordinates for sites as with ade4.\n\n\nScaling type 2\nHere, \\(\\chi^2\\) distances between columns (species) are preserved they are positioned at the centroid of sites.\n\nthe rows (sites) scores can be \\(\\hat{V} = D(p_{i \\cdot})^{-1/2} \\hat{U}\\) or \\(Z_2 = D(p_{i\\cdot})^{-1/2} \\hat{\\bar{Q}} U \\Lambda^{-1/2}\\)\nthe columns (species) scores are \\(\\hat{F} = D(p_{\\cdot j})^{-1/2} U \\Lambda^{1/2}\\)\nthe explanatory variable score are \\(BS_2 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\)\n\n\n# Row scores\nVhat &lt;- diag(dpi_^(-1/2)) %*% Uhat\nZ2 &lt;- diag(dpi_^(-1/2)) %*% Qbarhat %*% U %*% diag(lambda^(-1/2))\n\n# Columsn scores\nFhat &lt;- diag(dp_j^(-1/2)) %*% U %*% Lambda^(1/2)\n\n# Variables correlation\nBS2 &lt;- t(Estand) %*% Dpi_ %*% Zstand\n\nOn these graphs, species are in the same position as with ade4.\n\n\nCode\nmult &lt;- 5\n# WA scores\ngwa &lt;- multiplot(indiv_row = Vhat, indiv_col = Fhat, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS2, var_row_lab = colnames(E),\n                 row_color = params$colsite, col_color = params$colspp,\n                 mult = mult,\n                 eig = lambda) +\n  ggtitle(\"WA scores for sites\")\n\n# LC scores\nglc &lt;- multiplot(indiv_row = Z2, indiv_col = Fhat, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS2, var_row_lab = colnames(E),\n                 row_color = params$colsite, col_color = params$colspp,\n                 mult = mult,\n                 eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\ngrid.arrange(grobs = list(gwa, glc),\n             nrow = 1)\n\n\n\n\n\n\n\nScaling type 3\nThis type of scaling is a compromise between scalings type 1 and 2.\n\nthe rows (sites) scores can be \\(\\hat{S}_3 = D(p_{i \\cdot})^{-1/2} \\hat{U} \\Lambda^{1/4}\\) or \\(Z_3 = D(p_{i\\cdot})^{-1/2} \\hat{\\bar{Q}} U \\Lambda^{-1/4}\\)\nthe columns (species) scores are \\(S_3 = D(p_{\\cdot j})^{-1/2} U \\Lambda^{1/4}\\)\nthe explanatory variable score are \\(BS_3 = E_{stand}' D(p_{i\\cdot})Z_{stand} \\Lambda^{1/4}\\)\n\n\n# Row scores\nShat3 &lt;- diag(dpi_^(-1/2)) %*% Uhat %*% Lambda^(1/4)\nZ3 &lt;- diag(dpi_^(-1/2)) %*% Qbarhat %*% U %*% diag(lambda^(-1/4))\n\n# Columns scores\nS3 &lt;- diag(dp_j^(-1/2)) %*% U %*% Lambda^(1/4)\n\n# Variables correlation\nBS3 &lt;- t(Estand) %*% Dpi_ %*% Zstand %*% Lambda^(1/4)\n\n\n\nCode\nmult &lt;- 5\n# WA scores\ngwa &lt;- multiplot(indiv_row = Shat3, indiv_col = S3, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS3, var_row_lab = colnames(E),\n                 row_color = params$colsite, col_color = params$colspp,\n                 mult = mult,\n                 eig = lambda) +\n  ggtitle(\"WA scores for sites\")\n\n# LC scores\nglc &lt;- multiplot(indiv_row = Z3, indiv_col = S3, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS3, var_row_lab = colnames(E),\n                 row_color = params$colsite, col_color = params$colspp,\n                 mult = mult,\n                 eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\ngrid.arrange(grobs = list(gwa, glc),\n             nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\\(\\hat{F}\\), \\(Z_1\\) and \\(BS_2\\) are the values used in the outputs of pcaiv.\n\ncca$co[, 1]/Fhat[, 1]\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\ncca$li[, 1]/Z1[, 1]\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\ncca$cor[, 1]/BS2[, 1]\n\n           location           elevation          patch_area        perc_forests \n                  1                   1                   1                   1 \n    perc_grasslands ShannonLandscapeDiv \n                  1                   1"
  },
  {
    "objectID": "CCA.html#interpretation",
    "href": "CCA.html#interpretation",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Interpretation",
    "text": "Interpretation\nIn CCA, each ordination axis corresponds to a linear combination of the explanatory variables that maximizes the explained variance in the response data.\nThis analysis constrains rows (sites) scores to be linear combinations of the environmental variables (scaling \\(Z_i\\)).\nSpecies can be ordered along environmental variables axes by projecting species coordinates on the vector of this variable. This gives species niche optimum, but there are strong assumptions:\n\nunimodal distribution of niches preferences along the variable of interest\nspecies distributions are indeed controlled by the environment\nthe study gradient is long enough to capture the range of species abundance variation.\n\nThe part of variation explained by the environmental variables can be computed as \\[\n\\frac{\\sum_k \\lambda_k(CCA)}{\\sum_l \\lambda_l(CA)}\n\\]\n\nsum(lambda)/sum(ca$eig)\n\n[1] 0.3795835\n\n\nHere, the environmental variables explain 38 % of the total variation.\nWarning: in CCA, using noisy or not relevant explanatory variables leads to spurious relationships.\n\nResidual analysis\nIn order to examinate residuals, a CA can be performed on the table of residuals \\(\\bar{Q}_{res}\\):\n\\[\n\\bar{Q}_{res} = \\bar{Q} - \\hat{\\bar{Q}}\n\\]\n\nQres &lt;- Qbar - Qbarhat\n\nres_pca &lt;- dudi.pca(Qres, scannf = FALSE, nf = 27)\n\nscatter(res_pca)\n\n\n\n\n\n\nTests of significance\nIt is possible to test the significance of the the relationship between \\(E\\) and \\(Y\\) with a permutation test.\n\nrandtest(cca, nrepet = 999)\n\nMonte-Carlo test\nCall: randtest.pcaiv(xtest = cca, nrepet = 999)\n\nObservation: 0.3795835 \n\nBased on 999 replicates\nSimulated p-value: 0.001 \nAlternative hypothesis: greater \n\n     Std.Obs  Expectation     Variance \n3.7170824030 0.2682190741 0.0008976118"
  },
  {
    "objectID": "dcCA.html",
    "href": "dcCA.html",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# dc-CA\nsource(here(\"functions/dpcaiv2-ade4.R\"))\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(gridExtra)\nsource(here(\"functions/plot.R\"))\nThe contents of this page relies heavily on (Braak, Šmilauer, and Dray 2018)."
  },
  {
    "objectID": "dcCA.html#introduction",
    "href": "dcCA.html#introduction",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Introduction",
    "text": "Introduction\ndc-CA was developed as a natural extension of CCA and has been used to study the relationship between species traits and environmental variables.\nIn dc-CA, we have 3 matrices:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables \\(E\\) (\\(r \\times l\\))\nA matrix of predictor variables \\(T\\) (\\(c \\times k\\))\n\n\n\n\n\n\nThe aim of dc-CA is to find a linear combination of the predictor variables in \\(E\\) and \\(T\\) (environmental variables and traits) that maximizes the correlation.\nBelow are these matrices for our data:\n\\(Y =\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n4\n0\n0\n0\n0\n2\n0\n4\n0\n2\n0\n4\n0\n0\n0\n0\n1\n5\n0\n0\n2\n\n\n2\n0\n0\n1\n0\n2\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n5\n1\n5\n1\n\n\n4\n0\n0\n0\n0\n0\n0\n2\n0\n0\n3\n0\n0\n0\n0\n0\n1\n1\n0\n0\n1\n\n\n2\n0\n1\n5\n0\n0\n0\n5\n0\n1\n1\n4\n0\n0\n0\n1\n2\n2\n0\n0\n2\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n2\n0\n0\n0\n4\n0\n1\n10\n3\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n4\n0\n2\n2\n4\n0\n0\n0\n0\n2\n1\n2\n0\n1\n\n\n5\n5\n0\n0\n1\n1\n0\n1\n0\n3\n0\n5\n0\n0\n0\n0\n0\n0\n1\n5\n1\n\n\n4\n0\n0\n1\n0\n2\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n3\n0\n0\n0\n1\n0\n0\n0\n0\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n5\n0\n4\n0\n1\n2\n0\n0\n0\n0\n0\n0\n1\n2\n0\n0\n\n\n4\n0\n1\n1\n0\n1\n0\n3\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n1\n0\n3\n2\n1\n2\n0\n0\n0\n0\n0\n0\n1\n3\n0\n0\n\n\n4\n2\n0\n1\n0\n0\n0\n2\n0\n2\n2\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n4\n0\n0\n1\n0\n2\n0\n2\n2\n2\n1\n1\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n4\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n5\n1\n0\n3\n0\n2\n0\n2\n1\n0\n2\n0\n0\n0\n0\n0\n0\n3\n1\n0\n0\n\n\n3\n5\n0\n4\n0\n2\n0\n5\n0\n4\n2\n0\n0\n1\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n2\n0\n7\n0\n1\n1\n0\n0\n4\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n6\n0\n0\n2\n0\n1\n0\n0\n0\n1\n3\n0\n0\n0\n0\n0\n0\n0\n3\n3\n0\n\n\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n\n\n\n\n\n\\(E =\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n0\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n0\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n0\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n0\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n0\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n0\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n1\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n1\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n1\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n1\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n1\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n1\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n\n\n\n\\(T =\\)\n\n\n\n\n\n\nbiog\nforag\nmass\ndiet\nmove\nnest\neggs\n\n\n\n\nsp1\n1\n2\n2\n3\n1\n2\n2\n\n\nsp2\n1\n1\n1\n2\n1\n2\n2\n\n\nsp3\n1\n1\n2\n2\n2\n2\n1\n\n\nsp4\n1\n1\n1\n2\n1\n2\n2\n\n\nsp5\n1\n3\n3\n1\n2\n3\n4\n\n\nsp6\n1\n1\n4\n3\n2\n2\n1\n\n\nsp7\n1\n1\n1\n2\n1\n3\n3\n\n\nsp8\n1\n1\n1\n2\n2\n2\n2\n\n\nsp9\n1\n2\n1\n2\n1\n3\n3\n\n\nsp10\n1\n1\n1\n2\n1\n2\n2\n\n\nsp11\n2\n4\n3\n2\n1\n2\n2\n\n\nsp12\n2\n1\n2\n3\n2\n2\n3\n\n\nsp13\n2\n1\n4\n3\n2\n3\n1\n\n\nsp14\n2\n3\n2\n2\n1\n1\n3\n\n\nsp15\n2\n2\n2\n3\n2\n2\n3\n\n\nsp16\n2\n2\n2\n3\n2\n2\n4\n\n\nsp17\n2\n3\n4\n1\n1\n2\n2\n\n\nsp18\n2\n2\n1\n3\n2\n2\n3\n\n\nsp19\n2\n4\n3\n2\n1\n2\n2\n\n\nsp21\n2\n4\n3\n1\n2\n3\n3\n\n\nsp22\n2\n3\n2\n3\n2\n1\n3\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- dim(E)[2])\n\n[1] 6\n\n(k &lt;- dim(T_)[2])\n\n[1] 7\n\n\ndc-CA must not have to many traits compared to species: that is a disadvantage compared to RLQ, but on the other hand dc-CA allows to see relationships that RLQ would miss (Braak, Šmilauer, and Dray 2018).\nThere are several ways to perform dc-CA (Braak, Šmilauer, and Dray 2018), notably:\n\nsingular value decomposition (the method used here)\nan iterative method à la reciprocal averaging\ncanonical correlation analysis between \\(T\\) et \\(E\\), weighted by \\(Y\\)"
  },
  {
    "objectID": "dcCA.html#computation",
    "href": "dcCA.html#computation",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nWe perform the SVD of \\(D = [E_{center}' D(y_{i \\cdot}) E_{center}]^{-1/2} E_{center}' Y T_{center} [T_{center}' D(y_{\\cdot j}) T_{center}]^{-1/2}\\)\n\\[\nD = P \\Delta Q'\n\\] This allows us to find the eigenvectors \\(P\\) (rows or environment eigenvectors) and \\(Q\\) (columns or traits eigenvectors).\nThe eigenvalues of the dc-CA are the squared eigenvalues of the SVD: \\(\\Lambda = \\Delta^2\\).\nThere are \\(\\min(k, l)\\) non-null eigenvalues???\nRegression coefficients\nThen, the regression coefficients for explanatory variables can be found with:\n\n\\(B = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\Delta^\\alpha\\) (row explanatory variables = environmental variables)\n\\(C = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q\\Delta^\\alpha\\) (columns explanatory variables = species traits)\n\nwhere \\(\\alpha\\) is a scaling factor equal to 1, 0 or 1/2. The different scalings are detailed in the next part.\nIndividuals coordinates\nThe individuals coordinates (species or sites) can be computed in two ways:\nLinear combinations (LC scores) are computed from those coefficients :\n\n\\(Z_i = E_{center}B_i\\) for the rows (sites)\n\\(\\hat{Z}_i = T_{center}C_i\\) for columns (species)\n\nWeighted averages (WA scores) are computed from the scores of the other individuals:\n\n\\(\\hat{U}_i = D(y_{\\cdot i})^{-1} Y Z_i\\) for row (sites) scores\n\\(U_i = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_i\\) for column (species) scores\n\nCorrelations\nFinally, we can compute correlations scores for different scalings for the explanatory variables:\n\n\\(BS_B^i = \\left[ E_{center}'D(y_{i\\cdot})E_{center} \\right]^{1/2} P \\Delta^{\\alpha}\\) for the row (environmental variables)\n\\(BS_C^i = \\left[ T_{center}'D(y_{i\\cdot})T_{center} \\right]^{1/2} Q \\Delta^{1-\\alpha}\\) for the columns (species traits)\n\n\n\nFirst, we need to center the traits and environment matrices (resp. \\(T_{cent}\\) and \\(E_{cent}\\)). To do that, we have to compute “inflated” versions of these matrices matching the occurrence counts in \\(Y\\).\n\\[\nE_{stand} = E - \\bar{E}_{infl} =\\left[e_i \\sum_i y_{i\\cdot}e_i/y_{\\cdot\\cdot} \\right]\n\\]\n\\[\nT_{stand} = T - \\bar{T}_{infl} = \\left[t_j \\sum_j y_{\\cdot j}t_j/y_{\\cdot\\cdot} \\right]\n\\]\nWith our data:\n\n# Center E -----\nyi_ &lt;- rowSums(Y)\nEcenter &lt;- matrix(nrow = nrow(E), ncol = ncol(E))\n\nfor(i in 1:ncol(Ecenter)) {\n  Ecenter[, i] &lt;- E[, i] - sum(E[, i]*yi_)/sum(Y)\n}\n# This is the same as computing a mean on inflated data matrix Einfl and centering E with these means\n\n# Center T -----\ny_j &lt;- colSums(Y)\nTcenter &lt;- matrix(nrow = nrow(T_), ncol = ncol(T_))\nrownames(Tcenter) &lt;- rownames(T_)\ncolnames(Tcenter) &lt;- colnames(T_)\n\nfor(j in 1:ncol(Tcenter)) {\n  Tcenter[, j] &lt;- T_[, j] - (sum(T_[, j]*y_j)/sum(Y))\n}\n\n\n# Check centering -----\nM1 &lt;- matrix(rep(1, nrow(Y)), nrow = 1)\nall((M1 %*% diag(rowSums(Y)) %*% Ecenter) &lt; 10e-10)\n\n[1] TRUE\n\nM1 &lt;- matrix(rep(1, ncol(Y)), nrow = 1)\nall((M1 %*% diag(colSums(Y)) %*% Tcenter) &lt; 10e-10)\n\n[1] TRUE\n\n\nMaximizing the fourth-corner correlation means finding \\(\\hat{u}\\) and \\(u\\) that maximize \\(\\hat{u}'Yu\\) (where \\(\\hat{u}\\) are the sites (rows) scores and \\(u\\) are the species (columns) scores).\n\\(\\hat{u}\\) and \\(u\\) are linear combinations of traits and environmental variables: \\(\\hat{u} = E_{center}b\\) and \\(u = T_{center}c\\).\nSo in the end, we need to maximize \\(\\hat{u}'Yu\\) with respect to the coefficients vectors \\(b\\) and \\(c\\):\n\\[\n\\max_{b, c}(\\hat{u}'Yu) = \\max_{b, c}\\left(\\left[E_{center}b\\right]'Y  T_{center}c \\right)\n\\]\n\n\n\n\n\n\nNote\n\n\n\nThese equations are written for the first axis, but we can also write them in matrix form:\n\\[\n\\max_{B, C}(\\hat{U}'YU) = \\max_{B, C}\\left(\\left[E_{center}B\\right]'Y T_{center}C \\right)\n\\]\n\n\nIn addition, we introduce the following constraint on the norm of the columns vectors of \\(\\hat{U}\\) and \\(U\\): \\(\\hat{u}' D(y_{i\\cdot}) \\hat{u} = 1\\) and \\(u' D(y_{\\cdot j})u = 1\\). In fact, tjese constraints will be relaxed later depending on the scaling (see below).\nTo find the coefficients \\(B\\) and \\(C\\) defined above, we need to diagonalize the following matrices \\(M\\) and \\(M_2\\):\n\nTo find \\(B\\), we must diagonalize \\(M\\): \\[\nM = \\left[E_{center}' D(y_{i\\cdot}) E_{center} \\right]^{-1} E_{center}'YT_{center} \\left[T_{center}' D(y_{\\cdot j}) T_{center} \\right]^{-1} T_{center}' Y' E_{center}\n\\] Where matrices \\(D(y_{i \\cdot})\\) and \\(D(y_{\\cdot j})\\) are the diagonal matrices with the column and row sums (respectively). They are analogous to matrices \\(D(p_{i \\cdot})\\) and \\(D(p_{\\cdot j})\\) defined for CA and CCA (but we use \\(Y\\) instead of \\(P\\) to define the margins).\n\nWe can view \\(M\\) as: \\[\nM = \\hat{E}_{center} \\hat{T}_{center} = \\beta T_{center} \\gamma E_{center}\n\\] With \\(\\beta = \\left[E_{center}' D(y_{i\\cdot}) E_{center} \\right]^{-1} E_{center}'Y\\) and \\(\\gamma = \\left[T_{center}' D(y_{\\cdot j}) T_{center} \\right]^{-1} T_{center}' Y'\\). Here, we predict the environment with traits so that \\(\\hat{E}_{center} = \\beta T_{center}\\) and the traits with the environment so that \\(\\hat{T}_{center} = \\gamma E_{center}\\). So we maximize the correlation between \\(\\hat{E}_{center}\\) and \\(\\hat{T}_{center}\\).\n\nSimilarly, to find \\(C\\), we must diagonalize \\(M_2\\):\n\n\\[\nM_2 = \\left[T_{center}' D(y_{\\cdot j}) T_{center} \\right]^{-1} T_{center}' Y' E_{center} \\left[E_{center}' D(y_{i\\cdot}) E_{center} \\right]^{-1} E_{center}'YT_{center}\n\\] Here, we can view \\(M_2\\) as: \\[\nM_2 = \\hat{T}_{center} \\hat{E}_{center} = \\gamma E_{center} \\beta T_{center}\n\\]\nThe eigenvectors matrices of these diagonalizations give us \\(B\\) and \\(C\\):\n\\[\nM = B \\Lambda_b B^{-1} ~~ \\text{and} ~~ M_2 = C \\Lambda_c C^{-1}\n\\]\nWe can either diagonalize \\(M\\) and \\(M_2\\) of perform a single SVD of a matrix \\(D\\) defined below and get a similar result. Both methods are presented below.\n\nDiagonalizations\nWe diagonalize \\(M\\) and \\(M_2\\):\n\n# Define weights\nDyi_ &lt;- diag(rowSums(Y))\nDy_j &lt;- diag(colSums(Y))\n\n# Compute M\nM &lt;- solve(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% t(Ecenter) %*% Y %*% Tcenter %*% solve(t(Tcenter) %*% Dy_j %*% Tcenter) %*% t(Tcenter) %*% t(Y) %*% Ecenter\n\n# Compute M2\nM2 &lt;- solve(t(Tcenter) %*% Dy_j %*% Tcenter) %*% t(Tcenter) %*% t(Y) %*% Ecenter %*% solve(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% t(Ecenter) %*% Y %*% Tcenter \n\n\n# Diagonalize M\neigB &lt;- eigen(M)\nlambdaB &lt;- eigB$values\nlambdaB # All non-null eigenvectors\n\n[1] 0.139487442 0.088736680 0.049183623 0.013797529 0.008736645 0.002485683\n\nvB &lt;- eigB$vectors\n\n# Diagonalize M2\neigC &lt;- eigen(M2)\nlambdaC &lt;- eigC$values\nlambdaC # six non-null eigenvalues\n\n[1]  1.394874e-01  8.873668e-02  4.918362e-02  1.379753e-02  8.736645e-03\n[6]  2.485683e-03 -9.364154e-18\n\nvC &lt;- eigC$vectors\n\nall(lambdaB - lambdaC[1:l] &lt; 10e-10)\n\n[1] TRUE\n\n\n\n\nSVD\nAlternatively, we can compute the SVD of a matrix \\(D\\) computed from \\(M\\) and get a similar result. \\(D\\) is defined as:\n\\[\nD = M^{1/2} = [E_{center}' D(y_{i \\cdot}) E_{center}]^{-1/2} E_{center}' Y T_{center} [T_{center}' D(y_{\\cdot j}) T_{center}]^{-1/2}\n\\]\nWith our dataset:\n\nD &lt;- solve(sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter)) %*%\n  t(Ecenter) %*% Y %*% Tcenter %*%\n  solve(sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter))\n\nWe perform the SVD of \\(D\\): \\(D = P \\Lambda_{SVD} Q'\\).\n\nsv &lt;- svd(D)\n\ndelta &lt;- sv$d\nDelta &lt;- diag(delta)\n\nP_svd &lt;- sv$u\nQ_svd &lt;- sv$v\n\ndim(P_svd)\n\n[1] 6 6\n\ndim(Q_svd)\n\n[1] 7 6\n\n\nThe eigenvalues of the SVD are the square roots of the final eigenvalues obtained by diagonalization: \\(\\Lambda = \\Delta^2\\)\n\nlambda &lt;- delta^2\nLambda &lt;- diag(lambda)"
  },
  {
    "objectID": "dcCA.html#scalings",
    "href": "dcCA.html#scalings",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Scalings",
    "text": "Scalings\n\n\n\n\n\n\nTL;DR\n\n\n\nThere are two types of coordinates: linear combination scores (LC scores) and weighted averages scores (WA scores).\nThe general formulas are:\n\nthe regression coefficients for the rows (environmental variables) are \\(B = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\Delta^\\alpha\\)\nthe regression coefficients for the columns (species traits) are \\(C = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q\\Delta^{1 - \\alpha}\\)\nthe LC scores for rows (sites) are \\(Z_i = E_{center}B_i\\)\nthe LC scores for columns (species) are \\(\\hat{Z}_i = T_{center}C_i\\)\nthe WA scores for rows (sites) are \\(\\hat{U}_i = D(y_{\\cdot i})^{-1} Y Z_i\\)\nthe WA scores for columns (species) are \\(U_i = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_i\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_B^i = \\left[ E_{center}'D(y_{i\\cdot})E_{center} \\right]^{1/2} P \\Delta^{\\alpha}\\)\nthe correlations with axes for the columns (species traits) are \\(BS_C^i = \\left[ T_{center}'D(y_{i\\cdot})T_{center} \\right]^{1/2} Q \\Delta^{1-\\alpha}\\)\n\nNote: the formula for the regression coefficients \\(C_i\\) are in disagreement with the article of (Braak, Šmilauer, and Dray 2018). Here, we find that the scaling should include \\(\\Delta^{1-\\alpha}\\) in the formula (17) instead of \\(\\Delta^{\\alpha-1}\\). However, when we try to prove transition formula (6), we find that it should be \\(\\Delta^{\\alpha}\\).\nIn these formulas, note that the WA scores for one dimension are computed from the predicted scores of the other dimension.\nScaling type 1 (\\(\\alpha = 1\\))\n\nthe regression coefficients for the rows (environmental variables) are \\(B_1 = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\Delta\\)\nthe regression coefficients for the columns (species traits) are \\(C_1 = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q\\)\nthe LC scores for rows (sites) are \\(Z_1 = E_{center}B_1\\)\nthe LC scores for columns (species) are \\(\\hat{Z}_1 = T_{center}C_1\\)\nthe WA scores for rows (sites) are \\(\\hat{U}_1 = D(y_{\\cdot i})^{-1} Y Z_1\\)\nthe WA scores for columns (species) are \\(U_1 = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_1\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_B^1 = \\left[ E_{center}'D(y_{i\\cdot})E_{center} \\right]^{1/2} P \\Delta\\)\nthe correlations with axes for the columns (species traits) are \\(BS_C^1 = \\left[ T_{center}'D(y_{i\\cdot})T_{center} \\right]^{1/2} Q \\Delta\\)\n\nScaling type 2 (\\(\\alpha = 0\\))\n\nthe regression coefficients for the rows (environmental variables) are \\(B_2 = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\)\nthe regression coefficients for the columns (species traits) are \\(C_2 = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q \\Delta\\)\nthe LC scores for rows (sites) are \\(Z_2 = E_{center}B_2\\)\nthe LC scores for columns (species) are \\(\\hat{Z}_2 = T_{center}C_2\\)\nthe WA scores for rows (sites) are \\(\\hat{U}_2 = D(y_{\\cdot i})^{-1} Y Z_2\\)\nthe WA scores for columns (species) are \\(U_2 = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_2\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_B^2 = \\left[ E_{center}'D(y_{i\\cdot})E_{center} \\right]^{1/2} P\\)\nthe correlations with axes for the columns (species traits) are \\(BS_C^2 = \\left[ T_{center}'D(y_{i\\cdot})T_{center} \\right]^{1/2} Q\\)\n\nScaling type 3 (\\(\\alpha = 1/2\\))\n\nthe regression coefficients for the rows (environmental variables) are \\(B_3 = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\Delta^{1/2}\\)\nthe regression coefficients for the columns (species traits) are \\(C_3 = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q\\Delta^{1/2}\\)\nthe LC scores for rows (sites) are \\(Z_3 = E_{center}B_3\\)\nthe LC scores for columns (species) are \\(\\hat{Z}_3 = T_{center}C_3\\)\nthe WA scores for rows (sites) are \\(\\hat{U}_3 = D(y_{\\cdot i})^{-1} Y Z_3\\)\nthe WA scores for columns (species) are \\(U_3 = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_3\\)\nthe correlations with axes for the rows (environmental variables) are \\(BS_B^3 = \\left[ E_{center}'D(y_{i\\cdot})E_{center} \\right]^{1/2} P \\Delta^{1/2}\\)\nthe correlations with axes for the columns (species traits) are \\(BS_C^3 = \\left[ T_{center}'D(y_{i\\cdot})T_{center} \\right]^{1/2} Q \\Delta^{1/2}\\)\n\n\\(\\alpha\\) changes the interpretation of the correlations vectors:\n\nintra-set correlations: \\(BS_B^2\\) (\\(\\alpha = 0\\)) approximates the correlations between the environmental variables (rows variables) and \\(BS_C^1\\) (\\(\\alpha = 1\\)) approximates the correlations between the traits (columns variables)\ninter-set correlations (fourth-corner): \\(BS_B^1\\) (\\(\\alpha = 1\\)) approximates the correlation between environmental variables (row variables) and species (columns) and \\(BS_C^2\\) (\\(\\alpha = 0\\)) approximates the correlation between traits (columns variables) and sites (rows)\n\\(BS_B^3\\) and \\(BS_C^3\\) (\\(\\alpha = 1/2\\)) is the geometric mean of scalings 1 and 2.\n\nWhen plotting the correlation circle, to look at the correlations between variables of the same set (traits or environmental variables), we should use \\(BS_B^2\\) and \\(BS_C^1\\). There are the scores returned by ade4.\n\n\n\nca &lt;- dudi.coa(Y, \n               nf = c-1, \n               scannf = FALSE)\n\ndcca &lt;- dpcaiv2(dudi = ca, \n                dfR = E,\n                dfQ = T_,\n                scannf = FALSE, \n                nf = min(k, l))\n\n\nPre-computations\nCoefficients etc computed with our method are equal to those computed by ade4, but we need to multiply them by a scaling factor \\(\\sqrt{y_{\\cdot \\cdot}}\\).\n\n(scaling &lt;- sqrt(sum(Y)))\n\n[1] 22.2036\n\n\nWe will need this function to normalize correlations vectors to compare results to those of ade4.\n\n#' Normalize row or columns vectors of a matrix\n#'\n#' @param M the matrix to normalize\n#' @param margin the margin (1 = rows, 2 = columns)\n#'\n#' @return The normalized matrix M\nnormalize &lt;- function(M, margin) {\n  \n  m_norm &lt;- apply(M,\n                  margin, \n                  function(x) sqrt(sum(x^2)))\n  M_norm &lt;- sweep(M, margin, m_norm, \"/\")\n  return(M_norm)\n}\n\n\n\nScaling type 1\nThis type of scaling preserves the distances between rows.\n\nthe rows (sites) scores can be \\(\\hat{U}_1\\) (WA scores) or \\(\\hat{Z}_1\\) (LC scores)\n\nthe columns (species) scores can be \\(U_1\\) (WA scores) or \\(Z_1\\) (LC scores)\nrows variables (environmental variables) correlations are \\(BS_{B1}\\).\ncolumns variables (species traits) correlations are \\(BS_{C1}\\)\n\nWith the scaling type 1, \\(BS_{B1}\\) represents the correlation between environmental variables and species and \\(BS_{C1}\\) represents the correlation between species traits and species.\n\n# Coefficients\nB_1 &lt;- solve(sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter)) %*%  P_svd %*% Delta\nC_1 &lt;- solve(sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter)) %*% Q_svd\n\n# LC scores\nZhat1 &lt;- Ecenter %*% B_1 # rows\nZ1 &lt;- Tcenter %*% C_1 # columns\n\n# WA scores\nUhat1 &lt;- solve(Dyi_) %*% Y %*% Z1 # rows\nU1 &lt;- solve(Dy_j) %*% t(Y) %*% Zhat1  # columns\n\n# Variables scores\nBS_B1 &lt;- sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% P_svd %*% Delta\nBS_C1 &lt;- sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter) %*% Q_svd\n\n# Normalize\nBS_B1norm &lt;- normalize(BS_B1, 1)\nBS_C1norm &lt;- normalize(BS_C1, 1)\n\n\n\nCode\n# WA scores\ngwa &lt;- multiplot(indiv_row = Uhat1*scaling, indiv_col = U1*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B1norm, var_row_lab = colnames(E),\n                 var_col = BS_C1norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"WA scores for sites\")\n\n# LC scores\nglc &lt;- multiplot(indiv_row = Zhat1*scaling, indiv_col = Z1*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B1norm, var_row_lab = colnames(E),\n                 var_col = BS_C1norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\ngrid.arrange(grobs = list(gwa, glc),\n             nrow = 2)\n\n\n\n\n\nOn this plot:\n\nrow and columns variables (\\(BS_B^1\\) - \\(BS_C^1\\)): angles between arrows of rows and environmental variables represent their fourth-corner correlation. For instance, the correlation between mass and perc_forests is large (arrows size + direction).\nspecies traits (\\(BS_C^1\\)): arrows indicate intra-set correlations.\nspecies and environmental variables (\\(U\\) - \\(BS_B^1\\)): species points on the right are located in sites with a high location variable.\nsites and species traits (\\(\\hat{U}\\) - \\(BS_C^1\\)): we can understand sites using their community weighted mean (eg site 26 has birds with high mass).\nspecies and species traits (\\(U\\) - \\(BS_C^1\\)): for instance, species 12 has large eggs.\n\nThere is no interpretation for sites - environmental variables (\\(\\hat{U}\\) - \\(BS_B^1\\)).\n\n\nScaling type 2\nThis type of scaling preserves the distances between columns.\n\nthe rows (sites) scores can be \\(\\hat{U}_2\\) (WA scores) or \\(\\hat{Z}_2\\) (LC scores)\n\nthe columns (species) scores can be \\(U_2\\) (WA scores) or \\(Z_2\\) (LC scores)\nrows variables (environmental variables) correlations are \\(BS_{B2}\\).\ncolumns variables (species traits) correlations are \\(BS_{C2}\\)\n\nWith the scaling type 2, \\(BS_{B2}\\) represents the correlation between environmental variables and sites and \\(BS_{C2}\\) represents the correlation between species traits and sites.\n\n# Regression coefficients\nB_2 &lt;- solve(sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter)) %*%  P_svd\nC_2 &lt;- solve(sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter)) %*% Q_svd %*% Delta\n\n# LC scores\nZhat2 &lt;- Ecenter %*% B_2 # rows\nZ2 &lt;- Tcenter %*% C_2 # columns\n\n# WA scores\nUhat2 &lt;- solve(Dyi_) %*% Y %*% Z2 # rows\nU2 &lt;- solve(Dy_j) %*% t(Y) %*% Zhat2 # columns\n\n# Variables scores\nBS_B2 &lt;- sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% P_svd\nBS_C2 &lt;- sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter) %*% Q_svd %*% Delta\n\n# Normalize\nBS_B2norm &lt;- normalize(BS_B2, 1)\nBS_C2norm &lt;- normalize(BS_C2, 1)\n\n\n\nCode\n# WA scores\ngwa &lt;- multiplot(indiv_row = Uhat2*scaling, indiv_col = U2*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B2norm, var_row_lab = colnames(E),\n                 var_col = BS_C2norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"WA scores for sites\")\n\n# LC scores\nglc &lt;- multiplot(indiv_row = Zhat2*scaling, indiv_col = Z2*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B2norm, var_row_lab = colnames(E),\n                 var_col = BS_C2norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\ngrid.arrange(grobs = list(gwa, glc),\n             nrow = 2)\n\n\n\n\n\nOn this plot:\n\nrow and columns variables (\\(BS_B^2\\) - \\(BS_C^2\\)): angles between arrows of rows and environmental variables represent their fourth-corner correlation. For instance, the correlation between mass and patch_forests is large (arrows size + direction).\nenvironmental variables (\\(BS_B^2\\)): arrows indicate intra-set correlations.\nspecies and environmental variables (\\(U\\) - \\(BS_B^1\\))\nsites and species traits (\\(\\hat{U}\\) - \\(BS_C^1\\))\nsites and environmental variables (\\(U\\) - \\(BS_C^1\\))\n\nThere is no interpretation for species - species traits (\\(U\\) - \\(BS_C^2\\)).\n\n\nScaling type 3\nThis type of scaling is an intermediate between scalings 1 and 2.\n\nthe rows (sites) scores can be \\(\\hat{U}_3\\) (WA scores) or \\(\\hat{Z}_3\\) (LC scores)\n\nthe columns (species) scores can be \\(U_3\\) (WA scores) or \\(Z_3\\) (LC scores)\nrows variables (environmental variables) correlations are \\(BS_{B3}\\).\ncolumns variables (species traits) correlations are \\(BS_{C3}\\)\n\nWith the scaling type 3, \\(BS_{B3}\\) and \\(BS_{C3}\\) represent the geometric mean of their correlation with species and sites.\n\n# Variables coefficients\nB_3 &lt;- solve(sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter)) %*%  P_svd %*% Delta^(1/2)\nC_3 &lt;- solve(sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter)) %*% Q_svd %*% Delta^(1/2)\n\n# LC scores\nZhat3 &lt;- Ecenter %*% B_3 # rows\nZ3 &lt;- Tcenter %*% C_3 # columns\n\n# WA scores\nUhat3 &lt;- solve(Dyi_) %*% Y %*% Tcenter %*% C_3 # rows\nU3 &lt;- solve(Dy_j) %*% t(Y) %*% Zhat3 # columns\n\n# Variables scores\nBS_B3 &lt;- sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% P_svd %*% Delta^(1/2)\nBS_C3 &lt;- sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter) %*% Q_svd %*% Delta^(1/2)\n\n# Normalize\nBS_B3norm &lt;- normalize(BS_B3, 1)\nBS_C3norm &lt;- normalize(BS_C3, 1)\n\n\n\nCode\n# WA scores\ngwa &lt;- multiplot(indiv_row = Uhat3*scaling, indiv_col = U3*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B3norm, var_row_lab = colnames(E),\n                 var_col = BS_C3norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"WA scores for sites\")\n\n# LC scores\nglc &lt;- multiplot(indiv_row = Zhat3*scaling, indiv_col = Z3*scaling, \n                 indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), \n                 var_row = BS_B3norm, var_row_lab = colnames(E),\n                 var_col = BS_C3norm, var_col_lab = colnames(T_),\n                 row_color = params$colsite, col_color = params$colspp,\n                 eig = lambda) +\n  ggtitle(\"LC scores for sites\")\n\ngrid.arrange(grobs = list(gwa, glc),\n             nrow = 2)"
  },
  {
    "objectID": "dcCA.html#more-tests",
    "href": "dcCA.html#more-tests",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "More tests",
    "text": "More tests\nBelow, we test the variances of various scores.\n\n# Since ter Braak and ade4 disagree, check the variance of co and Z2 or Z2 (it should be the eigenvalues of each axis)\n\n#' Get the variance of vector x\n#'\n#' @param x The vector\n#' @param w The weights\n#'\n#' @return The variance\nvarvec &lt;- function(x, w) {\n  sum(w*(x-mean(x))^2)\n}\n\nres_ade4 &lt;- apply(as.matrix(dcca$co), \n                  2, \n                  function(x) varvec(x, dcca$cw))\nres_ade4/dcca$eig\n\n   Comp1    Comp2    Comp3    Comp4    Comp5    Comp6 \n1.106286 1.151797 1.466209 1.038659 1.005454 1.000003 \n\nres_tB &lt;- apply(Z2*scaling, \n                2, \n                function(x) varvec(x, dcca$cw))\nres_tB/dcca$eig \n\n[1] 1.106286 1.151797 1.466209 1.038659 1.005454 1.000003\n\nres_agree &lt;- apply(Z2*scaling, \n                   2, \n                   function(x) varvec(x, dcca$cw))\nres_agree/dcca$eig\n\n[1] 1.106286 1.151797 1.466209 1.038659 1.005454 1.000003\n\n\n\nLC scores for rows:\n\n\n# l1 variances should be 1\napply(as.matrix(dcca$l1), \n      2, \n      function(x) varvec(x, dcca$lw))\n\n     RS1      RS2      RS3      RS4      RS5      RS6 \n1.014490 1.005249 1.002007 1.000012 1.000331 1.000000 \n\n# li variances should be eigenvalues\napply(as.matrix(dcca$li), \n      2, \n      function(x) varvec(x, dcca$lw))/dcca$eig\n\n   Axis1    Axis2    Axis3    Axis4    Axis5    Axis6 \n1.014490 1.005249 1.002007 1.000012 1.000331 1.000000 \n\n\n\nLC scores for columns\n\n\n# c1 variances should be 1\napply(as.matrix(dcca$c1), \n      2, \n      function(x) varvec(x, dcca$cw))\n\n     CS1      CS2      CS3      CS4      CS5      CS6 \n1.106286 1.151797 1.466209 1.038659 1.005454 1.000003 \n\n# co variances should be eigenvalues\napply(as.matrix(dcca$co), \n      2, \n      function(x) varvec(x, dcca$cw))/dcca$eig \n\n   Comp1    Comp2    Comp3    Comp4    Comp5    Comp6 \n1.106286 1.151797 1.466209 1.038659 1.005454 1.000003 \n\n\n\n# Z2 variances should be the eigenvalues\napply(Z2*scaling, \n      2, \n      function(x) varvec(x, dcca$cw))/dcca$eig\n\n[1] 1.106286 1.151797 1.466209 1.038659 1.005454 1.000003\n\n\n\nWA scores:\n\n\n# Hypothesis: these scires shound be the eigenvalues\napply(as.matrix(dcca$lsR), \n      2, \n      function(x) varvec(x, dcca$lw))/dcca$eig\n\n    Axis1     Axis2     Axis3     Axis4     Axis5     Axis6 \n 1.397739  1.490618  1.894509  3.367612  7.569186 16.600310 \n\n# co variances should be eigenvalues\napply(as.matrix(dcca$lsQ), \n      2, \n      function(x) varvec(x, dcca$cw))/dcca$eig\n\n    Comp1     Comp2     Comp3     Comp4     Comp5     Comp6 \n 1.356947  1.416201  2.521861  7.980247  5.161038 13.632366"
  },
  {
    "objectID": "dcCA.html#interpretation",
    "href": "dcCA.html#interpretation",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Interpretation",
    "text": "Interpretation\nThis method finds the linear correlation of row explanatory variables (environmental variables) and the linear correlation of columns explanatory variables (species traits) that maximizes the fourth-corner correlation, i.e. the correlation between these linear combinations of row and columns-variables.\nThere are other related methods, that have been better described and also more used in ecology: RLQ, community weighted means RDA (CMW-RDA).\nContrary to RLQ, dc-CA takes into account the correlation between the row and column variables. Thus, while RLQ can analyze any number of row and column variables, it is not the case with dc-CA the number of row and column variables must not be large compared to the number of rows/columns in the tables. Also, CCA maximizes correlation and RLQ maximizes covariance (Braak, Šmilauer, and Dray 2018).\nThe eigenvalues of dc-CA are the squares of the fourth-corner correlations."
  }
]