[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "This website aims at summarizing the theory behind different methods to analyze count data:\nIt also describers reciprocal scaling (Thioulouse and Chessel 1992), which is a method to compute and visualize the dispersion among count tables analyzed with multivariate methods."
  },
  {
    "objectID": "index.html#dataset",
    "href": "index.html#dataset",
    "title": "Introduction",
    "section": "Dataset",
    "text": "Dataset\nThroughout this document, we will use the data from (Barbaro et al. 2012) on bird species distribution in New Zealand extracted from the CESTES database (Jeliazkov et al. 2020).\nThroughout this document, we will analyze a matrix \\(Y\\) (\\(r \\times c\\)) and two associated matrices \\(E\\) (\\(r \\times e\\)) and \\(T\\) (\\(t \\times c\\)). In our example:\n\n\\(Y\\) (\\(r =\\) 26 \\(\\times\\) \\(c =\\) 21) represents bird species counts in different sites\n\\(E\\) (\\(r =\\) 26 \\(\\times\\) \\(l =\\) 6) represents environmental variables in different sites\n\\(T\\) (\\(c =\\) 21 \\(\\times\\) \\(k =\\) 7) represents bird species traits"
  },
  {
    "objectID": "CA.html",
    "href": "CA.html",
    "title": "Correspondence analysis (CA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(ggplot2)\nsource(here(\"functions/plot.R\"))\nThe contents of this page relies heavily on (Legendre and Legendre 2012)."
  },
  {
    "objectID": "CA.html#introduction",
    "href": "CA.html#introduction",
    "title": "Correspondence analysis (CA)",
    "section": "Introduction",
    "text": "Introduction\nCorrespondence analysis (CA) was developed independently by several authors between the 1930s and 1960s. It has been mainly applied to analysis of ecological data tables (species \\(\\times\\) environment) such as the bat data we will analyze here.\nNotably, Hill discovered it in 1973 with an iterative method that he called reciprocal averaging. It involves ordering species with sites initially positioned randomly, reciprocally order sites with species, etc. This iterative procedure converges to reach the same results as what is achieved with CA’s first axis.\nCA is designed to analyze contingency tables (count tables) such \\(Y\\):\n\n\n\n\n\nHere is a preview of \\(Y\\) with our example dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n4\n0\n0\n0\n0\n2\n0\n4\n0\n2\n0\n4\n0\n0\n0\n0\n1\n5\n0\n0\n2\n\n\n2\n0\n0\n1\n0\n2\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n5\n1\n5\n1\n\n\n4\n0\n0\n0\n0\n0\n0\n2\n0\n0\n3\n0\n0\n0\n0\n0\n1\n1\n0\n0\n1\n\n\n2\n0\n1\n5\n0\n0\n0\n5\n0\n1\n1\n4\n0\n0\n0\n1\n2\n2\n0\n0\n2\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n2\n0\n0\n0\n4\n0\n1\n10\n3\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n4\n0\n2\n2\n4\n0\n0\n0\n0\n2\n1\n2\n0\n1\n\n\n5\n5\n0\n0\n1\n1\n0\n1\n0\n3\n0\n5\n0\n0\n0\n0\n0\n0\n1\n5\n1\n\n\n4\n0\n0\n1\n0\n2\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n3\n0\n0\n0\n1\n0\n0\n0\n0\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n5\n0\n4\n0\n1\n2\n0\n0\n0\n0\n0\n0\n1\n2\n0\n0\n\n\n4\n0\n1\n1\n0\n1\n0\n3\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n1\n0\n3\n2\n1\n2\n0\n0\n0\n0\n0\n0\n1\n3\n0\n0\n\n\n4\n2\n0\n1\n0\n0\n0\n2\n0\n2\n2\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n4\n0\n0\n1\n0\n2\n0\n2\n2\n2\n1\n1\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n4\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n5\n1\n0\n3\n0\n2\n0\n2\n1\n0\n2\n0\n0\n0\n0\n0\n0\n3\n1\n0\n0\n\n\n3\n5\n0\n4\n0\n2\n0\n5\n0\n4\n2\n0\n0\n1\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n2\n0\n7\n0\n1\n1\n0\n0\n4\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n6\n0\n0\n2\n0\n1\n0\n0\n0\n1\n3\n0\n0\n0\n0\n0\n0\n0\n3\n3\n0\n\n\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n\nThis table represents the abundance of different bird species (columns) at different sites (rows) in New Zealand.\nMore generally CA, can be used to analyze tables which are dimensionnally homogeneous and contain no negative values.\nCA preserves \\(\\chi^2\\) distances \\(D\\) between rows and columns of the contingency table:\n\\[\nD(x_1, x_2) = \\sqrt{\\sum_{j = 1}^p \\frac{1}{y_{\\cdot j}/y_{\\cdot \\cdot}}\\left(\\frac{y_{1j}}{y_{1\\cdot}} -  \\frac{y_{2j}}{y_{2\\cdot}}\\right)^2}\n\\]\nWhere \\(x_1\\) and \\(x_2\\) represent two items of the rows/columns. \\(p\\) is the number of rows (if \\(x_1\\) and \\(x_2\\) are items of columns) or columns else.\n\\(y_{\\cdot j}\\) represent either:\n\nif \\(x_1\\) and \\(x_2\\) are items of the columns: the sum of the \\(j\\)-th row. For a species x environment table, it is the total number of individuals in the \\(j\\)-th site.\nif \\(x_1\\) and \\(x_2\\) are items of the rows: the sum of the \\(j\\)-th column. For a species x environment table, it is the total number of individuals of the \\(j\\)-th species.\n\n\\(y_{\\cdot \\cdot}\\) is the sum of all individuals of the table.\n\\(\\frac{y_{1j}}{y_{1\\cdot}}\\) are relative frequencies of individuals per rows (if \\(x_1\\) and \\(x_2\\) are items of the rows) or columns.\nFor example, we compute the \\(\\chi^2\\) distance between sp1 and sp2:\n\n# Get how much each site contributed to the total count of species\nfreq &lt;- apply(Y, 2, FUN = function(x) x/sum(x))\n\n# Get total number of individuals of bats in all sites\n(ytot &lt;- sum(Y))\n\n[1] 493\n\nsqrt( sum(1/(rowSums(Y)/ytot)*(freq[, \"sp1\"] - freq[, \"sp2\"])^2 ) )\n\n[1] 2.090546\n\n\nAnd between sites 1 and 2:\n\n# Get the relative composition of species for each site\nfreq &lt;- t(apply(Y, 1, FUN = function(x) x/sum(x)))\n\nsqrt( sum(1/(colSums(Y)/ytot)*(freq[\"1\",] - freq[\"2\", ])^2 ) )\n\n[1] 2.563363"
  },
  {
    "objectID": "CA.html#computation",
    "href": "CA.html#computation",
    "title": "Correspondence analysis (CA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nGiven a data matrix \\(Y\\), we “center-scale” this matrix (\\(\\bar{Q}\\)).\nWe can diagonalize matrices \\(\\bar{Q} \\bar{Q'}\\) and \\(\\bar{Q}' \\bar{Q}\\).\n\\(U\\) (\\(c \\times c\\)) contains the loadings of the columns (species) of the contingency table.\n\\[\n\\bar{Q}' \\bar{Q} =  U \\Lambda U^{-1}\n\\]\n\\(\\hat{U}\\) (\\(r \\times c\\)) contains the loadings of the rows (sites) of the contingency table.\n\\[\n\\bar{Q} \\bar{Q}' =  \\hat{U} \\Lambda \\hat{U}^{-1}\n\\]\n\n\n\nTransform the table\n\nWe transform values of the contingency table \\(Y\\) with counts \\(f_{ij}\\) into proportions \\(p_{ij}\\):\n\\[\nP = Y/f_{\\cdot \\cdot}\n\\]\nWith our example data:\n\nP &lt;- Y/sum(Y)\n\nThen we transform values of this table into a quantity related to \\(\\chi^2\\) values \\(\\bar{Q}\\):\n\\[\n\\bar{Q} = [\\bar{q}_{ij}] = \\left[ \\frac{p_{ij} - p_{i\\cdot} p_{\\cdot j}}{\\sqrt{p_{i\\cdot} p_{\\cdot j}}} \\right]\n\\]\nThe \\(\\bar{q}_{ij}\\) values are equal to the \\(\\chi\\) values, a constant apart: \\(\\bar{q}_{ij} = \\chi_{ij}/\\sqrt{f_{\\cdot \\cdot}}\\).\nWith our data:\n\n# Initialize Qbar matrix\nQbar &lt;- matrix(ncol = ncol(Y), nrow = nrow(Y))\ncolnames(Qbar) &lt;- colnames(Y)\nrownames(Qbar) &lt;- rownames(Y)\n\nfor(i in 1:nrow(Y)) { # For each row\n  for (j in 1:ncol(Y)) { # For each column\n    # Do the sum\n    pi_ &lt;- sum(P[i, ])\n    p_j &lt;- sum(P[, j])\n    \n    # Compute the transformation\n    Qbar[i, j] &lt;- (P[i, j] - (pi_*p_j))/sqrt(pi_*p_j)\n  }\n}\n\n\nSingular value decomposition of \\(\\bar{Q}\\)\n\n\\[\n\\bar{Q} = \\hat{U}WU'\n\\]\nWhere \\(\\bar{Q}\\) is \\(r \\times c\\), \\(\\hat{U}\\) is \\(r \\times c\\), \\(W\\) is a \\(c \\times c\\) diagonal matrix (assuming \\(r \\geq c\\); the table can be transposed to meet this condition) and \\(U'\\) is \\(c \\times c\\).\nNote that the last eigenvalue of this SVD will always be null (due to the centering).\n\nsv &lt;- svd(Qbar)\n\nUhat &lt;- sv$u\nW &lt;- diag(sv$d)\nU &lt;- sv$v\nUprime &lt;- t(U)\n\nlength(sv$d)\n\n[1] 21\n\nsv$d # Last eigenvalue is zero\n\n [1] 5.498025e-01 4.925288e-01 4.329553e-01 4.040318e-01 3.433964e-01\n [6] 3.150413e-01 2.883515e-01 2.863913e-01 2.408812e-01 2.195224e-01\n[11] 1.962294e-01 1.587138e-01 1.429179e-01 1.242514e-01 1.095957e-01\n[16] 9.878630e-02 7.702202e-02 6.088389e-02 5.470965e-02 4.087652e-02\n[21] 6.653482e-17\n\n\nWith the SVD, we can rewrite \\(\\bar{Q}' \\bar{Q}\\):\n\\[\n\\bar{Q}' \\bar{Q} = U W' \\hat{U'} \\hat{U} W U'\n\\]\nWe have \\(\\hat{U}' \\hat{U} = I\\) (because \\(\\hat{U}\\) is orthonormal), so:\n\\[\n\\bar{Q}' \\bar{Q} =  U W' W U'\n\\]\nIf we rewrite \\(W' W\\) as \\(\\Lambda\\), and since \\(U' = U^{-1}\\) (\\(U\\) is orthonormal), then we can write this as a diagonalization:\n\\[\n\\bar{Q}' \\bar{Q} =  U \\Lambda U^{-1}\n\\]\nSimilarly, we can rewrite \\(\\bar{Q} \\bar{Q}'\\):\n\\[\n\\bar{Q} \\bar{Q}' =  \\hat{U} \\Lambda \\hat{U}^{-1}\n\\]\nWith that, we wouldn’t even need the SVD in the first place (a classical diagonalization of \\(\\bar{Q} \\bar{Q}'\\)/\\(\\bar{Q}' \\bar{Q}\\) works.)\n\nLambda &lt;- W %*% t(W)\nlambda &lt;- diag(Lambda)\n\n# Diagonalize Q'Q ---\ndg1 &lt;- eigen(t(Qbar) %*% Qbar)\n\n# Check eigenvalues\nlength(dg1$values)\n\n[1] 21\n\ndg1$values # Last value is zero\n\n [1]  3.022828e-01  2.425846e-01  1.874503e-01  1.632417e-01  1.179211e-01\n [6]  9.925099e-02  8.314661e-02  8.202000e-02  5.802375e-02  4.819010e-02\n[11]  3.850599e-02  2.519006e-02  2.042552e-02  1.543842e-02  1.201122e-02\n[16]  9.758733e-03  5.932391e-03  3.706847e-03  2.993146e-03  1.670890e-03\n[21] -9.451897e-18\n\n# Eigenvalues are equal to the SVD values\nall((dg1$values - lambda) &lt; 10e-10)\n\n[1] TRUE\n\n# Eigenvectors are equal to U\n# dg1$vectors\n# U\n\n# The vectors are in opposite directions so we use the absolute value\nall(abs(dg1$vectors[, 1:(c-1)]/U[, 1:(c-1)]) - 1 &lt; 10e-10)\n\n[1] TRUE\n\n\n\n# Diagonalize QQ' ---\ndg2 &lt;- eigen(Qbar %*% t(Qbar))\n\n# Check eigenvalues\nlength(dg2$values) # r eigenvalues\n\n[1] 26\n\ndg2$values # Last r - (c - 1) values are zero\n\n [1]  3.022828e-01  2.425846e-01  1.874503e-01  1.632417e-01  1.179211e-01\n [6]  9.925099e-02  8.314661e-02  8.202000e-02  5.802375e-02  4.819010e-02\n[11]  3.850599e-02  2.519006e-02  2.042552e-02  1.543842e-02  1.201122e-02\n[16]  9.758733e-03  5.932391e-03  3.706847e-03  2.993146e-03  1.670890e-03\n[21]  2.247433e-18  1.741751e-18  1.252738e-18 -6.541642e-18 -6.962632e-18\n[26] -1.862602e-17\n\n# Eigenvalues are equal to the SVD values\n# We test only the first values, the rest are zero\nall((dg2$values[1:c] - lambda) &lt; 10e-10)\n\n[1] TRUE\n\n# Eigenvectors are equal to Uhat (we test only eigenvectors for non-null eigenvalues)\nall(abs(dg2$vectors[, 1:(c-1)]/Uhat[, 1:(c-1)]) - 1 &lt; 10e-10)\n\n[1] TRUE"
  },
  {
    "objectID": "CA.html#scalings",
    "href": "CA.html#scalings",
    "title": "Correspondence analysis (CA)",
    "section": "Scalings",
    "text": "Scalings\n\n\n\n\n\n\nTL;DR\n\n\n\nOnce we diagonalized the stuff, there is still a question of scaling to plot them in the multivariate plane.\nColumns (species) can be represented with:\n\n\\(U\\) (the matrix of eigenvectors : \\(\\bar{Q}'Q = U \\Lambda U^{-1}\\)) (unscaled)\n\\(V = D(p_{\\cdot j})^{-1/2} U\\) (scaling type 1)\n\\(\\hat{F} = V \\Lambda^{1/2}\\) (scaling type 2)\n\\(V \\Lambda^{1/4}\\) (scaling type 3).\n\nRows (sites) can be represented with:\n\n\\(\\hat{U}\\) (the matrix of eigenvectors: \\(\\bar{Q} \\bar{Q}' = \\hat{U} \\Lambda \\hat{U}^{-1}\\)) (unscaled)\n\\(\\hat{V} = D(p_{i \\cdot})^{-1/2} \\hat{U}\\) (scaling type 2)\n\\(F = \\hat{V} \\Lambda^{1/2}\\) (scaling type 1)\n\\(\\hat{V} \\Lambda^{1/4}\\) (scaling type 3)\n\n\n\nThere are several scalings used in CA, which are useful to plot both variables on the same plot (biplot).\nFirst, the original coordinates are scaled to the square root of the margins of the proportion matrix.\n\nFor the columns (species), we have \\(V = D(p_{\\cdot j})^{-1/2} U\\).\nFor the rows (sites), we have \\(\\hat{V} = D(p_{i \\cdot})^{-1/2} \\hat{U}\\).\n\nTo get the position of these in the multivariate space, we have to use \\(\\Lambda\\):\n\nPosition of the columns (species) in the multivariate space (\\(U\\)): \\(\\hat{F} = V \\Lambda^{1/2}\\)\nPosition of the rows (sites) in the multivariate space (\\(\\hat{U}\\)): \\(F = \\hat{V} \\Lambda^{1/2}\\)\n\nSince these examples do not take into account the null eigenvalues, one column (= multivariate axis) will be discarded as it is not interpretable.\nWith our example, we have:\n\n# Scale species (columns)\nV &lt;- diag(1/sqrt(colSums(P))) %*% U\ndim(V)\n\n[1] 21 21\n\n# Get species coordinates in the multivariate space (columns)\nFhat &lt;- V %*% diag(sqrt(lambda))\ndim(Fhat)\n\n[1] 21 21\n\nall(Fhat[, ncol(Fhat)] &lt; 10e-10) # The last values will be discarded (all coordinates are zero)\n\n[1] TRUE\n\n\n\n# Scale sites (rows)\nVhat &lt;- diag(1/sqrt(rowSums(P))) %*% Uhat\ndim(Vhat)\n\n[1] 26 21\n\n# Get sites coordinates in the multivariate space (rows)\nF_ &lt;- Vhat %*% diag(sqrt(lambda))\ndim(F_)\n\n[1] 26 21\n\nall(F_[, ncol(F_)] &lt; 10e-10) # The last values discarded (all coordinates are zero)\n\n[1] TRUE\n\n\nThese transformed coordinates that are used in the outputs of dudi.coa.\n\nca &lt;- dudi.coa(Y, \n               nf = c-1, scannf = FALSE)\n\n# Species (columns)\nall(abs(ca$co/Fhat[, 1:(c-1)]) - 1 &lt; 10e-10)\n\n# Sites (rows)\nall(abs(ca$li/F_[, 1:(c-1)]) - 1 &lt; 10e-10)\n\nNow, there are different types of scalings for biplots. Below, we assume a sites x species matrix:\n\nType 1: use \\(F\\) (sites) and and \\(V\\) (species). This preserves \\(\\chi^2\\) distances between sites on the plot. Here, sites are positioned at the centroid of species.\n\n\n\nCode\nplot(x = V[, 1], y = V[, 2],\n     col = NULL,\n     asp = 1)\ntext(x = V[, 1], y = V[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\ntext(x = F_[, 1], y = F_[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\n\nType 2: use \\(\\hat{F}\\) (species) and and \\(\\hat{V}\\) (sites). This preserves \\(\\chi^2\\) distances between species on the plot. Here, species are positioned at the centroid of sites.\n\n\n\nCode\nplot(x = Vhat[, 1], y = Vhat[, 2],\n     col = NULL,\n     asp = 1)\ntext(x = Vhat[, 1], y = Vhat[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\ntext(x = Fhat[, 1], y = Fhat[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\n\nType 3: a compromise between scalings 1 and 2. It preserves none of the \\(\\chi^2\\) distances and is obtained with \\(\\hat{V}\\Lambda^{1/4}\\) (for sites) and \\(V\\Lambda^{1/4}\\) (for species).\n\n\n\nCode\nsites &lt;- Vhat %*% diag(lambda^(1/4))\nspp &lt;- V %*% diag(lambda^(1/4))\n\nplot(x = spp[, 1], y = spp[, 2],\n     col = NULL,\n     ylim = c(-5, 5),\n     xlim = c(-5, 5),\n     asp = 1)\ntext(x = sites[, 1], y = sites[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\ntext(x = spp[, 1], y = spp[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\n\nType 4: use \\(F\\) (sites) and \\(\\hat{F}\\) (species). Then, both \\(\\chi^2\\) distances are preserved. It is useful for a table crossing two factors.\n\n\n\nCode\nplot(x = F_[, 1], y = F_[, 2],\n     col = NULL,\n     ylim = c(-2, 2),\n     xlim = c(-2.5, 1),\n     asp = 1)\ntext(x = F_[, 1], y = F_[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\ntext(x = Fhat[, 1], y = Fhat[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\n\nabline(h = 0)\nabline(v = 0)"
  },
  {
    "objectID": "CA.html#interpretation",
    "href": "CA.html#interpretation",
    "title": "Correspondence analysis (CA)",
    "section": "Interpretation",
    "text": "Interpretation\n\\(V\\) and \\(\\hat{V}\\) are related with the following equation:\n\\[\n\\hat{V} \\Lambda^{1/2} = D(p_{i\\cdot})^{-1/2}\\bar{Q}D(p_{\\cdot j})^{1/2}V\n\\]\nThis equation relates the ordination of rows (sites) (\\(\\hat{V}\\)) to the ordination of columns (species) (\\(V\\)). The “conversion factor” is \\(\\Lambda^{1/2}\\), which translates to \\(\\sqrt{\\lambda_h}\\) along principal axis \\(h\\).\nIndeed, the eigenvalue \\(\\lambda_h\\) is a measure of the correlation of the rows and columns ordinations along axis \\(h\\).\nIf species have a unimodal (bell-shaped) response along the gradient defined by the sites ordination along a given axis, then their position should be close to their niche optimum.\nDepending on he position of, say, species, in the multivariate space, there are several interpretations:\n\nspecies that are absent from most sites: often at the edge, close to a site where they happen to be present. They have little influence on the analysis.\nspecies that are in the center: either have their optimum there, they have a multimodal niche or their niche is not influenced by the latent variables of the ordination axes.\nspecies found away from the center but not at the edges: more likely to display clear relationships with the axis\n\n\n\n\n\n\n\nNote\n\n\n\nRare species are generally not very interesting because they are exceptions, not a general tendency. So some authors propose strategies to remove them, notably an iterative procedure. First do the complete CA, then remove the species seen one, twice… etc. Note the total inertia and the eigenvalues. When there is a jump, stop.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen there is a succession of species, along an hypothetical gradient, the CA may lead to an arch shape. There are techniques to detrend it, but knowing how to interpret this effect is probably more important."
  },
  {
    "objectID": "CCA.html",
    "href": "CCA.html",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(ggplot2)\nsource(here(\"functions/plot.R\"))\nThe contents of this page relies heavily on (Legendre and Legendre 2012)."
  },
  {
    "objectID": "CCA.html#introduction",
    "href": "CCA.html#introduction",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Introduction",
    "text": "Introduction\nCCA is a method of the family of canonical or direct gradient analyses, in which a matrix of predictor variables intervenes in the computation of the ordination vectors.\nCCA is an asymmetric method because the predictor variables and the response variables are not equivalent in the analysis.\nCCA takes two matrices in input:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables \\(E\\) (\\(r \\times l\\))\n\n\n\n\n\n\nHere, \\(Y\\) represents the abundance of different bird species (columns) at different sites (rows):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n4\n0\n0\n0\n0\n2\n0\n4\n0\n2\n0\n4\n0\n0\n0\n0\n1\n5\n0\n0\n2\n\n\n2\n0\n0\n1\n0\n2\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n5\n1\n5\n1\n\n\n4\n0\n0\n0\n0\n0\n0\n2\n0\n0\n3\n0\n0\n0\n0\n0\n1\n1\n0\n0\n1\n\n\n2\n0\n1\n5\n0\n0\n0\n5\n0\n1\n1\n4\n0\n0\n0\n1\n2\n2\n0\n0\n2\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n2\n0\n0\n0\n4\n0\n1\n10\n3\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n4\n0\n2\n2\n4\n0\n0\n0\n0\n2\n1\n2\n0\n1\n\n\n5\n5\n0\n0\n1\n1\n0\n1\n0\n3\n0\n5\n0\n0\n0\n0\n0\n0\n1\n5\n1\n\n\n4\n0\n0\n1\n0\n2\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n3\n0\n0\n0\n1\n0\n0\n0\n0\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n5\n0\n4\n0\n1\n2\n0\n0\n0\n0\n0\n0\n1\n2\n0\n0\n\n\n4\n0\n1\n1\n0\n1\n0\n3\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n1\n0\n3\n2\n1\n2\n0\n0\n0\n0\n0\n0\n1\n3\n0\n0\n\n\n4\n2\n0\n1\n0\n0\n0\n2\n0\n2\n2\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n4\n0\n0\n1\n0\n2\n0\n2\n2\n2\n1\n1\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n4\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n5\n1\n0\n3\n0\n2\n0\n2\n1\n0\n2\n0\n0\n0\n0\n0\n0\n3\n1\n0\n0\n\n\n3\n5\n0\n4\n0\n2\n0\n5\n0\n4\n2\n0\n0\n1\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n2\n0\n7\n0\n1\n1\n0\n0\n4\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n6\n0\n0\n2\n0\n1\n0\n0\n0\n1\n3\n0\n0\n0\n0\n0\n0\n0\n3\n3\n0\n\n\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n\n\n\n\n\n\\(E\\) represents environmental variables (columns) associated to each site (rows).\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n0\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n0\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n0\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n0\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n0\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n0\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n1\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n1\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n1\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n1\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n1\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n1\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- dim(E)[2])\n\n[1] 6"
  },
  {
    "objectID": "CCA.html#computation",
    "href": "CCA.html#computation",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nWe have a data matrix \\(Y\\) (\\(r \\times c\\)) and a matrix \\(E\\) (\\(r \\times l\\)) of predictors variables.\nWe regress \\(\\bar{Q}\\) (“centered” \\(Y\\)) on \\(E_{stand}\\) (which is the centered and scaled \\(E\\) matrix):\n\\[\n\\hat{\\bar{Q}} = D(p_{i\\cdot})^{1/2} E_{stand}B\n\\]\nThen, we diagonalize matrix \\(S_{\\hat{\\bar{Q}}'\\hat{\\bar{Q}}} = \\hat{\\bar{Q}}'\\hat{\\bar{Q}}\\).\n\\[\nS_{\\hat{\\bar{Q}}'\\hat{\\bar{Q}}} =  U \\Lambda U^{-1}\n\\]\nThe matrix \\(U\\) (\\(c \\times \\text{mindim}\\)) contains the loadings of the columns (species) of the contingency table. There are \\(\\text{mindim} = \\min(r-1, c, l)\\) non-null eigenvalues.\nThen, we can find the loadings rows (sites) \\(\\hat{U}\\) (\\(r \\times \\text{mindim}\\)) from the columns (species) loadings using the following formula:\n\\[\n\\hat{U} = \\bar{Q} U \\Lambda^{-1/2}\n\\]\n\n\n\nTransform matrix\nWe start by “centering” the matrix \\(Y\\) to get \\(\\bar{Q}\\) (as with CA).\nHere, we have:\n\n\nCode\nP &lt;- Y/sum(Y)\n\n# Initialize Qbar matrix\nQbar &lt;- matrix(ncol = ncol(Y), nrow = nrow(Y))\ncolnames(Qbar) &lt;- colnames(Y)\nrownames(Qbar) &lt;- rownames(Y)\n\nfor(i in 1:nrow(Y)) { # For each row\n  for (j in 1:ncol(Y)) { # For each column\n    # Do the sum\n    pi_ &lt;- sum(P[i, ])\n    p_j &lt;- sum(P[, j])\n    \n    # Compute the transformation\n    Qbar[i, j] &lt;- (P[i, j] - (pi_*p_j))/sqrt(pi_*p_j)\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n-0.0246174\n-0.0235678\n0.1819102\n0.0177849\n-0.0086058\n0.0190444\n-0.0060852\n0.0389306\n-0.0172115\n0.0177849\n0.0142185\n-0.0285421\n-0.0121704\n-0.0086058\n-0.0172115\n-0.0136069\n-0.0172115\n-0.0425963\n0.0259875\n-0.0227687\n-0.0250899\n\n\n-0.0700532\n-0.0430288\n-0.0192431\n-0.0075494\n-0.0157119\n-0.0362309\n-0.0111100\n0.0317935\n-0.0314238\n-0.0075494\n-0.0702658\n0.0257394\n0.3429284\n-0.0157119\n0.1622254\n0.2201063\n-0.0314238\n0.0004761\n-0.0290665\n-0.0415698\n0.0427538\n\n\n0.0325898\n-0.0342433\n-0.0153141\n0.0216502\n-0.0125039\n-0.0148135\n-0.0088416\n-0.0092517\n-0.0250078\n-0.0160655\n0.0166286\n-0.0414707\n-0.0176832\n-0.0125039\n-0.0250078\n-0.0197704\n-0.0250078\n0.0364300\n0.0331807\n-0.0330822\n0.0191867\n\n\n0.0149125\n-0.0283250\n-0.0126673\n-0.0444862\n-0.0103428\n0.0023441\n-0.0073135\n0.0865729\n0.0773724\n-0.0444862\n-0.0024017\n-0.0343033\n-0.0146270\n-0.0103428\n-0.0206857\n-0.0163535\n-0.0206857\n0.0280484\n-0.0407198\n-0.0273646\n0.0371130\n\n\n0.0381182\n-0.0333300\n-0.0149056\n-0.0135976\n-0.0121704\n-0.0123509\n-0.0086058\n-0.0058019\n-0.0243408\n-0.0523468\n0.0573758\n-0.0403646\n-0.0172115\n-0.0121704\n-0.0243408\n0.0861662\n-0.0243408\n0.0407749\n-0.0055815\n-0.0321998\n0.0216837\n\n\n-0.0648859\n-0.0351329\n-0.0157119\n-0.0184176\n-0.0128287\n0.0201080\n-0.0090713\n0.0163368\n0.0533995\n0.0183431\n-0.0220164\n-0.0425480\n-0.0181425\n-0.0128287\n0.0533995\n-0.0202840\n0.0533995\n0.0003888\n0.0298152\n-0.0339416\n0.1252960\n\n\n-0.0121284\n-0.0384861\n-0.0172115\n-0.0604449\n-0.0140532\n0.0084189\n-0.0099371\n0.0284370\n-0.0281063\n0.0066707\n-0.0628476\n0.1274686\n-0.0198742\n-0.0140532\n-0.0281063\n-0.0222200\n0.0440625\n0.0762434\n-0.0553273\n-0.0371811\n0.0580431\n\n\n-0.0383974\n-0.0342433\n-0.0153141\n-0.0160655\n-0.0125039\n0.0234224\n-0.0088416\n-0.0684866\n-0.0250078\n-0.0537812\n-0.0196452\n0.0074409\n-0.0176832\n-0.0125039\n-0.0250078\n-0.0197704\n-0.0250078\n0.1019773\n-0.0080236\n0.2734875\n0.0191867\n\n\n0.0509731\n-0.0272138\n-0.0121704\n-0.0427410\n-0.0099371\n-0.0421595\n-0.0070266\n0.0201080\n-0.0198742\n-0.0427410\n0.0924907\n-0.0329576\n-0.0140532\n-0.0099371\n-0.0198742\n-0.0157119\n0.0821879\n-0.0079467\n-0.0391223\n-0.0262910\n0.0410427\n\n\n-0.0598219\n-0.0400576\n0.0953134\n0.0982934\n-0.0146270\n-0.0620570\n-0.0103428\n0.0464771\n-0.0292540\n-0.0306717\n-0.0344052\n0.1187362\n-0.0206857\n-0.0146270\n-0.0292540\n0.0645785\n0.1094211\n-0.0163667\n-0.0575865\n-0.0386994\n0.0524857\n\n\n-0.0770633\n-0.0451290\n-0.0201823\n-0.0136415\n-0.0164788\n-0.0409006\n-0.0116523\n0.0221086\n-0.0329576\n-0.0136415\n-0.0186472\n-0.0546539\n-0.0233045\n-0.0164788\n0.2132254\n-0.0260552\n0.0285882\n0.1671166\n0.0289188\n-0.0435988\n-0.0058235\n\n\n-0.0082886\n-0.0376758\n-0.0168491\n-0.0591722\n-0.0137573\n-0.0236147\n-0.0097279\n0.0323248\n-0.0275145\n0.0093869\n0.0044137\n0.1321940\n-0.0194557\n-0.0137573\n-0.0275145\n-0.0217521\n0.1199274\n-0.0383072\n0.0207382\n-0.0363983\n0.0104632\n\n\n-0.0066028\n0.2024052\n-0.0185906\n-0.0652879\n0.1184515\n-0.0329026\n-0.0107333\n-0.0587421\n-0.0303583\n0.0279175\n-0.0678832\n0.1511122\n-0.0214665\n-0.0151791\n-0.0303583\n-0.0240003\n-0.0303583\n-0.0751329\n-0.0258181\n0.2123779\n0.0015805\n\n\n0.0509731\n-0.0272138\n-0.0121704\n0.0047169\n-0.0099371\n0.0540656\n-0.0070266\n-0.0544276\n-0.0198742\n0.0047169\n0.0468471\n-0.0329576\n-0.0140532\n-0.0099371\n-0.0198742\n-0.0157119\n-0.0198742\n-0.0491860\n0.0645729\n-0.0262910\n-0.0289713\n\n\n0.0537748\n-0.0222200\n-0.0099371\n-0.0348979\n0.2418864\n-0.0344230\n-0.0057372\n-0.0444400\n-0.0162272\n0.1394736\n-0.0362851\n0.0484681\n-0.0114743\n-0.0081136\n-0.0162272\n-0.0128287\n-0.0162272\n-0.0401602\n-0.0319432\n-0.0214665\n-0.0236550\n\n\n-0.0105035\n-0.0333300\n-0.0149056\n-0.0523468\n-0.0121704\n0.1447840\n-0.0086058\n0.0550562\n-0.0243408\n-0.0135976\n0.0201080\n-0.0403646\n-0.0172115\n-0.0121704\n-0.0243408\n-0.0192431\n-0.0243408\n-0.0265686\n0.0367519\n-0.0321998\n-0.0354825\n\n\n0.0303585\n-0.0304260\n0.1354643\n-0.0053382\n-0.0111100\n-0.0041026\n-0.0078559\n0.0391481\n0.0690671\n0.0371094\n-0.0496854\n-0.0368477\n-0.0157119\n-0.0111100\n-0.0222200\n-0.0175664\n-0.0222200\n0.0187795\n-0.0437401\n-0.0293943\n-0.0323909\n\n\n0.0325898\n-0.0342433\n-0.0153141\n-0.0160655\n-0.0125039\n-0.0148135\n-0.0088416\n0.0203657\n0.1372137\n-0.0160655\n0.0166286\n-0.0414707\n-0.0176832\n-0.0125039\n-0.0250078\n-0.0197704\n-0.0250078\n-0.0291174\n0.0743850\n-0.0330822\n-0.0364548\n\n\n0.0244779\n0.0976756\n-0.0140532\n-0.0082533\n-0.0114743\n-0.0486815\n-0.0081136\n0.0017021\n-0.0229487\n0.0328465\n0.0277421\n-0.0380561\n-0.0162272\n0.1653023\n-0.0229487\n-0.0181425\n-0.0229487\n-0.0210808\n-0.0002732\n-0.0303583\n-0.0334532\n\n\n0.0189774\n-0.0323909\n-0.0144857\n-0.0109993\n-0.0118275\n0.0306654\n-0.0083633\n-0.0021594\n0.1478436\n0.0288733\n-0.0145459\n0.0124814\n-0.0167266\n-0.0118275\n-0.0236550\n-0.0187009\n-0.0236550\n0.0107528\n-0.0465649\n-0.0312926\n-0.0344828\n\n\n0.0502635\n-0.0314238\n-0.0140532\n-0.0082533\n-0.0114743\n0.1179851\n-0.0081136\n-0.0628476\n-0.0229487\n-0.0493530\n0.1067990\n-0.0380561\n-0.0162272\n-0.0114743\n-0.0229487\n-0.0181425\n-0.0229487\n-0.0567951\n0.0446281\n-0.0303583\n-0.0334532\n\n\n0.0273672\n0.0226022\n-0.0157119\n0.0551038\n-0.0128287\n0.0201080\n-0.0090713\n-0.0125307\n0.0533995\n-0.0551784\n0.0133389\n-0.0425480\n-0.0181425\n-0.0128287\n-0.0256574\n-0.0202840\n-0.0256574\n0.0323326\n-0.0103457\n-0.0339416\n-0.0374018\n\n\n-0.0455868\n0.2024052\n-0.0185906\n0.0589860\n-0.0151791\n-0.0014055\n-0.0107333\n0.0388479\n-0.0303583\n0.0589860\n-0.0081217\n-0.0503435\n-0.0214665\n0.1184515\n-0.0303583\n-0.0240003\n-0.0303583\n-0.0211380\n-0.0597603\n-0.0401602\n-0.0442544\n\n\n0.0089254\n0.0669231\n-0.0172115\n0.1744597\n-0.0140532\n-0.0256018\n0.1941871\n-0.0769723\n-0.0281063\n0.0737863\n0.0017021\n-0.0466090\n-0.0198742\n-0.0140532\n-0.0281063\n-0.0222200\n-0.0281063\n-0.0695595\n0.0179962\n-0.0371811\n-0.0409716\n\n\n0.0562523\n-0.0342433\n-0.0153141\n0.0216502\n-0.0125039\n-0.0148135\n-0.0088416\n-0.0684866\n-0.0250078\n-0.0160655\n0.0529024\n-0.0414707\n-0.0176832\n-0.0125039\n-0.0250078\n-0.0197704\n-0.0250078\n-0.0618911\n0.0743850\n0.1508596\n-0.0364548\n\n\n0.0649207\n-0.0207849\n-0.0092953\n-0.0326440\n-0.0075896\n0.0307943\n-0.0053666\n-0.0415698\n-0.0151791\n-0.0326440\n0.0258198\n-0.0251718\n-0.0107333\n-0.0075896\n-0.0151791\n-0.0120002\n-0.0151791\n-0.0375664\n0.0380043\n0.0809351\n-0.0221272\n\n\n\n\n\n\n\nWeights on \\(E\\)\nWe standardize \\(E\\) as \\(E_{stand}\\), but we standardize so that the variables associated to the sites wihch have more observations have more weight.\nTo do that, we use the inflated matrix \\(E_{infl}\\) to compute its mean \\(\\bar{E}_{infl}\\) and standard deviation \\(\\sigma(E_{infl})\\) per column. In \\(E_{infl}\\), the rows corresponding to each site are duplicates as many times as there are observations for this given site (so that \\(E_{infl}\\) is of dimension \\(y_{\\cdot \\cdot} \\times l\\)).\n\\[\nE_{stand} = \\frac{E - \\bar{E}_{infl}}{\\sigma(E_{infl})}\n\\]\nWith our data: first, we compute \\(E_{infl}\\):\n\n\nCode\nEinfl &lt;- matrix(data = 0,\n                ncol = ncol(E), \n                nrow = sum(Y))\ncolnames(Einfl) &lt;- colnames(E)\nrownames(Einfl) &lt;- 1:nrow(Einfl)\n\n# Get the number of times to duplicate each site\nnrep_sites &lt;- rowSums(Y)\n\nnrstart &lt;- 0\nfor (i in 1:nrow(E)) {\n  ri &lt;- as.matrix(E)[i, ]\n  \n  rname &lt;- rownames(E)[i]\n  \n  # Get how many times to duplicate this site\n  nr &lt;- nrep_sites[as.character(rname)]\n  \n  Einfl[(nrstart+1):(nrstart+nr), ] &lt;- matrix(rep(ri, nr), \n                                              nrow = nr, \n                                              byrow = TRUE)\n  \n  rownames(Einfl)[(nrstart+1):(nrstart+nr)] &lt;- paste(rname,\n                                                     1:nr,\n                                                     sep = \"_\")\n  nrstart &lt;- nrstart + nr\n}\npaste(\"Dimension:\", paste(dim(Einfl), collapse = \" \"))\n\n\n[1] \"Dimension: 493 6\"\n\n\nCode\nknitr::kable(head(Einfl, 10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n1_1\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_2\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_3\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_4\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_5\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_6\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_7\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_8\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1_9\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n2_1\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n\n\n\nThen, we compute the mean and standard deviation per column and standardize \\(E\\).\n\nEinfl_mean &lt;- apply(Einfl, 2, mean)\n\nn &lt;- nrow(Einfl)\nEinfl_sd &lt;- apply(Einfl, 2, \n                  function(x) sd(x)*sqrt((n-1)/n))\n\n\nEstand &lt;- scale(E, \n                center = Einfl_mean,\n                scale = Einfl_sd)\nknitr::kable(Estand)\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n-0.8940191\n-1.4578384\n-0.5429520\n-1.0404731\n1.0369741\n-1.0351817\n\n\n-0.8940191\n-1.3502706\n-0.5081483\n-0.3311255\n-0.4345644\n1.0954816\n\n\n-0.8940191\n0.8010856\n1.0902771\n0.3301082\n-1.3346326\n1.0954816\n\n\n-0.8940191\n0.7473017\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n-0.8940191\n0.6397339\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n-0.8940191\n1.1775730\n-0.6656140\n-1.0605165\n0.9946790\n-0.6293411\n\n\n-0.8940191\n1.0162212\n-0.5098460\n-0.0929573\n0.3501447\n0.0301499\n\n\n-0.8940191\n-0.9199993\n-0.2273840\n0.2490300\n-0.0430582\n0.4867206\n\n\n-0.8940191\n0.9624373\n-0.1495000\n0.0784846\n0.3887809\n-0.4771509\n\n\n-0.8940191\n0.9086534\n-0.6102251\n-1.2838968\n1.3976330\n-1.8468630\n\n\n-0.8940191\n-1.2964867\n-0.5348877\n-1.0664053\n0.9299593\n-0.6293411\n\n\n-0.8940191\n-0.6510798\n-0.5567462\n0.9797698\n-0.3354772\n0.0301499\n\n\n-0.8940191\n-0.6510798\n-0.4429974\n0.7628294\n-1.9186435\n1.9578929\n\n\n1.1185444\n-1.4578384\n-0.5429520\n-1.0404731\n1.0369741\n-1.0351817\n\n\n1.1185444\n-1.3502706\n-0.5081483\n-0.3311255\n-0.4345644\n1.0954816\n\n\n1.1185444\n0.8010856\n1.0902771\n0.3301082\n-1.3346326\n1.0954816\n\n\n1.1185444\n0.7473017\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n1.1185444\n0.6397339\n2.3124400\n1.7730331\n-0.9879574\n0.3852605\n\n\n1.1185444\n1.1775730\n-0.6656140\n-1.0605165\n0.9946790\n-0.6293411\n\n\n1.1185444\n1.0162212\n-0.5098460\n-0.0929573\n0.3501447\n0.0301499\n\n\n1.1185444\n-0.9199993\n-0.2273840\n0.2490300\n-0.0430582\n0.4867206\n\n\n1.1185444\n0.9624373\n-0.1495000\n0.0784846\n0.3887809\n-0.4771509\n\n\n1.1185444\n0.9086534\n-0.6102251\n-1.2838968\n1.3976330\n-1.8468630\n\n\n1.1185444\n-1.2964867\n-0.5348877\n-1.0664053\n0.9299593\n-0.6293411\n\n\n1.1185444\n-0.6510798\n-0.5567462\n0.9797698\n-0.3354772\n0.0301499\n\n\n1.1185444\n-0.6510798\n-0.4429974\n0.7628294\n-1.9186435\n1.9578929\n\n\n\n\n\n\n\nRegression\nAfter that, we perform the weighted multiple linear regression of \\(\\bar{Q}\\) by \\(E_{stand}\\). Each row of \\(\\bar{Q}\\) \\(\\bar{q}\\) is approximated by \\(\\hat{\\bar{q}}\\) using multiple linear regression on \\(E_{stand}\\): \\(\\hat{\\bar{q}} = b_0 + b_1 e_{1} + \\ldots + b_e e_{l}\\), where \\(e_i\\) are columns of \\(E_{stand}\\) and \\(b_i\\) are regression coefficients. In a matrix form, it is written:\n\\[\n\\hat{\\bar{Q}} = D(p_{i\\cdot})^{1/2}E_{stand}B\n\\]\nWhere\n\\[\nB = [E_{stand}' D(p_{i\\cdot}) E_{stand}]^{-1}E_{stand}'D(p_{i\\cdot})^{1/2}\\bar{Q}\n\\]\nWith our example:\n\n# Diagonal matrix weights\nDpi_ &lt;-  diag(rowSums(P))\ncolnames(Dpi_) &lt;- rownames(P)\n\n# Regression coefficient\nB &lt;- solve(t(Estand) %*% Dpi_ %*% Estand) %*% t(Estand) %*% sqrt(Dpi_) %*% Qbar\n\nNow, we can get the predicted values for \\(\\bar{Q}\\). For instance, let’s plot predicted vs observed values for site 2:\n\n# Compute predicted values\nQbarhat &lt;- sqrt(Dpi_) %*% Estand %*% B\ncolnames(Qbarhat) &lt;- colnames(Qbar)\nrownames(Qbarhat) &lt;- rownames(Qbar)\ndim(Qbarhat)\n\n[1] 26 21\n\n# Get predicted and observed values for one site\nind &lt;- 2\n\npred &lt;- Qbarhat[ind, ]\nobs &lt;- Qbar[ind, ]\n\n\n\nCode\ndf &lt;- data.frame(pred, obs, names = names(pred))\ndf&lt;- df |&gt; \n  tidyr::pivot_longer(cols = c(\"pred\", \"obs\"))\n\nggplot(df, aes(x = names, y = value, col = name)) +\n  geom_point() +\n  theme_linedraw() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\nDiagonalization\nThen, we diagonalize the covariance matrix of predicted values \\(S_{\\hat{\\bar{Q}}' \\hat{\\bar{Q}}}\\).\nFirst, we compute the covariance matrix (note that here we don’t divide by the degrees of freedom).\n\\[\nS_{\\hat{\\bar{Q}}' \\hat{\\bar{Q}}} = \\hat{\\bar{Q}}' \\hat{\\bar{Q}}\n\\]\n\nSqq &lt;- t(Qbarhat) %*% Qbarhat\n\nWe diagonalize \\(S_{\\hat{\\bar{Q}}' \\hat{\\bar{Q}}}\\):\n\\[\nS_{\\hat{\\bar{Q}}' \\hat{\\bar{Q}}} = U \\Lambda U^{-1}\n\\]\n\\(\\Lambda\\) is the matrix of eigenvalues (there are \\(\\min(r-1, c, l)\\) non-null eigenvalues) and \\(U\\) contains the columns (species) loadings.\n\nneig &lt;- min(c(r-1, c, l))\n\nHere, \\(r-1 =\\) 25, \\(c =\\) 21 and \\(l =\\) 6 so the minimum (and the number of eigenvalues) is 6.\n\neig &lt;- eigen(Sqq)\n\n(lambda &lt;- eig$values) # There are l = 6 non-null eigenvalues\n\n [1]  1.846574e-01  1.571586e-01  1.009501e-01  8.711508e-02  3.222443e-02\n [6]  1.476469e-02  9.795705e-18  8.252762e-18  7.486518e-18  6.959888e-18\n[11]  5.759585e-18  5.381418e-18  4.061072e-18  1.605351e-18  4.678542e-19\n[16]  3.679331e-19 -4.523252e-20 -7.096450e-19 -4.140284e-18 -7.864342e-18\n[21] -2.116046e-17\n\nlambda &lt;- lambda[1:neig]\n\nLambda &lt;- diag(lambda)\nU &lt;- eig$vectors[, 1:neig] # We keep only the eigenvectors\nrownames(U) &lt;- colnames(Y)\n\nFinally, we can get the ordination of rows (sites) by using the link between rows and columns ordination:\n\\[\n\\hat{U} = \\bar{Q} U \\Lambda^{-1/2}\n\\]\n\nUhat &lt;- Qbar %*% U %*% diag(lambda^(-1/2))\nrownames(Uhat) &lt;- rownames(Qbar)\n\ndim(Uhat)\n\n[1] 26  6"
  },
  {
    "objectID": "CCA.html#scaling",
    "href": "CCA.html#scaling",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Scaling",
    "text": "Scaling\n\n\n\n\n\n\nTL;DR\n\n\n\nAs with CA, we have the following scalings:\n\nColumns (species) scores: \\(U\\), \\(V = D(p_{\\cdot j})^{-1/2}U\\), \\(\\hat{F} = V \\Lambda^{1/2}\\) and \\(V \\Lambda^{1/4}\\)\nRows (sites) scores: \\(\\hat{U}\\), \\(\\hat{V} = D(p_{\\cdot j})^{-1/2}\\hat{U}\\), \\(F = \\hat{V} \\Lambda^{1/2}\\) and \\(\\hat{V} \\Lambda^{1/4}\\)\n\nThere are also scores for the predicted values of the row (sites) scores:\n\nScaling type 1: \\(Z_1 = D(p_{i\\cdot})^{-1/2}\\hat{Y}U\\)\nScaling type 2: \\(Z_2 = D(p_{i\\cdot})^{-1/2}\\hat{Y}U \\Lambda^{-1/2}\\)\nScaling type 3: \\(Z_3 = D(p_{i\\cdot})^{-1/2}\\hat{Y}U \\Lambda^{-1/4}\\)\n\nThere are also scalings for explanatory variables:\n\nScaling type 1: \\(BS_1 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\Lambda^{1/2}\\)\nScaling type 2: \\(BS_2 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\)\nScaling type 3: \\(BS_3 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\Lambda^{1/4}\\)\n\n\n\n\nca &lt;- dudi.coa(Y, \n               nf = c-1, \n               scannf = FALSE)\ncca &lt;- pcaiv(dudi = ca, \n             df = E,\n             scannf = FALSE,\n             nf = neig)\n\nlambda[1:neig]/cca$eig # Eigenvalues are the same as computed manually\n\n[1] 1 1 1 1 1 1\n\n\n\nCompute scaling\nIn CCA, just like with CA, there are different scalings (types 1, 2 and 3). So there are scalings for:\n\ncolumns (species)\n\n\n# Scale species (columns)\nV &lt;- diag(1/sqrt(colSums(P))) %*% U\ndim(V)\n\n[1] 21  6\n\n# Get species coordinates in the multivariate space (columns)\nFhat &lt;- V %*% diag(sqrt(lambda))\ndim(Fhat)\n\n[1] 21  6\n\n\n\nrows (sites)\n\n\n# Scale sites (rows)\nVhat &lt;- diag(1/sqrt(rowSums(P))) %*% Uhat\ndim(Vhat)\n\n[1] 26  6\n\n# Get sites coordinates in the multivariate space (rows)\nF_ &lt;- Vhat %*% diag(sqrt(lambda))\ndim(F_)\n\n[1] 26  6\n\n\n\npredicted rows (sites scores that are a combination of explanatory variables).\n\nScaling type 1: \\(Z_1 = D(p_{i\\cdot})^{-1/2}\\hat{Y}U\\)\n\n\nZ1 &lt;- diag(diag(Dpi_)^(-1/2)) %*% Qbarhat %*% U\ndim(Z1)\n\n[1] 26  6\n\n\n\nScaling type 2: \\(Z_2 = D(p_{i\\cdot})^{-1/2}\\hat{Y}U \\Lambda^{-1/2}\\)\n\n\nZ2 &lt;- diag(diag(Dpi_)^(-1/2)) %*% Qbarhat %*% U %*% diag(lambda^(-1/2))\ndim(Z2)\n\n[1] 26  6\n\n\n\nScaling type 3: \\(Z_3 = D(p_{i\\cdot})^{-1/2}\\hat{Y}U \\Lambda^{-1/4}\\)\n\n\nZ3 &lt;- diag(diag(Dpi_)^(-1/2)) %*% Qbarhat %*% U %*% diag(lambda^(-1/4))\ndim(Z3)\n\n[1] 26  6\n\n\nexplanatory variables (environmental factors). The scores for the explanatory variables are computed from matrix \\(Z_{stand}\\): so we first need to standardize \\(Z\\) into \\(Z_{stand}\\) (the computation can involve \\(Z_1\\), \\(Z_2\\) or \\(Z_3\\) and give the same result).\n\n\n\nCode\n# Compute inflated matrix ------\nZinfl &lt;- matrix(data = 0,\n                ncol = ncol(Z1), \n                nrow = sum(Y))\nrownames(Zinfl) &lt;- 1:nrow(Zinfl)\n# Give names to Z1\nrownames(Z1) &lt;- rownames(Y)\n\n# Get the number of times to duplicate each site\nnrep_sites &lt;- rowSums(Y)\n\nnrstart &lt;- 0\nfor (i in 1:nrow(Z1)) {\n  ri &lt;- Z1[i, ]\n  \n  rname &lt;- rownames(Z1)[i]\n  \n  # Get how many times to duplicate this site\n  nr &lt;- nrep_sites[as.character(rname)]\n  \n  Zinfl[(nrstart+1):(nrstart+nr), ] &lt;- matrix(rep(ri, nr), \n                                              nrow = nr, \n                                              byrow = TRUE)\n  \n  rownames(Zinfl)[(nrstart+1):(nrstart+nr)] &lt;- paste(rname, \n                                                     1:nr, \n                                                     sep = \"_\")\n  nrstart &lt;- nrstart + nr\n}\n\npaste(\"Dimension of Zinfl:\", \n      paste(dim(Zinfl), collapse = \" \"))\n\n\n[1] \"Dimension of Zinfl: 493 6\"\n\n\nCode\n# Compute mean/sd ------\nZinfl_mean &lt;- apply(Zinfl, 2, mean)\n\nn &lt;- nrow(Zinfl)\nZinfl_sd &lt;- apply(Zinfl, 2, \n                  function(x) sd(x)*sqrt((n-1)/n))\n\n# Compute Zstand ------\nZstand &lt;- scale(Z1, \n                center = Zinfl_mean,\n                scale = Zinfl_sd)\n\npaste(\"Dimension of Zstand:\", \n      paste(dim(Zstand), collapse = \" \"))\n\n\n[1] \"Dimension of Zstand: 26 6\"\n\n\n\nScaling type 1: \\(BS_1 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\Lambda^{1/2}\\)\n\n\nBS1 &lt;- t(Estand) %*% Dpi_ %*% Zstand %*% sqrt(Lambda)\ndim(BS1)\n\n[1] 6 6\n\n\n\nScaling type 2: \\(BS_2 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\)\n\n\nBS2 &lt;- t(Estand) %*% Dpi_ %*% Zstand\ndim(BS2)\n\n[1] 6 6\n\n\n\nScaling type 3: \\(BS_3 = E_{stand}' D(p_{i\\cdot})Z_{stand}\\Lambda^{1/4}\\)\n\n\nBS3 &lt;- t(Estand) %*% Dpi_ %*% Zstand %*% diag(lambda^(1/4))\ndim(BS3)\n\n[1] 6 6\n\n\n\n\n\n\n\n\nNote\n\n\n\n\\(\\hat{F}\\), \\(Z_1\\) and \\(BS_2\\) are the values used in the outputs of pcaiv.\n\ncca$co[, 1]/Fhat[, 1]\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\ncca$li[, 1]/Z1[, 1]\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 \n\ncca$cor[, 1]/BS2[, 1]\n\n           location           elevation          patch_area        perc_forests \n                  1                   1                   1                   1 \n    perc_grasslands ShannonLandscapeDiv \n                  1                   1 \n\n\n\n\n\n\nPlot scalings\nLet’s plot graphs for different scalings.\n\nScaling type 1 (rows (sites): \\(F\\) or \\(Z_1\\), columns (species): \\(V\\), explanatory variable: \\(BS_1\\)). Here, \\(\\chi^2\\) distances between rows (sites) are preserved they are positioned at the centroid of species.\n\n\n\nCode\nplot(x = V[, 1], y = V[, 2],\n     col = NULL,\n     asp = 1,\n     main = \"Observed sites scores\")\ntext(x = V[, 1], y = V[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\ntext(x = F_[, 1], y = F_[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\narrows(x0 = rep(0, nrow(BS1)),\n       y0 = rep(0, nrow(BS1)),\n       x1 = BS1[, 1], \n       y1 = BS1[, 2],\n       length = 0.1,\n       asp = 1)\ntext(x = BS1[, 1], \n     y = BS1[, 2],\n     label = colnames(E),\n     asp = 1)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\nThe plot with the predicted sites scores should show the same coordinates for sites as with ade4:\n\n\nCode\nplot(x = V[, 1], y = V[, 2],\n     col = NULL,\n     asp = 1,\n     main = \"Predicted sites scores\")\ntext(x = V[, 1], y = V[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\ntext(x = Z1[, 1], y = Z1[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\narrows(x0 = rep(0, nrow(BS1)),\n       y0 = rep(0, nrow(BS1)),\n       x1 = BS1[, 1], \n       y1 = BS1[, 2],\n       length = 0.1,\n       asp = 1)\ntext(x = BS1[, 1], \n     y = BS1[, 2],\n     label = colnames(E),\n     asp = 1)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\n\nScaling type 2 (rows (sites): \\(\\hat{V}\\) or \\(Z_2\\), columns (species): \\(\\hat{F}\\), explanatory variable: \\(BS_2\\)). Here, \\(\\chi^2\\) distances between columns (species) are preserved they are positioned at the centroid of sites.\n\nOn these graphs, species are in the same position as with ade4.\n\n\nCode\nplot(x = Fhat[, 1], y = Fhat[, 2],\n     col = NULL,\n     asp = 1,\n     xlim = c(-3, 3),\n     ylim = c(-3, 3),\n     main = \"Observed sites scores\")\ntext(x = Fhat[, 1], y = Fhat[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\ntext(x = Vhat[, 1], y = Vhat[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\narrows(x0 = rep(0, nrow(BS2)),\n       y0 = rep(0, nrow(BS2)),\n       x1 = BS2[, 1], \n       y1 = BS2[, 2],\n       length = 0.1,\n       asp = 1)\ntext(x = BS2[, 1], \n     y = BS2[, 2],\n     label = colnames(E),\n     asp = 1)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\n\n\nCode\nplot(x = Fhat[, 1], y = Fhat[, 2],\n     col = NULL,\n     asp = 1,\n     xlim = c(-4, 4),\n     ylim = c(-4, 4),\n     main = \"Predicted sites scores\")\ntext(x = Fhat[, 1], y = Fhat[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\ntext(x = Z2[, 1], y = Z2[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\narrows(x0 = rep(0, nrow(BS2)),\n       y0 = rep(0, nrow(BS2)),\n       x1 = BS2[, 1], \n       y1 = BS2[, 2],\n       length = 0.1,\n       asp = 1)\ntext(x = BS2[, 1], \n     y = BS2[, 2],\n     label = colnames(E),\n     asp = 1)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\n\nScaling type 3 (rows (sites): \\(\\hat{V} \\Lambda^{1/4}\\) or \\(Z_3\\), columns (species): \\(V \\Lambda^{1/4}\\), explanatory variable: \\(BS_3\\))\n\n\n\nCode\nsites &lt;- Vhat %*% diag(lambda^(1/4))\nspp &lt;- V %*% diag(lambda^(1/4))\n\nplot(x = spp[, 1], y = spp[, 2],\n     col = NULL,\n     asp = 1,\n     xlim = c(-3, 3),\n     ylim = c(-3, 3),\n     main = \"Observed sites scores\")\ntext(x = spp[, 1], y = spp[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\ntext(x = sites[, 1], y = sites[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\narrows(x0 = rep(0, nrow(BS3)),\n       y0 = rep(0, nrow(BS3)),\n       x1 = BS3[, 1], \n       y1 = BS3[, 2],\n       length = 0.1,\n       asp = 1)\ntext(x = BS3[, 1], \n     y = BS3[, 2],\n     label = colnames(E),\n     asp = 1)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\n\n\nCode\nplot(x = spp[, 1], y = spp[, 2],\n     col = NULL,\n     xlim = c(-3, 3),\n     ylim = c(-3, 3),\n     asp = 1,\n     main = \"Predicted sites scores\")\ntext(x = spp[, 1], y = spp[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\ntext(x = Z3[, 1], y = Z3[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\narrows(x0 = rep(0, nrow(BS3)),\n       y0 = rep(0, nrow(BS3)),\n       x1 = BS3[, 1], \n       y1 = BS3[, 2],\n       length = 0.1,\n       asp = 1)\ntext(x = BS3[, 1], \n     y = BS3[, 2],\n     label = colnames(E),\n     asp = 1)\n\nabline(h = 0)\nabline(v = 0)"
  },
  {
    "objectID": "CCA.html#interpretation",
    "href": "CCA.html#interpretation",
    "title": "Canonical Correspondence Analysis (CCA)",
    "section": "Interpretation",
    "text": "Interpretation\nIn CCA, each ordination axis corresponds to a linear combination of the explanatory variables that maximizes the explained variance in the response data.\nThis analysis constrains rows (sites) scores to be linear combinations of the environmental variables (scaling \\(Z_i\\)).\nSpecies can be ordered along environmental variables axes by projecting species coordinates on the vector of this variable. This gives species niche optimum, but there are strong assumptions:\n\nunimodal distribution of niches preferences along the variable of interest\nspecies distributions are indeed controlled by the environment\nthe study gradient is long enough to capture the range of species abundance variation.\n\nThe part of variation explained by the environmental variables can be computed as \\[\n\\frac{\\sum_k \\lambda_k(CCA)}{\\sum_l \\lambda_l(CA)}\n\\]\n\nsum(lambda)/sum(ca$eig)\n\n[1] 0.3795835\n\n\nHere, the environmental variables explain 38 % of the total variation.\nWarning: in CCA, using noisy or not relevant explanatory variables leads to spurious relationships.\n\nResidual analysis\nIn order to examinate residuals, a CA can be performed on the table of residuals \\(\\bar{Q}_{res}\\):\n\\[\n\\bar{Q}_{res} = \\bar{Q} - \\hat{\\bar{Q}}\n\\]\n\nQres &lt;- Qbar - Qbarhat\n\nres_pca &lt;- dudi.pca(Qres, scannf = FALSE, nf = 27)\n\nscatter(res_pca)\n\n\n\n\n\n\nTests of significance\nIt is possible to test the significance of the the relationship between \\(E\\) and \\(Y\\) with a permutation test.\n\nrandtest(cca, nrepet = 999)\n\nMonte-Carlo test\nCall: randtest.pcaiv(xtest = cca, nrepet = 999)\n\nObservation: 0.3795835 \n\nBased on 999 replicates\nSimulated p-value: 0.001 \nAlternative hypothesis: greater \n\n     Std.Obs  Expectation     Variance \n3.6408359395 0.2692189406 0.0009188763"
  },
  {
    "objectID": "dcCA.html",
    "href": "dcCA.html",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "",
    "text": "Code\n# Paths\nlibrary(here)\n\n# Multivariate analysis\nlibrary(ade4)\nlibrary(adegraphics)\n\n# dc-CA\nsource(here(\"functions/dpcaiv2-ade4.R\"))\n\n# Matrix algebra\nlibrary(expm)\n\n# Plots\nlibrary(ggplot2)\nsource(here(\"functions/plot.R\"))\nThe contents of this page relies heavily on (Braak, Šmilauer, and Dray 2018)."
  },
  {
    "objectID": "dcCA.html#introduction",
    "href": "dcCA.html#introduction",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Introduction",
    "text": "Introduction\ndc-CA was developed as a natural extension of CCA and has been used to study the relationship between species traits and environmental variables.\nIn dc-CA, we have 3 matrices:\n\nA data matrix \\(Y\\) (\\(r \\times c\\))\nA matrix of predictor variables \\(E\\) (\\(r \\times l\\))\nA matrix of predictor variables \\(T\\) (\\(c \\times k\\))\n\n\n\n\n\n\nThe aim of dc-CA is to find a linear combination of the predictor variables in \\(E\\) and \\(T\\) (environmental variables and traits) that maximizes the correlation.\nBelow are these matrices for our data:\n\\(Y =\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsp1\nsp2\nsp3\nsp4\nsp5\nsp6\nsp7\nsp8\nsp9\nsp10\nsp11\nsp12\nsp13\nsp14\nsp15\nsp16\nsp17\nsp18\nsp19\nsp21\nsp22\n\n\n\n\n1\n0\n1\n1\n0\n1\n0\n2\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n0\n2\n4\n0\n3\n3\n0\n3\n1\n0\n2\n\n\n5\n0\n0\n2\n0\n1\n0\n2\n0\n1\n2\n0\n0\n0\n0\n0\n0\n3\n2\n0\n1\n\n\n3\n0\n0\n0\n0\n1\n0\n4\n1\n0\n1\n0\n0\n0\n0\n0\n0\n2\n0\n0\n1\n\n\n5\n0\n0\n1\n0\n1\n0\n2\n0\n0\n3\n0\n0\n0\n0\n1\n0\n3\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n2\n0\n3\n1\n2\n1\n0\n0\n0\n1\n0\n1\n2\n2\n0\n3\n\n\n4\n0\n0\n0\n0\n2\n0\n4\n0\n2\n0\n4\n0\n0\n0\n0\n1\n5\n0\n0\n2\n\n\n2\n0\n0\n1\n0\n2\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n5\n1\n5\n1\n\n\n4\n0\n0\n0\n0\n0\n0\n2\n0\n0\n3\n0\n0\n0\n0\n0\n1\n1\n0\n0\n1\n\n\n2\n0\n1\n5\n0\n0\n0\n5\n0\n1\n1\n4\n0\n0\n0\n1\n2\n2\n0\n0\n2\n\n\n2\n0\n0\n2\n0\n1\n0\n5\n0\n2\n2\n0\n0\n0\n4\n0\n1\n10\n3\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n4\n0\n2\n2\n4\n0\n0\n0\n0\n2\n1\n2\n0\n1\n\n\n5\n5\n0\n0\n1\n1\n0\n1\n0\n3\n0\n5\n0\n0\n0\n0\n0\n0\n1\n5\n1\n\n\n4\n0\n0\n1\n0\n2\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n3\n0\n0\n0\n1\n0\n0\n0\n0\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n5\n0\n4\n0\n1\n2\n0\n0\n0\n0\n0\n0\n1\n2\n0\n0\n\n\n4\n0\n1\n1\n0\n1\n0\n3\n1\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n1\n0\n3\n2\n1\n2\n0\n0\n0\n0\n0\n0\n1\n3\n0\n0\n\n\n4\n2\n0\n1\n0\n0\n0\n2\n0\n2\n2\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n4\n0\n0\n1\n0\n2\n0\n2\n2\n2\n1\n1\n0\n0\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n0\n0\n1\n0\n4\n0\n0\n0\n0\n4\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n5\n1\n0\n3\n0\n2\n0\n2\n1\n0\n2\n0\n0\n0\n0\n0\n0\n3\n1\n0\n0\n\n\n3\n5\n0\n4\n0\n2\n0\n5\n0\n4\n2\n0\n0\n1\n0\n0\n0\n2\n0\n0\n0\n\n\n5\n2\n0\n7\n0\n1\n1\n0\n0\n4\n2\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\n\n6\n0\n0\n2\n0\n1\n0\n0\n0\n1\n3\n0\n0\n0\n0\n0\n0\n0\n3\n3\n0\n\n\n3\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n\n\n\n\n\n\\(E =\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nelevation\npatch_area\nperc_forests\nperc_grasslands\nShannonLandscapeDiv\n\n\n\n\n0\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n0\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n0\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n0\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n0\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n0\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n0\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n0\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n0\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n0\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n0\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n0\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n1\n10\n6.28\n7.7882\n67.7785\n0.232\n\n\n1\n30\n7.92\n16.4129\n43.4066\n0.274\n\n\n1\n430\n83.24\n24.4526\n28.4995\n0.274\n\n\n1\n420\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n400\n140.83\n41.9966\n34.2412\n0.260\n\n\n1\n500\n0.50\n7.5445\n67.0780\n0.240\n\n\n1\n470\n7.84\n19.3087\n56.4031\n0.253\n\n\n1\n110\n21.15\n23.4668\n49.8908\n0.262\n\n\n1\n460\n24.82\n21.3932\n57.0430\n0.243\n\n\n1\n450\n3.11\n4.8285\n73.7518\n0.216\n\n\n1\n40\n6.66\n7.4729\n66.0061\n0.240\n\n\n1\n160\n5.63\n32.3516\n45.0477\n0.253\n\n\n1\n160\n10.99\n29.7139\n18.8270\n0.291\n\n\n\n\n\n\\(T =\\)\n\n\n\n\n\n\nbiog\nforag\nmass\ndiet\nmove\nnest\neggs\n\n\n\n\nsp1\n1\n2\n2\n3\n1\n2\n2\n\n\nsp2\n1\n1\n1\n2\n1\n2\n2\n\n\nsp3\n1\n1\n2\n2\n2\n2\n1\n\n\nsp4\n1\n1\n1\n2\n1\n2\n2\n\n\nsp5\n1\n3\n3\n1\n2\n3\n4\n\n\nsp6\n1\n1\n4\n3\n2\n2\n1\n\n\nsp7\n1\n1\n1\n2\n1\n3\n3\n\n\nsp8\n1\n1\n1\n2\n2\n2\n2\n\n\nsp9\n1\n2\n1\n2\n1\n3\n3\n\n\nsp10\n1\n1\n1\n2\n1\n2\n2\n\n\nsp11\n2\n4\n3\n2\n1\n2\n2\n\n\nsp12\n2\n1\n2\n3\n2\n2\n3\n\n\nsp13\n2\n1\n4\n3\n2\n3\n1\n\n\nsp14\n2\n3\n2\n2\n1\n1\n3\n\n\nsp15\n2\n2\n2\n3\n2\n2\n3\n\n\nsp16\n2\n2\n2\n3\n2\n2\n4\n\n\nsp17\n2\n3\n4\n1\n1\n2\n2\n\n\nsp18\n2\n2\n1\n3\n2\n2\n3\n\n\nsp19\n2\n4\n3\n2\n1\n2\n2\n\n\nsp21\n2\n4\n3\n1\n2\n3\n3\n\n\nsp22\n2\n3\n2\n3\n2\n1\n3\n\n\n\n\n\n\n(r &lt;- dim(Y)[1])\n\n[1] 26\n\n(c &lt;- dim(Y)[2])\n\n[1] 21\n\n(l &lt;- dim(E)[2])\n\n[1] 6\n\n(k &lt;- dim(T_)[2])\n\n[1] 7\n\n\ndc-CA must not have to many traits compared to species: that is a disadvantage compared to RLQ, but on the other hand dc-CA allows to see relationships that RLQ would miss (Braak, Šmilauer, and Dray 2018).\nThere are several ways to perform dc-CA (Braak, Šmilauer, and Dray 2018), notably:\n\nsingular value decomposition (the method used here)\nan iterative method à la reciprocal averaging\ncanonical correlation analysis between \\(T\\) et \\(E\\), weighted by \\(Y\\)"
  },
  {
    "objectID": "dcCA.html#computation",
    "href": "dcCA.html#computation",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Computation",
    "text": "Computation\n\n\n\n\n\n\nTL;DR\n\n\n\nWe perform the SVD of \\(D = [E_{center}' D(y_{i \\cdot}) E_{center}]^{-1/2} E_{center}' Y T_{center} [T_{center}' D(y_{\\cdot j}) T_{center}]^{-1/2}\\)\n\\[\nD = P \\Lambda_{SDV} Q'\n\\] This allows us to find the eigenvectors \\(P\\) (rows or environment eigenvectors) and \\(Q\\) (columns or traits eigenvectors).\nThe eigenvalues of the dc-CA are the squared eigenvalues of the SVD: \\(\\Lambda_{dc-CA} = \\Lambda_{SVD}^2\\)\nThere are \\(\\min(k, l)\\) non-null eigenvalues???\nThen, the regression coefficients for explanatory variables can be found with\n\n\\(B = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P\\) (row explanatory variables = environmental variables)\n\\(C = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q\\) (columns explanatory variables = species traits)\n\nThe rows/column scores are detailed below in the Scalings section.\n\n\nFirst, we need to center the traits and environment matrices (resp. \\(T_{cent}\\) and \\(E_{cent}\\)). To do that, we have to compute “inflated” versions of these matrices matching the occurrence counts in \\(Y\\).\n\\[\nE_{stand} = E - \\bar{E}_{infl} =\\left[e_i \\sum_i y_{i\\cdot}e_i/y_{\\cdot\\cdot} \\right]\n\\]\n\\[\nT_{stand} = T - \\bar{T}_{infl} = \\left[t_j \\sum_j y_{\\cdot j}t_j/y_{\\cdot\\cdot} \\right]\n\\]\nWith our data:\n\n# Center E -----\nyi_ &lt;- rowSums(Y)\nEcenter &lt;- matrix(nrow = nrow(E), ncol = ncol(E))\n\nfor(i in 1:ncol(Ecenter)) {\n  Ecenter[, i] &lt;- E[, i] - sum(E[, i]*yi_)/sum(Y)\n}\n# This is the same as computing a mean on inflated data matrix Einfl and centering E with these means\n\n# Center T -----\ny_j &lt;- colSums(Y)\nTcenter &lt;- matrix(nrow = nrow(T_), ncol = ncol(T_))\nrownames(Tcenter) &lt;- rownames(T_)\ncolnames(Tcenter) &lt;- colnames(T_)\n\nfor(j in 1:ncol(Tcenter)) {\n  Tcenter[, j] &lt;- T_[, j] - (sum(T_[, j]*y_j)/sum(Y))\n}\n\n\n# Check centering -----\nM1 &lt;- matrix(rep(1, nrow(Y)), nrow = 1)\nall((M1 %*% diag(rowSums(Y)) %*% Ecenter) &lt; 10e-10)\n\n[1] TRUE\n\nM1 &lt;- matrix(rep(1, ncol(Y)), nrow = 1)\nall((M1 %*% diag(colSums(Y)) %*% Tcenter) &lt; 10e-10)\n\n[1] TRUE\n\n\nMaximizing the fourth-corner correlation means finding \\(\\hat{u}\\) and \\(u\\) that maximize \\(\\hat{u}'Yu\\) (where \\(\\hat{u}\\) are the sites (rows) scores and \\(u\\) are the species (columns) scores).\n\\(\\hat{u}\\) and \\(u\\) are linear combinations of traits and environmental variables: \\(\\hat{u} = E_{center}b\\) and \\(u = T_{center}c\\).\nSo in the end, we need to maximize \\(\\hat{u}'Yu\\) with respect to the coefficients vectors \\(b\\) and \\(c\\):\n\\[\n\\max_{b, c}(\\hat{u}'Yu) = \\max_{b, c}\\left(\\left[E_{center}b\\right]'Y  T_{center}c \\right)\n\\]\n\n\n\n\n\n\nNote\n\n\n\nThese equations are written for the first axis, but we can also write them in matrix form:\n\\[\n\\max_{B, C}(\\hat{U}'YU) = \\max_{B, C}\\left(\\left[E_{center}B\\right]'Y T_{center}C \\right)\n\\]\n\n\nIn addition, we introduce the following constraint on the norm of the columns vectors of \\(\\hat{U}\\) and \\(U\\): \\(\\hat{u}' D(y_{i\\cdot}) \\hat{u} = 1\\) and \\(u' D(y_{\\cdot j})u = 1\\). In fact, tjese constraints will be relaxed later depending on the scaling (see below).\nTo find the coefficients \\(B\\) and \\(C\\) defined above, we need to diagonalize the following matrices \\(M\\) and \\(M_2\\):\n\nTo find \\(B\\), we must diagonalize \\(M\\): \\[\nM = \\left[E_{center}' D(y_{i\\cdot}) E_{center} \\right]^{-1} E_{center}'YT_{center} \\left[T_{center}' D(y_{\\cdot j}) T_{center} \\right]^{-1} T_{center}' Y' E_{center}\n\\] Where matrices \\(D(y_{i \\cdot})\\) and \\(D(y_{\\cdot j})\\) are the diagonal matrices with the column and row sums (respectively). They are analogous to matrices \\(D(p_{i \\cdot})\\) and \\(D(p_{\\cdot j})\\) defined for CA and CCA (but we use \\(Y\\) instead of \\(P\\) to define the margins). We can view \\(M\\) as: \\[\nM = \\hat{E}_{center} \\hat{T}_{center} = \\beta T_{center} \\gamma E_{center}\n\\] With \\(\\beta = \\left[E_{center}' D(y_{i\\cdot}) E_{center} \\right]^{-1} E_{center}'Y\\) and \\(\\gamma = \\left[T_{center}' D(y_{\\cdot j}) T_{center} \\right]^{-1} T_{center}' Y'\\). Here, we predict the environment with traits so that \\(\\hat{E}_{center} = \\beta T_{center}\\) and the traits with the environment so that \\(\\hat{T}_{center} = \\gamma E_{center}\\). So we maximize the correlation between \\(\\hat{E}_{center}\\) and \\(\\hat{T}_{center}\\).\nSimilarly, to find \\(C\\), we must diagonalize \\(M_2\\):\n\n\\[\nM_2 = \\left[T_{center}' D(y_{\\cdot j}) T_{center} \\right]^{-1} T_{center}' Y' E_{center} \\left[E_{center}' D(y_{i\\cdot}) E_{center} \\right]^{-1} E_{center}'YT_{center}\n\\] Here, we can view \\(M_2\\) as: \\[$M_2 = \\hat{T}_{center} \\hat{E}_{center} = \\gamma E_{center} \\beta T_{center}\\]\nThe eigenvectors matrices of these diagonalizations give us \\(B\\) and \\(C\\):\n\\[\nM = B \\Lambda_b B^{-1} ~~ \\text{and} ~~ M_2 = C \\Lambda_c C^{-1}\n\\]\nWe can either diagonalize \\(M\\) and \\(M_2\\) of perform a single SVD of a matrix \\(D\\) defined below and get a similar result. Both methods are presented below.\n\nDiagonalizations\nWe diagonalize \\(M\\) and \\(M_2\\):\n\n# Define weights\nDyi_ &lt;- diag(rowSums(Y))\nDy_j &lt;- diag(colSums(Y))\n\n# Compute M\nM &lt;- solve(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% t(Ecenter) %*% Y %*% Tcenter %*% solve(t(Tcenter) %*% Dy_j %*% Tcenter) %*% t(Tcenter) %*% t(Y) %*% Ecenter\n\n# Compute M2\nM2 &lt;- solve(t(Tcenter) %*% Dy_j %*% Tcenter) %*% t(Tcenter) %*% t(Y) %*% Ecenter %*% solve(t(Ecenter) %*% Dyi_ %*% Ecenter) %*% t(Ecenter) %*% Y %*% Tcenter \n\n\n# Diagonalize M\neigB &lt;- eigen(M)\nlambdaB &lt;- eigB$values\nlambdaB # All non-null eigenvectors\n\n[1] 0.139487442 0.088736680 0.049183623 0.013797529 0.008736645 0.002485683\n\nvB &lt;- eigB$vectors\n\n# Diagonalize M2\neigC &lt;- eigen(M2)\nlambdaC &lt;- eigC$values\nlambdaC # six non-null eigenvalues\n\n[1]  1.394874e-01  8.873668e-02  4.918362e-02  1.379753e-02  8.736645e-03\n[6]  2.485683e-03 -9.364154e-18\n\nvC &lt;- eigC$vectors\n\nall(lambdaB - lambdaC[1:l] &lt; 10e-10)\n\n[1] TRUE\n\n\n### SVD\nAlternatively, we can compute the SVD of a matrix \\(D\\) computed from \\(M\\) and get a similar result. \\(D\\) is defined as:\n\\[\nD = M^{1/2} = [E_{center}' D(y_{i \\cdot}) E_{center}]^{-1/2} E_{center}' Y T_{center} [T_{center}' D(y_{\\cdot j}) T_{center}]^{-1/2}\n\\]\nWith our dataset:\n\nD &lt;- solve(sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter)) %*%\n  t(Ecenter) %*% Y %*% Tcenter %*%\n  solve(sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter))\n\nWe perform the SVD of \\(D\\): \\(D = P \\Lambda_{SVD} Q'\\).\n\nsv &lt;- svd(D)\n\nlambda_svd &lt;- sv$d\nLambda_svd &lt;- diag(lambda_svd)\n\nP_svd &lt;- sv$u\nQ_svd &lt;- sv$v\n\ndim(P_svd)\n\n[1] 6 6\n\ndim(Q_svd)\n\n[1] 7 6\n\n\nThe eigenvalues of the SVD are the square roots of the final eigenvalues obtained by diagonalization: \\(\\Lambda_{dc-CA} = \\Lambda_{SVD}^2\\)\n\nlambda &lt;- lambda_svd^2\nLambda &lt;- diag(lambda)\n\nNow, we can compute the regression coefficients of the sites environmental variables (\\(B\\)) as:\n\\[\nB = [E_{center}'D(y_{i\\cdot})E_{center}]^{-1/2}P \\Lambda_{SVD}\n\\]\n\nB &lt;- solve(sqrtm(t(Ecenter) %*% Dyi_ %*% Ecenter)) %*%  P_svd %*% Lambda_svd\n\nSame for the coefficients of species traits \\(C\\):\n\\[\nC = [T_{center}' D(y_{\\cdot j})T_{center}]^{-1/2}Q\\Lambda_{SVD}\n\\]\n\nC &lt;- solve(sqrtm(t(Tcenter) %*% Dy_j %*% Tcenter)) %*% Q_svd %*% Lambda_svd\n\n\n# Compare both methods\nB/vB # The eigenvectors are almost the same\n\n           [,1]      [,2]      [,3]      [,4]      [,5]       [,6]\n[1,] -0.5259939 0.7780306 0.8097335 0.3580791 0.3630149 -0.1983442\n[2,] -0.5259939 0.7780306 0.8097335 0.3580791 0.3630149 -0.1983442\n[3,] -0.5259939 0.7780306 0.8097335 0.3580791 0.3630149 -0.1983442\n[4,] -0.5259939 0.7780306 0.8097335 0.3580791 0.3630149 -0.1983442\n[5,] -0.5259939 0.7780306 0.8097335 0.3580791 0.3630149 -0.1983442\n[6,] -0.5259939 0.7780306 0.8097335 0.3580791 0.3630149 -0.1983442\n\napply(B, 2, function(x) sqrt(sum(x^2))) # column vectors of B have different norms\n\n[1] 0.5259939 0.7780306 0.8097335 0.3580791 0.3630149 0.1983442\n\napply(vB, 2, function(x) sqrt(sum(x^2))) # column vectors of vB are of norm 1\n\n[1] 1 1 1 1 1 1\n\nC/vC[, 1:l] # The eigenvectors are almost the same\n\n           [,1]        [,2]       [,3]        [,4]         [,5]        [,6]\n[1,] 0.03204444 -0.03641707 0.03393986 -0.02556497 -0.007219091 0.006079451\n[2,] 0.03204444 -0.03641707 0.03393986 -0.02556497 -0.007219091 0.006079451\n[3,] 0.03204444 -0.03641707 0.03393986 -0.02556497 -0.007219091 0.006079451\n[4,] 0.03204444 -0.03641707 0.03393986 -0.02556497 -0.007219091 0.006079451\n[5,] 0.03204444 -0.03641707 0.03393986 -0.02556497 -0.007219091 0.006079451\n[6,] 0.03204444 -0.03641707 0.03393986 -0.02556497 -0.007219091 0.006079451\n[7,] 0.03204444 -0.03641707 0.03393986 -0.02556497 -0.007219091 0.006079451\n\napply(C, 2, function(x) sqrt(sum(x^2))) # column vectors of C have different norms\n\n[1] 0.032044439 0.036417073 0.033939863 0.025564966 0.007219091 0.006079451\n\napply(vC, 2, function(x) sqrt(sum(x^2))) # column vectors of vC are of norm 1\n\n[1] 1 1 1 1 1 1 1"
  },
  {
    "objectID": "dcCA.html#scalings",
    "href": "dcCA.html#scalings",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Scalings",
    "text": "Scalings\n\n\n\n\n\n\nTL;DR\n\n\n\nThere are two types of coordinates: linear combination scores (LC scores) and weighted averages scores (WA scores).\nLC scores are computed from the regression coefficients and the predictor variable table associated with the same dimension.\n\nScaling type 1 (that preserve the rows distances): \\(\\hat{Z}_1 = E_{center}B\\) (for rows = sites) and \\(Z_1 = T_{center}C\\Lambda_{dc-CA}^{-1/2}\\) (for columns = species)\nScaling type 2 (that preserve the columns distances) : \\(\\hat{Z}_2 = E_{center}B\\Lambda_{dc-CA}^{-1/2}\\) (for rows = sites) and \\(Z_2 = T_{center}C\\) (for columns = species)\nScaling type 3 (symmetric scaling): \\(\\hat{Z}_3 = E_{center}B\\Lambda_{dc-CA}^{-1/4}\\) (for rows = sites) and \\(Z_3 = T_{center}C\\Lambda_{dc-CA}^{-1/4}\\) (for columns = species)\n\nNote: these results are in disagreement with the article of (Braak, Šmilauer, and Dray 2018), since the scalings of the columns should be times \\(\\Lambda^{-1}\\), and there is a problem with the variance of $co. We find that there should be \\(\\Lambda^{1-\\alpha}\\) in (17) instead of \\(\\Lambda^{\\alpha-1}\\).\nWA scores are computed from the predicted coordinates of the other dimension:\n\nThe WA row (sites) scores are computed from the \\(Z_i\\) column (species) scores as \\(\\hat{U}_i = D(y_{\\cdot i})^{-1} Y Z_i\\)\nThe WA column (species) scores are computed from the \\(\\hat{Z}_i\\) row (sites) scores as \\(U_i = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_i\\)\n\n\n\n\nLinear combinations (LC) scores\nUsing the coefficients \\(B\\) and \\(C\\), we can get the predicted species/sites scores as a linear combination of coefficients and traits/environment matrices.\n\nca &lt;- dudi.coa(Y, \n               nf = c-1, \n               scannf = FALSE)\n\ndcca &lt;- dpcaiv2(dudi = ca, \n                dfR = E,\n                dfQ = T_,\n                scannf = FALSE, \n                nf = min(k, l))\n\nCoordinates computed with our method are equal to those computed by ade4, but we need to multiply them by a scaling factor \\(\\sqrt{y_{\\cdot \\cdot}}\\).\n\n(scaling &lt;- sqrt(sum(Y)))\n\n[1] 22.2036\n\n\n\n\n                    RS1 RS2 RS3 RS4 RS5 RS6\nlocation             -1   1   1  -1   1  -1\nelevation            -1   1   1  -1   1  -1\npatch_area           -1   1   1  -1   1  -1\nperc_forests         -1   1   1  -1   1  -1\nperc_grasslands      -1   1   1  -1   1  -1\nShannonLandscapeDiv  -1   1   1  -1   1  -1\n\n\n      CS1 CS2 CS3 CS4 CS5 CS6\nbiog   -1   1   1  -1   1  -1\nforag  -1   1   1  -1   1  -1\nmass   -1   1   1  -1   1  -1\ndiet   -1   1   1  -1   1  -1\nmove   -1   1   1  -1   1  -1\nnest   -1   1   1  -1   1  -1\neggs   -1   1   1  -1   1  -1\n\n\n\nScaling type 1 (that preserve the rows distances): \\(\\hat{Z}_1 = E_{center}B\\) (for rows = sites) and \\(Z_1 = T_{center}C \\Lambda_{SVD}^{-1} = T_{center}C \\Lambda_{dc-CA}^{-1/2}\\) (for columns = species).\n\n\nZhat1 &lt;- Ecenter %*% B\nZ1 &lt;- Tcenter %*% C %*% diag(lambda^(-1/2))\n\n\n\nCode\nZ1inv &lt;- Z1*scaling\nZ1inv[, 1] &lt;- -Z1inv[, 1]\n\nZhat1inv &lt;- Zhat1*scaling\nZhat1inv[, 1] &lt;- -Zhat1inv[, 1]\n\nplot(x = Z1inv[, 1], y = Z1inv[, 2],\n     col = NULL,\n     asp = 1,\n     main = \"LC scores (scaling type 1: row-preserving)\")\ntext(x = Z1inv[, 1], y = Z1inv[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 1)\ntext(x = Zhat1inv[, 1], y = Zhat1inv[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 1)\n# arrows(x0 = rep(0, nrow(BS1)),\n#        y0 = rep(0, nrow(BS1)),\n#        x1 = BS1[, 1], \n#        y1 = BS1[, 2],\n#        length = 0.1,\n#        asp = 1)\n# text(x = BS1[, 1], \n#      y = BS1[, 2],\n#      label = colnames(E),\n#      asp = 1)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\n\nScaling type 2 (that preserve the columns distances) : \\(\\hat{Z}_2 = E_{center}B\\Lambda_{SVD}^{-1} = E_{center}B\\Lambda_{dc-CA}^{-1/2}\\) (for rows = sites) and \\(Z_2 = T_{center}C\\) (for columns = species) (Here we use the formula that works, different from ter Braak, for Z2 agree)\n\n\nZhat2 &lt;- Ecenter %*% B %*% diag(lambda_svd^(-1))\n\nZ2 &lt;- Tcenter %*% C %*% diag(lambda_svd^(-2))\nZ2_agree &lt;- Tcenter %*% C\n\n\nZhat2*scaling/dcca$l1 # Ok\n\n    RS1 RS2 RS3 RS4 RS5 RS6\nX1   -1   1   1  -1   1  -1\nX2   -1   1   1  -1   1  -1\nX3   -1   1   1  -1   1  -1\nX4   -1   1   1  -1   1  -1\nX5   -1   1   1  -1   1  -1\nX6   -1   1   1  -1   1  -1\nX7   -1   1   1  -1   1  -1\nX8   -1   1   1  -1   1  -1\nX9   -1   1   1  -1   1  -1\nX10  -1   1   1  -1   1  -1\nX11  -1   1   1  -1   1  -1\nX12  -1   1   1  -1   1  -1\nX13  -1   1   1  -1   1  -1\nX14  -1   1   1  -1   1  -1\nX15  -1   1   1  -1   1  -1\nX16  -1   1   1  -1   1  -1\nX17  -1   1   1  -1   1  -1\nX18  -1   1   1  -1   1  -1\nX19  -1   1   1  -1   1  -1\nX20  -1   1   1  -1   1  -1\nX21  -1   1   1  -1   1  -1\nX22  -1   1   1  -1   1  -1\nX23  -1   1   1  -1   1  -1\nX24  -1   1   1  -1   1  -1\nX25  -1   1   1  -1   1  -1\nX26  -1   1   1  -1   1  -1\n\nZ2*scaling/dcca$co # Not ok (but using tB formula)\n\n         Comp1   Comp2    Comp3     Comp4    Comp5     Comp6\nsp1  -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp2  -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp3  -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp4  -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp5  -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp6  -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp7  -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp8  -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp9  -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp10 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp11 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp12 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp13 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp14 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp15 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp16 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp17 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp18 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp19 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp21 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\nsp22 -7.169104 11.2693 20.33197 -72.47675 114.4604 -402.3038\n\nZ2_agree*scaling/dcca$co # Ok\n\n     Comp1 Comp2 Comp3 Comp4 Comp5 Comp6\nsp1     -1     1     1    -1     1    -1\nsp2     -1     1     1    -1     1    -1\nsp3     -1     1     1    -1     1    -1\nsp4     -1     1     1    -1     1    -1\nsp5     -1     1     1    -1     1    -1\nsp6     -1     1     1    -1     1    -1\nsp7     -1     1     1    -1     1    -1\nsp8     -1     1     1    -1     1    -1\nsp9     -1     1     1    -1     1    -1\nsp10    -1     1     1    -1     1    -1\nsp11    -1     1     1    -1     1    -1\nsp12    -1     1     1    -1     1    -1\nsp13    -1     1     1    -1     1    -1\nsp14    -1     1     1    -1     1    -1\nsp15    -1     1     1    -1     1    -1\nsp16    -1     1     1    -1     1    -1\nsp17    -1     1     1    -1     1    -1\nsp18    -1     1     1    -1     1    -1\nsp19    -1     1     1    -1     1    -1\nsp21    -1     1     1    -1     1    -1\nsp22    -1     1     1    -1     1    -1\n\n\n\n# Since ter Braak and ade4 disagree, check the variance of co and Z2 or Z2_agree (it should be the eigenvalues of each axis)\n\n#' Get the variance of vector x\n#'\n#' @param x The vector\n#' @param w The weights\n#'\n#' @return The variance\nvarvec &lt;- function(x, w) {\n  sum(w*(x-mean(x))^2)\n}\n\nres_ade4 &lt;- apply(as.matrix(dcca$co), \n                  2, \n                  function(x) varvec(x, dcca$cw))\nres_ade4/dcca$eig\n\n   Comp1    Comp2    Comp3    Comp4    Comp5    Comp6 \n1.106286 1.151797 1.466209 1.038659 1.005454 1.000003 \n\nres_tB &lt;- apply(Z2*scaling, \n                2, \n                function(x) varvec(x, dcca$cw))\nres_tB/dcca$eig \n\n[1]     56.85872    146.27484    606.11487   5455.95087  13172.64370\n[6] 161848.88784\n\nres_agree &lt;- apply(Z2_agree*scaling, \n                   2, \n                   function(x) varvec(x, dcca$cw))\nres_agree/dcca$eig\n\n[1] 1.106286 1.151797 1.466209 1.038659 1.005454 1.000003\n\n\n\n\nCode\nZ2inv &lt;- Z2_agree*scaling\nZ2inv[, 1] &lt;- -Z2inv[, 1]\n\nZhat2inv &lt;- Zhat2*scaling\nZhat2inv[, 1] &lt;- -Zhat2inv[, 1]\n\nplot(x = Zhat2inv[, 1], y = Zhat2inv[, 2],\n     col = NULL,\n     asp = 2,\n     main = \"LC scores (scaling type 2: column-preserving)\")\ntext(x = Z2inv[, 1], y = Z2inv[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 2)\ntext(x = Zhat2inv[, 1], y = Zhat2inv[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 2)\n# arrows(x0 = rep(0, nrow(BS2)),\n#        y0 = rep(0, nrow(BS2)),\n#        x2 = BS2[, 1], \n#        y2 = BS2[, 2],\n#        length = 0.2,\n#        asp = 2)\n# text(x = BS2[, 1], \n#      y = BS2[, 2],\n#      label = colnames(E),\n#      asp = 2)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\n\nScaling type 3 (symmetric scaling): \\(\\hat{Z}_3 = E_{center}B\\Lambda_{SVD}^{-1/2} = E_{center}B\\Lambda_{dc-CA}^{-1/4}\\) (for rows = sites) and \\(Z_3 = T_{center}C\\Lambda_{SVD}^{-1/2} = T_{center}C\\Lambda_{dc-CA}^{-1/4}\\) (for columns = species) (we the heuristic formula)\n\n\nZhat3 &lt;- Ecenter %*% B %*% diag(lambda^(-1/4))\n\nZ3 &lt;- Tcenter %*% C %*% diag(lambda^(-1/4))\n# Should be\n# Z3 &lt;- Tcenter %*% C %*% diag(lambda^(-3/4))\n\n\n\nCode\nZ3inv &lt;- Z3*scaling\nZ3inv[, 1] &lt;- -Z3inv[, 1]\n\nZhat3inv &lt;- Zhat3*scaling\nZhat3inv[, 1] &lt;- -Zhat3inv[, 1]\n\nplot(x = Zhat3inv[, 1], y = Zhat3inv[, 2],\n     col = NULL,\n     asp = 2,\n     xlim = c(-2, 2),\n     ylim = c(-2, 2),\n     main = \"LC scores (scaling type 3: symmetric)\")\ntext(x = Z3inv[, 1], y = Z3inv[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 2)\ntext(x = Zhat3inv[, 1], y = Zhat3inv[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 2)\n# arrows(x0 = rep(0, nrow(BS2)),\n#        y0 = rep(0, nrow(BS2)),\n#        x2 = BS2[, 1], \n#        y2 = BS2[, 2],\n#        length = 0.2,\n#        asp = 2)\n# text(x = BS2[, 1], \n#      y = BS2[, 2],\n#      label = colnames(E),\n#      asp = 2)\n\nabline(h = 0)\nabline(v = 0)\n\n\n\n\n\n\n\nWeighted averages (WA) scores\nWe can also get the weighted averages (WA) scores of the rows/columns. Indeed, rows scores are related to columns scores and conversely.\n\nThe WA scores for the rows (sites) are \\(\\hat{U}\\) and are computed from the column (species) scores:\n\n\\[\n\\hat{U}_i = D(y_{\\cdot i})^{-1} Y Z_i\n\\]\n\nThe WA scores for the column (species) are \\(U\\) and are computed from the row (sites) scores:\n\n\\[\nU_i = D(y_{j \\cdot})^{-1} Y' \\hat{Z}_i\n\\]\n\n# Column (species) scores\nU1 &lt;- solve(Dy_j) %*% t(Y) %*% Zhat1  \nU2 &lt;- solve(Dy_j) %*% t(Y) %*% Zhat2\nU3 &lt;- solve(Dy_j) %*% t(Y) %*% Zhat3\n\n# Rows (sites) scores\nUhat1 &lt;- solve(Dyi_) %*% Y %*% Z1\nUhat2 &lt;- solve(Dyi_) %*% Y %*% Z2\nUhat3 &lt;- solve(Dyi_) %*% Y %*% Z3\n\n\n\nCode\nU2inv &lt;- U2*scaling\nU2inv[, 1] &lt;- -U2inv[, 1]\n\nUhat1inv &lt;- Uhat1*scaling\nUhat1inv[, 1] &lt;- -Uhat1inv[, 1]\n\nplot(x = Uhat1inv[, 1], y = Uhat1inv[, 2],\n     col = NULL,\n     asp = 2,\n     xlim = c(-2, 2),\n     ylim = c(-2, 2),\n     main = \"WA scores (with scaling type 1: row-preserving)\")\ntext(x = U2inv[, 1], y = U2inv[, 2],\n     label = colnames(Y),\n     col = params$colspp,\n     asp = 2)\ntext(x = Uhat1inv[, 1], y = Uhat1inv[, 2],\n     label = rownames(Y),\n     col = params$colsite,\n     asp = 2)\n# arrows(x0 = rep(0, nrow(BS2)),\n#        y0 = rep(0, nrow(BS2)),\n#        x2 = BS2[, 1], \n#        y2 = BS2[, 2],\n#        length = 0.2,\n#        asp = 2)\n# text(x = BS2[, 1], \n#      y = BS2[, 2],\n#      label = colnames(E),\n#      asp = 2)\n\nabline(h = 0)\nabline(v = 0)"
  },
  {
    "objectID": "dcCA.html#more-tests",
    "href": "dcCA.html#more-tests",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "More tests",
    "text": "More tests\nBelow, we test the variances of various scores.\n\nLC scores for rows:\n\n\n# l1 variances should be 1\napply(as.matrix(dcca$l1), \n      2, \n      function(x) varvec(x, dcca$lw))\n\n     RS1      RS2      RS3      RS4      RS5      RS6 \n1.014490 1.005249 1.002007 1.000012 1.000331 1.000000 \n\n# li variances should be eigenvalues\napply(as.matrix(dcca$li), \n      2, \n      function(x) varvec(x, dcca$lw))/dcca$eig\n\n   Axis1    Axis2    Axis3    Axis4    Axis5    Axis6 \n1.014490 1.005249 1.002007 1.000012 1.000331 1.000000 \n\n\n\nLC scores for columns\n\n\n# c1 variances should be 1\napply(as.matrix(dcca$c1), \n      2, \n      function(x) varvec(x, dcca$cw))\n\n     CS1      CS2      CS3      CS4      CS5      CS6 \n1.106286 1.151797 1.466209 1.038659 1.005454 1.000003 \n\n# co variances should be eigenvalues\napply(as.matrix(dcca$co), \n      2, \n      function(x) varvec(x, dcca$cw))/dcca$eig \n\n   Comp1    Comp2    Comp3    Comp4    Comp5    Comp6 \n1.106286 1.151797 1.466209 1.038659 1.005454 1.000003 \n\n\n\n# Z2 variances should be the eigenvalues\napply(Z2*scaling, \n      2, \n      function(x) varvec(x, dcca$cw))/dcca$eig\n\n[1]     56.85872    146.27484    606.11487   5455.95087  13172.64370\n[6] 161848.88784\n\n\n\nWA scores:\n\n\n# Hypothesis: these scires shound be the eigenvalues\napply(as.matrix(dcca$lsR), \n      2, \n      function(x) varvec(x, dcca$lw))/dcca$eig\n\n    Axis1     Axis2     Axis3     Axis4     Axis5     Axis6 \n 1.397739  1.490618  1.894509  3.367612  7.569186 16.600310 \n\n# co variances should be eigenvalues\napply(as.matrix(dcca$lsQ), \n      2, \n      function(x) varvec(x, dcca$cw))/dcca$eig\n\n    Comp1     Comp2     Comp3     Comp4     Comp5     Comp6 \n 1.356947  1.416201  2.521861  7.980247  5.161038 13.632366"
  },
  {
    "objectID": "dcCA.html#interpretation",
    "href": "dcCA.html#interpretation",
    "title": "Double-constrained Correspondence Analysis (dc-CA)",
    "section": "Interpretation",
    "text": "Interpretation\nThis method finds the linear correlation of row explanatory variables (environmental variables) and the linear correlation of columns explanatory variables (species traits) that maximizes the fourth-corner correlation, i.e. the correlation between these linear combinations of row and columns-variables.\nThere are other related methods, that have been better described and also more used in ecology: RLQ, community weighted means RDA (CMW-RDA).\nContrary to RLQ, dc-CA takes into account the correlation between the row and column variables. Thus, while RLQ can analyze any number of row and column variables, it is not the case with dc-CA the number of row and column variables must not be large compared to the number of rows/columns in the tables.\nThe eigenvaines of dc-CA are the squares of the fourth-corner correlations."
  }
]