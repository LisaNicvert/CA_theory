---
title: "Canonical Correspondence Analysis (CCA)"
params:
  colsite: "burlywood4"
  colspp: "cornflowerblue"
---

```{r, results='hide', message=FALSE}
#| code-fold: true

# Paths
library(here)

# Multivariate analysis
library(ade4)
library(adegraphics)

# Matrix algebra
library(expm)

# Plots
source(here("functions/plot.R"))
```

```{r}
#| code-fold: true

# Define bound for comparison to zero
zero <- 10e-10
```

*The contents of this page relies heavily on @legendre2012.*

## Introduction

CCA is a method of the family of *canonical* or *direct gradient analyses*, in which a matrix of predictor variables intervenes in the computation of the ordination vectors.

CCA is an asymmetric method because the predictor variables and the response variables are not equivalent in the analysis.

CCA takes two matrices in input:

-   A data matrix $Y$ ($r \times c$)
-   A matrix of predictor variables $E$ ($r \times l$)

```{r, message = FALSE}
#| code-fold: true
dat <- readRDS(here("data/Barbaro2012.rds"))
Y <- dat$comm
E <- dat$envir

r <- dim(Y)[1]
c <- dim(Y)[2]
l <- dim(E)[2]

plotmat(r = r, c = c, l = l, 
        E = TRUE)
```

Here, $Y$ represents the abundance of different bird species (columns) at different sites (rows):

```{r, message = FALSE}
#| code-fold: true
knitr::kable(head(Y))
```

$E$ represents environmental variables (columns) associated to each site (rows).

```{r, message = FALSE}
#| code-fold: true
knitr::kable(head(E))
```

```{r}
(r <- dim(Y)[1])
(c <- dim(Y)[2])
(l <- dim(E)[2])
```

## Computation

::: {.callout-tip title="*TL;DR*"}
We have a data matrix $Y$ ($r \times c$) and a matrix $E$ ($r \times l$) of predictors variables.

We regress $P_0$ ("centered" $Y$) on $E_{stand}$ (which is the centered and scaled $E$ matrix):

$$
\hat{P_0} = D_r^{1/2} E_{stand}B
$$

Then, we diagonalize matrix $S_{\hat{P_0}^\top \hat{P_0}} = \hat{P_0}^\top\hat{P_0}$.

$$
S_{\hat{P_0}^\top\hat{P_0}} =  V_0 \Lambda V_0^{-1}
$$

The matrix $V_0$ ($c \times \text{mindim}$) contains the loadings of the columns (species) of the contingency table. There are $\text{mindim} = \min(r-1, c, l)$ non-null eigenvalues.

Then, we can find the rows (sites) observed scores $U_0$ ($r \times \text{mindim}$) from the eigenvectors of the multivariate space using the following formula:

$$
U_0 = P_0 V_0 \Lambda^{-1/2}
$$

Here, it is important to note that $U_0$ contains the loadings of the sites computed *from the observed data matrix* $P_0$, i.e. the latent ordination of the sites not taking into account the sites variables. The position of the sites taking into account the regression will be defined below in the [scalings](#scaling) section.


Finally, we define the following transformations of $U_0$ and $V_0$ ($V_0$ corresponds to `c1`):

$$
\left\{
\begin{array}{ll}
  U &= D_r^{-1/2} U_0\\
  V &= D_c^{-1/2} V_0\\
\end{array}
\right.
$$
This transformation is similar to the [transformation applied to CA eigenvectors](CA.qmd#define-u-and-v).
:::

### Transform matrix

We start by "centering" the matrix $Y$ to get $P_0$ ([just like with CA]( CA.qmd#transform-the-table CA)).

$$
P = Y/y_{\cdot \cdot}
$$

$$
P_0 = [p_{0ij}] = \left[ \frac{p_{ij} - p_{i\cdot} p_{\cdot j}}{\sqrt{p_{i\cdot} p_{\cdot j}}} \right]
$$

Here, we have:

```{r}
#| code-fold: true
P <- Y/sum(Y)

# Initialize P0 matrix
P0 <- matrix(ncol = ncol(Y), nrow = nrow(Y))
colnames(P0) <- colnames(Y)
rownames(P0) <- rownames(Y)

for(i in 1:nrow(Y)) { # For each row
  for (j in 1:ncol(Y)) { # For each column
    # Do the sum
    pi_ <- sum(P[i, ])
    p_j <- sum(P[, j])
    
    # Compute the transformation
    P0[i, j] <- (P[i, j] - (pi_*p_j))/sqrt(pi_*p_j)
  }
}
```

```{r}
#| code-fold: true
knitr::kable(head(P0))
```

### Weights on $E$

We standardize $E$ as $E_{stand}$, but we standardize so that the variables associated to the sites which have more observations have more weight. Therefore, we standardize $E$ with the weights $y_{i\cdot}/r$.

```{r}
E_wt <- rowSums(Y)/nrow(E)

Estand <- scalewt(E, wt = E_wt)
```


```{r}
#| code-fold: true
knitr::kable(head(Estand))
```

Conceptually, it is equivalent to using the inflated matrix $E_{infl}$ to compute its mean $\bar{E}_{infl}$ and standard deviation $\sigma(E_{infl})$ per column. In $E_{infl}$, the rows corresponding to each site are duplicates as many times as there are observations for this given site (so that $E_{infl}$ is of dimension $y_{\cdot \cdot} \times l$).

$$
E_{stand} = \frac{E - \bar{E}_{infl}}{\sigma(E_{infl})}
$$

With our data: first, we compute $E_{infl}$:

```{r}
#| code-fold: true
Einfl <- matrix(data = 0,
                ncol = ncol(E), 
                nrow = sum(Y))
colnames(Einfl) <- colnames(E)
rownames(Einfl) <- 1:nrow(Einfl)

# Get the number of times to duplicate each site
nrep_sites <- rowSums(Y)

nrstart <- 0
for (i in 1:nrow(E)) {
  ri <- as.matrix(E)[i, ]
  
  rname <- rownames(E)[i]
  
  # Get how many times to duplicate this site
  nr <- nrep_sites[as.character(rname)]
  
  Einfl[(nrstart+1):(nrstart+nr), ] <- matrix(rep(ri, nr), 
                                              nrow = nr, 
                                              byrow = TRUE)
  
  rownames(Einfl)[(nrstart+1):(nrstart+nr)] <- paste(rname,
                                                     1:nr,
                                                     sep = "_")
  nrstart <- nrstart + nr
}

paste("Dimension of Einfl:", paste(dim(Einfl), collapse = " "))
```

Then, we compute the mean and standard deviation per column and standardize $E$.

```{r}
#| code-fold: true
Einfl_mean <- apply(Einfl, 2, mean)

n <- nrow(Einfl)
Einfl_sd <- apply(Einfl, 2, 
                  function(x) sd(x)*sqrt((n-1)/n))
```

```{r}
#| code-fold: true
Estand2 <- scale(E, 
                 center = Einfl_mean,
                 scale = Einfl_sd)

all(abs(Estand2/Estand - 1) < zero)
```


### Regression

After that, we perform the weighted multiple linear regression of $P_0$ by $E_{stand}$. $P_0$ is approximated by $\hat{P_0}$ using multiple linear regression on $E_{stand}$: for each row, we can write $\hat{p_{0i\cdot}} = b_0 + b_1 e_{1\cdot} + \ldots + b_e e_{l\cdot}$, where $e_i$ are columns of $E_{stand}$ and $b_i$ are regression coefficients. 

In a matrix form, it is written:

$$
\hat{P_0} = D_r^{1/2}E_{stand}B
$$

Where

$$
B = [E_{stand}^\top D_r E_{stand}]^{-1}E_{stand}^\top D_r^{1/2}P_0
$$

With our example:

```{r}
# Diagonal matrix weights
dr <- rowSums(P)
Dr <- diag(dr)
colnames(Dr) <- rownames(P)

# Regression coefficient
B <- solve(t(Estand) %*% Dr %*% Estand) %*% t(Estand) %*% diag(dr^(1/2)) %*% P0

# Compute predicted values
P0hat <- diag(dr^(1/2)) %*% Estand %*% B
colnames(P0hat) <- colnames(P0)
rownames(P0hat) <- rownames(P0)
```

Now, we can get the predicted values for $P_0$. For instance, let's plot predicted vs observed values for site 2:

```{r}
# Get predicted and observed values for one site
ind <- 2

pred <- P0hat[ind, ]
obs <- P0[ind, ]
```

```{r}
#| code-fold: true
df <- data.frame(predicted = pred, 
                 observed = obs, 
                 names = names(pred))
df<- df |> 
  tidyr::pivot_longer(cols = c("predicted", "observed"),
                      names_to = "type")

ggplot(df, aes(x = reorder(names, value, decreasing = TRUE), 
               y = value, col = type, group = type)) +
  geom_point() +
  geom_line() +
  theme_linedraw() +
  ylab("Values of P0") +
  xlab("Species") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

### Diagonalization of $S_{\hat{P_0}^\top \hat{P_0}}$

Then, we diagonalize the covariance matrix of predicted values $S_{\hat{P_0}^\top \hat{P_0}}$.

First, we compute the covariance matrix (note that here we don't divide by the degrees of freedom).

$$
S_{\hat{P_0}^\top \hat{P_0}} = \hat{P_0}^\top \hat{P_0}
$$

```{r}
Spp <- t(P0hat) %*% P0hat
```

```{r}
#| code-fold: true

# Covariance matrix of predicted P0 is equal to that
Spe <- t(P0hat) %*% diag(dr^(1/2)) %*% as.matrix(Estand)
See <- t(Estand) %*% Dr %*% as.matrix(Estand)
Spp2 <- Spe %*% solve(See) %*% t(Spe)

all(abs(Spp/Spp2 - 1) < zero)
```

We diagonalize $S_{\hat{P_0}^\top \hat{P_0}}$:

$$
S_{\hat{P_0}^\top \hat{P_0}} = V_0 \Lambda V_0^{-1}
$$

$\Lambda$ is the matrix of eigenvalues (there are $\min(r-1, c, l)$ non-null eigenvalues) and $V_0$ contains the columns (species) loadings.

```{r}
neig <- min(c(r-1, c, l))
```

Here, $r-1 =$ `r r-1`, $c =$ `r c` and $l =$ `r l` so the minimum (and the number of eigenvalues) is `r neig`.

```{r}
eig <- eigen(Spp)

(lambda <- eig$values) # There are l = 6 non-null eigenvalues
lambda <- lambda[1:neig]

Lambda <- diag(lambda)
V0 <- eig$vectors[, 1:neig] # We keep only the eigenvectors
rownames(V0) <- colnames(Y)
```

Finally, we can get the ordination of rows (sites) by projecting the observed values (matrix $P_0$) onto the axes defined by the diagonalization ($V_0$):

$$
U_0 = P_0 V_0 \Lambda^{-1/2}
$$


```{r}
U0 <- P0 %*% V0 %*% diag(lambda^(-1/2))
rownames(U0) <- rownames(U0)

apply(U0, 2, varfacwt, wt = rowSums(P)) # Norm?
```


::: callout-note
The rows loadings $U_0$ are different from the loadings obtained by diagonalizing $S_{hat{P_0} \hat{P_0}^\top}$ or performing the SVD of $\hat{P_0}$, because $U_0$ does not contain the loadings of $\hat{P_0}$ but the loadings of $P_0$.


```{r}
# This is not the same as diagonalizing S_ppt
Sppt <- P0hat %*% t(P0hat)
eig2 <- eigen(Sppt)

all(abs(eig2$vectors[,1:neig]/U0 - 1) < zero) # Eigenvectors are different
```


```{r}
# We perform the SVD
sv <- svd(P0hat)

all(abs(abs(sv$u[, 1:neig]/U0) - 1) < zero) # Eigenvectors are different for U0
all(abs(abs(sv$v[, 1:neig]/V0) - 1) < zero) # But they are the same for V0
```


```{r}
# If U was computed as below (using the matrix of predicted values), it would give the same results as the diagonalization/SVD above (but it is not the case).

# Compute rows loadings differently
Uhat <- P0hat %*% V0 %*% diag(lambda^(-1/2))

all(abs(abs(Uhat/eig2$vectors[,1:neig]) - 1) < zero) # Eigenvectors are the same
all(abs(abs(sv$u[, 1:l]/eig2$vectors[,1:l]) - 1) < zero) # Eigenvectors are the same
```
::: 

### Compute $U$ and $V$

We compute $U$ and $V$ as:

$$
\left\{
\begin{array}{ll}
  U &= D_r^{-1/2} U_0\\
  V &= D_c^{-1/2} V_0\\
\end{array}
\right.
$$

First, we define the diagonal matrices with rows and columns weights (respectively $D_r$ and $D_c$).

```{r}
# Define weights vectors and matrices
dr <- rowSums(P)
dc <- colSums(P)

Dr <- diag(dr)
Dc <- diag(dc)
```

```{r}
# Sites
U <- diag(dr^(-1/2)) %*% U0
  
# Species
V <- diag(dc^(-1/2)) %*% V0
```

```{r}
apply(U, 2, varfacwt, wt = dr)/lambda # variance larger than lambda, because it contains the residuals of P0hat as well!!
apply(V, 2, varfacwt, wt = dc) # variance is one
```


## Scaling

::: {.callout-tip title="*TL;DR*"}
As with CA, we have scalings type 1, 2 and 3. There are 2 differences with CA:

+ For the sites, we have 3 types of scores: the predicted sites scores $Z$ (LC scores), computed from the regression, the "observed" sites scores $U$ computed from the observed data matrix, and the weighted averages $U^\star$ (WA scores), computed from the species scores.
+ There are also scalings for the correlations of the explanatory variables with the axes.

**Scaling type 1 ($\alpha = 1$)**

-   WA scores for rows (sites): $U^\star = U \Lambda^{1/2}$ (`ls`)
-   LC scores for rows (sites): $Z_1 = D_r^{-1/2} \hat{P_0} V_0$ (`li`)
-   Columns (species) scores: $V = D_c^{-1/2} V_0$ (`c1`)
-   Variables scores: $BS_1 = E_{stand}^\top D_r Z_{stand} \Lambda^{1/2}$

**Scaling type 2 ($\alpha = 0$)**

-   WA scores for rows (sites): $U = D_r^{-1/2} U_0$ (not computed by ade4: sort of `ls1`, but variance not normed to one)
-   LC scores for rows (sites): $Z_2 = D_r^{-1/2}\hat{P_0} V_0 \Lambda^{-1/2}$ (`l1`)
-   Columns (species) scores: $V^\star = V \Lambda^{1/2}$ (`co`)
-   Variables scores: $BS_2 = E_{stand}^\top D_r Z_{stand}$

**Scaling type 3 ($\alpha = 1/2$)**

-   WA scores for rows (sites): $\hat{S}_3 = U \Lambda^{1/4}$
-   LC scores for rows (sites): $Z_3 = D_r^{-1/2}\hat{P_0} V_0 \Lambda^{-1/4}$
-   Columns (species) scores: $S_3 = V \Lambda^{1/4}$
-   Variables scores: $BS_3 = E_{stand}' D_r Z_{stand}\Lambda^{1/4}$


$V^\star$ (columns/species) and $U^\star$ (rows/sites) correspond to weighted averagings, and cab be computed from $U$ (rows/sites) (resp. $V$ (columns/species)). See @eq-wa-sites and @eq-wa-spp below.

***How to find the fa (i.e. correlation coefficients for each environmental variable in the multivariate space)??***

:::

Let's compute CCA with `ade4` to compare results.

```{r}
ca <- dudi.coa(Y, 
               nf = c-1, 
               scannf = FALSE)
cca <- pcaiv(dudi = ca, 
             df = E,
             scannf = FALSE,
             nf = neig)

lambda[1:neig]/cca$eig # Eigenvalues are the same as computed manually
```

### Pre-computations

The scores for the explanatory variables are computed from matrix $Z_{stand}$: so we first need to standardize $Z$ into $Z_{stand}$ (the computation can involve $Z_1$, $Z_2$ or $Z_3$ (defined below) and give the same result).

$Z_1$, $Z_2$ or $Z_3$ are defined as some variation of:

$$Z_i = D_r^{-1/2} \hat{P}_0 V_0 \Lambda^\alpha$$
where $\alpha$ is an exponent equal to 0, -1/2 or -1/4. This equation corresponds to the projection of the predicted data matrix $\hat{P}_0$ onto the multivariate space.

```{r}
# Compute Z1
Z1 <- diag(dr^(-1/2)) %*% P0hat %*% V0

apply(Z1, 2, varfacwt)

Z_wt <- E_wt
Zstand <- scalewt(Z1, wt = Z_wt)
```

It is the same as computing with the inflated matrix (below):

```{r}
#| code-fold: true

# Compute inflated matrix ------
Zinfl <- matrix(data = 0,
                ncol = ncol(Z1), 
                nrow = sum(Y))
rownames(Zinfl) <- 1:nrow(Zinfl)
# Give names to Z1
rownames(Z1) <- rownames(Y)

# Get the number of times to duplicate each site
nrep_sites <- rowSums(Y)

nrstart <- 0
for (i in 1:nrow(Z1)) {
  ri <- Z1[i, ]
  
  rname <- rownames(Z1)[i]
  
  # Get how many times to duplicate this site
  nr <- nrep_sites[as.character(rname)]
  
  Zinfl[(nrstart+1):(nrstart+nr), ] <- matrix(rep(ri, nr), 
                                              nrow = nr, 
                                              byrow = TRUE)
  
  rownames(Zinfl)[(nrstart+1):(nrstart+nr)] <- paste(rname, 
                                                     1:nr, 
                                                     sep = "_")
  nrstart <- nrstart + nr
}

# Compute mean/sd ------
Zinfl_mean <- apply(Zinfl, 2, mean)

n <- nrow(Zinfl)
Zinfl_sd <- apply(Zinfl, 2, 
                  function(x) sd(x)*sqrt((n-1)/n))

# Compute Zstand ------
Zstand2 <- scale(Z1, 
                 center = Zinfl_mean,
                 scale = Zinfl_sd)

all(abs(Zstand2/Zstand - 1) < zero)
```


### Scaling type 1

Here, $\chi^2$ distances between rows (sites) are preserved they are positioned at the centroid of species. 

+ the rows (sites) scores can be positioned by averaging: $U^\star = U \Lambda^{1/2}$ (`ls`) or by predicted positions $Z_1 = D_r^{-1/2} \hat{P_0} V_0$ (`li`)
+ the columns (species) scores are positioned at variance 1 $V = D_c^{-1/2} V_0$ (`c1`)
+ the explanatory variable score are $BS_1 = E_{stand}^\top D_r Z_{stand}\Lambda^{1/2}$

```{r}
# Rows WA scores
Ustar <- U %*% diag(lambda^(1/2))

# Variables correlation
BS1 <- t(Estand) %*% Dr %*% Zstand %*% sqrt(Lambda)
```

If we compare to the results obtained with ade4, we can see what each score corresponds to.

```{r}
all(abs(abs(Z1/cca$li) - 1) < zero) # Predicted sites scores
all(abs(abs(Ustar/cca$ls) - 1) < zero) # Averaging sites scores

all(abs(abs(V/cca$c1) - 1) < zero) # Variance 1 species scores

# What does the BS1 correspond to?
res <- as.matrix(cca$cor)/(BS1 %*% diag(lambda^(-1/2)) )
all(abs(abs(res) - 1) < zero)
```


We know that $V$/`c1` is of variance 1 (computed above). Below we show that $Z_1$/`li` is of variance $\lambda$ and try to get the variance of $U^\star$/`ls`.

```{r}
# The CCA weights can be recovered from data (modulo a constant)
cca$lw/E_wt
cca$cw/(colSums(Y)/ncol(Y))
```


```{r}
apply(Z1, 2, varwt, wt = cca$lw)/cca$eig # Z1 variance = eigenvalues
apply(Ustar, 2, varwt, wt = cca$lw)
```

#### Weighted averaging

Similarly to the [CA case](CA.qmd#weighted-averaging), $U^\star$ (sites coordinates) can be obtained from species coordinates, weighted by the observed data matrix:

$$
U^\star = \left\{
\begin{array}{ll}
  D_r^{-1/2} P_0 V_0 \qquad &\text{(from } V_0 \text{)}\\
  D_r^{-1/2} P_0 D_c^{1/2} V \qquad &\text{(from } V \text{)}\\
   D_r^{-1} P V \qquad &\text{(from } V \text{ and } P \text{)}\\
\end{array}
\right.
$${#eq-wa-sites}

```{r}
# With V0
Ustar_wa <- diag(dr^(-1/2)) %*% P0 %*% V0
res <- Ustar_wa/Ustar
all(res[, 1:neig] - 1 < zero)

# With V
Ustar_wa_V <- diag(dr^(-1/2)) %*% P0 %*% diag(dc^(1/2)) %*% V
res <- Ustar_wa_V/Ustar
all(res[, 1:neig] - 1 < zero)

# With V and P
Ustar_wa_legendre <- diag(dr^(-1)) %*% P %*% V
res <- Ustar_wa_legendre/Ustar
all(res[, 1:neig] - 1 < zero)
```

#### Plots

We can plot the predicted scores for sites (LC scores):

```{r, warning=FALSE}
#| code-fold: true

mult <- 10

# LC scores
multiplot(indiv_row = Z1, indiv_col = V, 
          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), 
          var_row = BS1, var_row_lab = colnames(E),
          row_color = params$colsite, col_color = params$colspp,
          mult = mult,
          eig = lambda) +
  ggtitle("LC scores for sites")
```


```{r}
#| code-fold: true

s.label(cca$c1, # Species constrained at variance 1
        plabels.optim = TRUE,
        plabels.col  = params$colspp,
        ppoints.col = params$colspp,
        main = "LC scores for sites")
s.label(cca$li, # Predicted sites scores
        plabels.optim = TRUE,
        plabels.col  = params$colsite,
        ppoints.col = params$colsite,
        add = TRUE)
```

We can also plot the weighted averaging sites scores:

```{r, warning=FALSE}
#| code-fold: true

# WA scores
multiplot(indiv_row = Ustar, indiv_col = V, 
          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), 
          var_row = BS1, var_row_lab = colnames(E),
          row_color = params$colsite, col_color = params$colspp,
          mult = mult,
          eig = lambda) +
  ggtitle("WA scores for sites")
```

```{r}
#| code-fold: true

s.label(cca$c1, # Species constrained at variance 1
        plabels.optim = TRUE,
        plabels.col  = params$colspp,
        ppoints.col = params$colspp,
        main = "WA scores for sites")
s.label(cca$ls, # WA sites scores
        plabels.optim = TRUE,
        plabels.col  = params$colsite,
        ppoints.col = params$colsite,
        add = TRUE)
```


### Scaling type 2

Here, $\chi^2$ distances between columns (species) are preserved they are positioned at the centroid of sites.


+ the rows (sites) scores can be $U = D_r^{-1/2} U_0$ (variance 1) or $Z_2 = D_r^{-1/2} \hat{P_0} V_0 \Lambda^{-1/2}$ (`l1`) (predicted sites scores)
+ the columns (species) scores are $V^\star = V \Lambda^{1/2}$ (`co`) (WA scores from sites latent ordination)
+ the explanatory variable score are $BS_2 = E_{stand}^\top D_r Z_{stand}$


```{r}
# Row predicted scores
Z2 <- diag(dr^(-1/2)) %*% P0hat %*% V0 %*% diag(lambda^(-1/2))

# Columns WA scores
Vstar <- V %*% Lambda^(1/2)

# Variables correlation
BS2 <- t(Estand) %*% Dr %*% Zstand
```


If we compare to the results obtained with ade4, we can see what each score corresponds to.

```{r}
all(abs(abs(Z2/cca$l1) - 1) < zero) # Predicted sites scores of variance 1

# U is not computed by ade4 so we compute it from ls (corresponding to Ustar)
ls1_ade4 <- as.matrix(cca$ls) %*% diag(lambda^(-1/2))
all(abs(abs(ls1_ade4/U) - 1) < zero)

all(abs(abs(Vstar/cca$co) - 1) < zero) # Averaging column scores

all(abs(abs(cca$cor/BS2) - 1) < zero) # Variables correlations
```

Below we show that $V^\star$/`co` is of variance $\lambda$, $Z_2$/`l1` is of variance 1 and try to get the variance of $U$/`ls1`.

```{r}
apply(Vstar, 2, varwt, wt = cca$cw)/cca$eig # Vstar variance = eigenvalues
apply(Z2, 2, varwt, wt = cca$lw) # Z variance = 1
apply(ls1_ade4, 2, varwt, wt = cca$lw) # ?
```


#### Weighted averaging

$V^\star$ (species coordinates) can be obtained from sites coordinates, weighted by the *predicted* data matrix. Contrary to the [CA case](CA.qmd#weighted-averaging-1), sites coordinates are not weighted by $P_0$ (observed) but by $\hat{P}_0$ (predicted):

$$
V^\star = \left\{
\begin{array}{ll}
  D_c^{-1/2} \hat{P}_0^\top U_0 \qquad &\text{(from } U_0 \text{)}\\
  D_c^{-1/2} \hat{P}_0^\top D_r^{1/2} U \qquad &\text{(from } U \text{)}
\end{array}
\right.
$${#eq-wa-spp}

```{r}
# U0
Vstar_wa <- diag(dc^(-1/2)) %*% t(P0hat) %*% U0
res <- Vstar_wa/Vstar
all(res[, 1:neig] - 1 < zero)

Vstar_wa_U <- diag(dc^(-1/2)) %*% t(P0hat) %*% diag(dr^(1/2)) %*% U
res <- Vstar_wa_U/Vstar
all(res[, 1:neig] - 1 < zero)
```

#### Plots

We can plot the predicted scores for sites (LC scores):

```{r, warning=FALSE}
#| code-fold: true

mult <- 1

# LC scores
multiplot(indiv_row = Z2, indiv_col = Vstar, 
          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), 
          var_row = BS2, var_row_lab = colnames(E),
          row_color = params$colsite, col_color = params$colspp,
          mult = mult,
          eig = lambda) +
  ggtitle("LC scores for sites (variance 1)")
```

```{r}
#| code-fold: true

s.label(cca$l1, # Predicted sites scores of variance 1
        plabels.optim = TRUE,
        plabels.col  = params$colsite,
        ppoints.col = params$colsite,
        main = "LC scores for sites (variance 1)")
s.label(cca$co, # Species WA
        plabels.optim = TRUE,
        plabels.col  = params$colspp,
        ppoints.col = params$colspp,
        add = TRUE)

s.corcircle(cca$cor)
```

We can also plot the sites WA scores $U$:

```{r, warning=FALSE}
#| code-fold: true

# WA scores
multiplot(indiv_row = U, indiv_col = Vstar, 
          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), 
          var_row = BS2, var_row_lab = colnames(E),
          row_color = params$colsite, col_color = params$colspp,
          mult = mult,
          eig = lambda) +
  ggtitle("Sites WA scores (U)")
```

ade4 does not compute the sites WA scores corresponding to $U$, so we compute them below:

```{r}
#| code-fold: true

s.label(ls1_ade4, # Sites WA scores U
        plabels.optim = TRUE,
        plabels.col  = params$colsite,
        ppoints.col = params$colsite,
        main = "Sites WA scores (U)")
s.label(cca$co, # Species WA
        plabels.optim = TRUE,
        plabels.col  = params$colspp,
        ppoints.col = params$colspp,
        add = TRUE)
```

### Scaling type 3

This type of scaling is a compromise between scalings type 1 and 2.

+ the rows (sites) scores can be $\hat{S}_3 = U \Lambda^{1/4}$ or $Z_3 = D_r^{-1/2} \hat{P_0} V_0 \Lambda^{-1/4}$ 
+ the columns (species) scores are $S_3 = V \Lambda^{1/4}$
+ the explanatory variable score are $BS_3 = E_{stand}^\top D_r Z_{stand} \Lambda^{1/4}$

```{r}
# Row scores
Shat3 <- U %*% Lambda^(1/4) # Latent scores
Z3 <- diag(dr^(-1/2)) %*% P0hat %*% V0 %*% diag(lambda^(-1/4)) # Predicted scores

# Columns scores
S3 <- V %*% Lambda^(1/4)

# Variables correlation
BS3 <- t(Estand) %*% Dr %*% Zstand %*% Lambda^(1/4)
```

The corresponding ade4 values are not computed, but we can compute them:
```{r}
Z3_ade4 <- as.matrix(cca$l1) %*% diag(cca$eig^(1/4))
Shat3_ade4 <- ls1_ade4 %*% diag(cca$eig^(1/4))
S3_ade4 <- as.matrix(cca$c1) %*% diag(cca$eig^(1/4))
```

```{r}
all(abs(abs(Z3_ade4/Z3) - 1) < zero) # LC scores for sites
all(abs(abs(Shat3_ade4/Shat3) - 1) < zero) # sites scores
all(abs(abs(S3_ade4/S3) - 1) < zero) # species scores
```

### Plots

```{r, warning=FALSE}
#| code-fold: true

# LC scores
multiplot(indiv_row = Z3, indiv_col = S3, 
          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), 
          var_row = BS3, var_row_lab = colnames(E),
          row_color = params$colsite, col_color = params$colspp,
          mult = mult,
          eig = lambda) +
  ggtitle("LC scores for sites")
```

```{r}
s.label(Z3_ade4,
        plabels.optim = TRUE,
        xlim = c(-3, 2),
        ylim = c(-2, 3),
        plabels.col  = params$colsite,
        ppoints.col = params$colsite)
s.label(S3_ade4,
        plabels.optim = TRUE,
        plabels.col  = params$colspp,
        ppoints.col = params$colspp,
        add = TRUE)
```

```{r, warning=FALSE}
#| code-fold: true

mult <- 5

multiplot(indiv_row = Shat3, indiv_col = S3, 
          indiv_row_lab = rownames(Y), indiv_col_lab = colnames(Y), 
          var_row = BS3, var_row_lab = colnames(E),
          row_color = params$colsite, col_color = params$colspp,
          mult = mult,
          eig = lambda) +
  ggtitle("Sites latent scores")
```

```{r}
s.label(Shat3_ade4,
        plabels.optim = TRUE,
        xlim = c(-3, 2),
        ylim = c(-2, 3),
        plabels.col  = params$colsite,
        ppoints.col = params$colsite)
s.label(S3_ade4,
        plabels.optim = TRUE,
        plabels.col  = params$colspp,
        ppoints.col = params$colspp,
        add = TRUE)
```

## Interpretation

In CCA, each ordination axis corresponds to a linear combination of the explanatory variables that maximizes the explained variance in the response data.

This analysis constrains rows (sites) scores to be linear combinations of the environmental variables (scaling $Z_i$).

Species can be ordered along environmental variables axes by projecting species coordinates on the vector of this variable. This gives species niche optimum, but there are strong assumptions:

-   unimodal distribution of niches preferences along the variable of interest
-   species distributions are indeed controlled by the environment
-   the study gradient is long enough to capture the range of species abundance variation.

The part of variation explained by the environmental variables can be computed as 

$$
\frac{\sum_k \lambda_k(CCA)}{\sum_l \lambda_l(CA)}
$$


```{r}
sum(lambda)/sum(ca$eig)
```

Here, the environmental variables explain `r round(sum(lambda)/sum(ca$eig), 3)*100` % of the total variation.

Warning: in CCA, using noisy or not relevant explanatory variables leads to spurious relationships.

### Residual analysis

In order to examinate residuals, a CA can be performed on the table of residuals $P_{\text{res}}$:

$$
P_{\text{res}} = P_0 - \hat{P}_0
$$

```{r}
Pres <- P0 - P0hat

res_pca <- dudi.pca(Pres, scannf = FALSE, nf = 27)

scatter(res_pca)
```

### Tests of significance

It is possible to test the significance of the the relationship between $E$ and $Y$ with a permutation test.

```{r}
randtest(cca, nrepet = 999)
```
